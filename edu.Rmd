---
title: "Education"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(data.table)
library(scales)
library(plotly)
library(rgeos)
library(rgdal)
library(sp)
library(doSNOW)
library(foreach)
library(doParallel)
library(tictoc)
library(gridExtra)
library(future.apply)
library(FNN)
library(sf)
source("helpers.R")
```

## Import Files

```{r Import files, include=FALSE}
# TRESO 
treso_shp <- readOGR(dsn = "input/treso", layer = "TRESO_Zones_SocioData_Gatineau_LCC")
treso_tb <- readRDS("cache/treso/treso_tb.rds")

# TRESO time skim
travel_time_skim_square <- read_csv("input/treso/mf224.csv.gz")

travel_time_skim <- travel_time_skim_square %>%
  reshape2::melt(id = c("p/q/[val]")) %>%
  rename(orig = "p/q/[val]", dest = variable) %>%
  mutate(orig = as.numeric(orig), dest = as.numeric(levels(dest))[dest]) %>%
  filter(orig %in% treso_shp@data$Treso_ID) %>%
  filter(dest %in% treso_shp@data$Treso_ID)

# Definition files
school_board_def <- read_csv("input/edu/school_board_types.csv")
treso_zone_def <- read.csv("input/treso/treso_zone_system.csv", stringsAsFactors = FALSE)

# Student travel data
student_travel_90 <- readRDS("cache/edu/student_travel_0.9.rds")
student_travel_80 <- readRDS("cache/edu/student_travel_0.8.rds")
student_travel_70 <- readRDS("cache/edu/student_travel_0.7.rds")
student_travel_60 <- readRDS("cache/edu/student_travel_0.6.rds")
student_travel_50 <- readRDS("cache/edu/student_travel_0.5.rds")

# School related data
school_sfis_2017 <- readRDS("cache/edu/school_sfis_2017.rds") %>%
  rename(year = year.x)

# EQAO only has school number which corresponds to BSID
eqao_2017 <- readRDS("cache/edu/eqao_standardized_2017.rds") %>%
  mutate(School.Number = as.character(School.Number)) %>%
  mutate(School.Number = gsub("^0+", "", School.Number)) %>%
  mutate(School.Number = as.integer(School.Number)) %>%
  drop_na(School.Number) %>% # 3 NA schools with not value
  left_join(select(school_sfis_2017, bsid, sfis),
            by = c("School.Number" = "bsid"))
print(paste0("There are ", length(filter(eqao_2017, is.na(sfis))$sfis), " schools with no SFIS ID linked to EQAO scores."))
eqao_2017 <- drop_na(eqao_2017, sfis)
saveRDS(eqao_2017, "cache/edu/eqao_2017.rds")

# Read in user-set travel-time threshold as a function of mean system-wide travel time
travel_time_threshold_factor <- 1.5 #TODO: Replace this with value provided by user through the visualization interface

# Define zone proximity threshold in minutes of travel time (i.e., proximity of TRESO zones within which two new schools should not be built)
zone_proximity_threshold <- 15 # TODO:Replace this with value provided by user through the visualization interface

# Define excess travel time below which it is not worthwhile to consider building a school
min_tt_threshold <- 350 # TODO:Replace this with value provided by user through the visualization interface?

# Define threshold below which existing schools should be consolidated, assuming existing schools are elible for consolidation
consolidation_threshold <- 0.25 # TODO:Replace this with value provided by user through the visualization interface?

# Identify whether user is running decision-making layer
dm <- TRUE # TODO:Replace this with value provided by user through the visualization interface

# Percentage of current OTG to be set as maximum capacity in model
USER_OTG_THRESHOLD = 1.0 # TODO: Replace this hard-coded value with user-input value from visualization

# Future scenario year
year_id <- 2025 # TODO: Replace this hard-coded value with user-input value from visualization

# Base scenario year
base_year <- 2017

```

## Application of Gravity Model {.tabset .tabset-fade}

### Step 1 - Run 2017 Base Model

```{r application of gravity model - step 1}
# Read the saved full list of POR and POS TRESO zones once and save it in output
por_full <- readRDS("output/treso/por_full.rds")
pos_full <- readRDS("output/treso/pos_full.rds")

# Remove schools with status other than "Open" for modelling
school_master <- readRDS("cache/edu/school_treso_master.rds") %>%
  filter((status == "Open" | is.na(status)), otg != 0, ade != 0)

# Used in Step 4 but initialized here before school_master changes
school_master_2017 <- school_master %>% 
  filter(year == base_year)

# Create a list of schools closed between 2017 and the scenario run year to avoid sending students to non-existent schools
schools_closed <- school_master_2017 %>% 
  anti_join(select(school_master, sfis), by = c('sfis'))

# Initalize consolidated and closed schools list for use in decision-making layer
schools_consolidated_closed <- schools_closed

# Percentage of students attending each board type, by home origin CSD
board_type_sample_spread <- readRDS("output/edu/board_type_sample_spread.rds")

board_id <- "English Public" # TODO: Replace this hard-coded value with user-input value from visualization
panel_id <- "Elementary" # TODO: Replace this hard-coded value with user-input value from visualization

treso_forecast_population <- readRDS("input/edu/treso_population_edu.rds") %>% 
  select(treso.id.por = treso_zone, panel = age.group, csduid, potential.enrolment = paste0("population.", base_year)) %>%
  filter(panel != "other")

# Initialize new school dataframe
new_school <- tibble(treso.id.pos = integer(), panel = character(), board_type_name = character(), year = integer(), build.priority = integer(), sfis.temp = integer(), otg = integer())

# Initialize consolidated schools dataframe for use in Step 4 and decision-making layer
schools_consolidated <- tibble(sfis = integer())

# TODO: Check that we scale population from treso_forecast_population above to forecasted ADE, since only ~90% of age-appropriate children attend public schools

segment_id = paste0(str_split(str_split(board_id, " ")[[1]][1], "")[[1]][1],
                    str_split(str_split(board_id, " ")[[1]][2], "")[[1]][1],
                    str_split(panel_id, "")[[1]][1])
print(segment_id)

# Read the propensity matrix
prop_matrix <- readRDS(paste0("cache/edu/cfunc_", segment_id, ".rds"))

# Create pos vector
pos <- create_pos_vector(school_master, new_school=NULL, pos_full, year_id=base_year, panel_id=panel_id, board_id=board_id)

# Apply the board sampling probabilities to the student population from TRESO
treso_forecast_population_board <- apply_sampling_to_population(forecast_population = treso_forecast_population,
                                                                board_type_sample = board_type_sample_spread) 
# Create forecast por vector
por <- create_por_forecast_vector(treso_forecast_population_board, por_full, 
                                  panel_id=panel_id, board_id=board_id)

# TODO: Scale potential.enrolment down to actual forecasted ADE - compare historical population in CSD to historical enrolment (ADE) in CSD and create scaling factor for each CSD, and apply across all TRESO zones within CSD

print(paste0("ADE is: ", sum(por), ". OTG is: ", sum(pos), "."))

# 1D balancing
prop_matrix_balanced <- matrix_balancing_1d(prop_matrix, por, pos, axis=1, is_weight_continuous=TRUE)

trip_list <- reshape2::melt(prop_matrix_balanced) %>%
    arrange(Var1, Var2)
colnames(trip_list) <- c("treso.id.por", "treso.id.pos", "trips")

# Produce the simulated ADE for each school
school_summary_2017 <- forecast_school_ade(prop_matrix, trip_list, school_master, eqao_2017, new_school,
                                           year_id = base_year, panel_id = panel_id, board_id = board_id)[[1]]

# There are a handful of schools that does not get any simulated ADE due to a variety of reasons. 
# It is a very small percentage of total schools in the segment x board type combination
# However, the potential impact of this is that if the population decrease in the future, and zero simulated ADE is distributed
# to these schools, with our methodology - the schools will remain with the same observed 2017 ADE as opposed to decreasing to 0.
number_of_zero_simulated_schools <- school_master %>% 
  filter(panel == panel_id, board_type_name == board_id, year == base_year) %>% 
  anti_join(select(school_summary_2017, sfis), by = c('sfis')) %>% 
  nrow()

print(paste0("The number of schools with no simulated ADE is: ", number_of_zero_simulated_schools))

```

### Step 2 - Run 20xx Forecast Model 
- Date set by user

```{r application of gravity model - Step 2}
# Read the saved full list of POR and POS TRESO zones once and save it in output
por_full <- readRDS("output/treso/por_full.rds")
pos_full <- readRDS("output/treso/pos_full.rds")
# The forecasted schools have "NA" in status
school_master <- readRDS("cache/edu/school_treso_master.rds") %>% 
  filter((status == "Open" | is.na(status)), otg != 0, ade != 0)
board_type_sample_spread <- readRDS("output/edu/board_type_sample_spread.rds") 

treso_forecast_population <- readRDS("input/edu/treso_population_edu.rds") %>% 
  select(treso.id.por = treso_zone, panel = age.group, csduid, potential.enrolment = paste0("population.", year_id)) %>%
  filter(panel != "other")

segment_id = paste0(str_split(str_split(board_id, " ")[[1]][1], "")[[1]][1],
                    str_split(str_split(board_id, " ")[[1]][2], "")[[1]][1],
                    str_split(panel_id, "")[[1]][1])
print(segment_id)

# Read the propensity matrix
prop_matrix <- readRDS(paste0("cache/edu/cfunc_", segment_id, ".rds"))

# Create pos vector
pos <- create_pos_vector(school_master, new_school, pos_full, year_id=year_id, panel_id=panel_id, board_id=board_id)

# Apply the board sampling probabilities to the student population from TRESO
treso_forecast_population_board <- apply_sampling_to_population(forecast_population = treso_forecast_population,
                                                                board_type_sample = board_type_sample_spread) 

por <- create_por_forecast_vector(treso_forecast_population_board, por_full, 
                                  panel_id=panel_id, board_id=board_id)

print(paste0("ADE is: ", sum(por), ". OTG is: ", sum(pos), "."))

# 1D balancing
prop_matrix_balanced <- matrix_balancing_1d(prop_matrix, por, pos, axis=1, is_weight_continuous=TRUE)
trip_list <- reshape2::melt(prop_matrix_balanced) %>%
    arrange(Var1, Var2)
colnames(trip_list) <- c("treso.id.por", "treso.id.pos", "trips")

# Produce the simulated ADE for each school
school_summary_df_list <- forecast_school_ade(prop_matrix, trip_list, school_master, eqao_2017, new_school,
                                           year_id = year_id, panel_id = panel_id, board_id = board_id)

school_summary_20xx <- school_summary_df_list[[1]]

# Create dataframe containing list of schools which do not receive any ADE in model run
df_0 <- school_summary_df_list[[2]]

```

### Step 3 - Calculate Delta between Simulated Base and Forecast Models

```{r application of gravity model - step 3}
# Take the difference between the simulated ADEs
trip_list_schools_summary_difference <- full_join(school_summary_2017, school_summary_20xx, 
                                                  by="sfis", suffix=c(".2017", ".20xx")) %>% 
  replace_na(list(simulated.ade.2017 = 0, simulated.ade.20xx = 0)) %>% 
  mutate(change.ade = simulated.ade.20xx - simulated.ade.2017)
```

### Step 4 - Apply delta to 2017 Observed ADE. Create POR and POS vectors with overflow students.

```{r application of gravity model - step 4}

# User input for capacity constraint
CAPACITY_CONSTRAINED = TRUE # TODO: Replace this hard-coded value with user-input value from visualization

# Create the forecasted school list with OTG, OTG Threshold, ADE and Simulated ADE
school_forecast <- school_master_2017 %>% 
  filter((status == "Open" | is.na(status)), otg != 0, ade != 0) %>% 
  filter(panel == panel_id, board_type_name == board_id) %>% 
  # Add in new schools
  bind_rows(., new_school) %>% 
  full_join(select(trip_list_schools_summary_difference, sfis, simulated.ade.20xx, simulated.ade.2017, change.ade), by="sfis") %>%
  # Anti-join to remove any schools which existed in 2017 but no longer exist in future year
  anti_join(select(schools_consolidated_closed, sfis), by = c('sfis')) %>% 
  replace_na(list(ade = 0, change.ade = 0)) %>%                 
  # 'Actual' forecast ADE = existing ADE (2017 actual historical data) plus change in ADE estimated in Step 3
  mutate(simulated.ade.raw = ade + change.ade) %>% 
  mutate(simulated.ade = ifelse(ade + change.ade < 0, 0, ade + change.ade)) %>%
  # If simulated.ade.raw < 0 for any school, this value is rounded up to 0 to prevent having a negative number of students at each school. However, by rounding up to 0, the model is adding 'phantom' students to the system, so total ADE as estimated by the distribution model will exceed total ADE estimated in population forecasts. However, in test runs, this did not occur at any schools, so risk appears low. If it were to happen, the result would be a slight increase in the total number of ADE across the province, which would almost certainly be negligible. 
  # Create OTG threshold based on user input
  mutate(otg.threshold = otg * USER_OTG_THRESHOLD) %>% 
  select(treso.id.pos, sfis, school.name, otg, otg.threshold, ade, simulated.ade)

# Create a POS vector with schools over OTG Threshold - pos_overfill. These students need to be redistributed to other schools.
# Start by redistributing overflow to other schools within the TRESO zone
pos_redist <- school_forecast %>% 
  mutate(ade.diff = simulated.ade - otg.threshold,
         overfill = pmax(ade.diff, 0),
         underfill = pmin(ade.diff, 0)) %>% 
  # Create flag to determine if there is capacity remaining in each school
  mutate(capacity.flag = 1 - pmax(pmin(ade.diff, 1),0)) %>%
  group_by(treso.id.pos) %>% 
  mutate(treso.capacity = sum(underfill),
         treso.overfill = sum(overfill)) %>%
  # Calculate likelihood of going each of the other school(s) in the TRESO zone if redirected from full school
  mutate(otg.weight.underfill = otg * capacity.flag,
         underfill.share = otg.weight.underfill / sum(otg.weight.underfill)) %>%
  mutate(underfill.share = replace_na(underfill.share, 0)) %>% 
  # Calculate likelihood of coming from each overfilled school in a TRESO zone
  mutate(otg.weight.overfill = overfill * (1 - capacity.flag),
         overfill.share = otg.weight.overfill / sum(otg.weight.overfill)) %>%
  mutate(overfill.share = replace_na(overfill.share, 0)) %>% 
  # Determine how many students will be redistributed within zone
  mutate(treso.redist = min(treso.overfill, -treso.capacity),
         school.redist.to = treso.redist * underfill.share,
         school.redist.from = treso.redist * overfill.share) %>% 
  # Adjust simulated ADE to account for shift from one school to another within zones
  mutate(simulated.ade.rev = simulated.ade + school.redist.to - school.redist.from) %>%
  ungroup()

# Create a POS vector with schools over OTG Threshold after redistributing to other schools within the TRESO zone
pos_overfill <- school_forecast %>%
  select(-simulated.ade) %>% 
  left_join(select(pos_redist, sfis, simulated.ade.rev), by = c('sfis')) %>% 
  rename(simulated.ade = simulated.ade.rev) %>% 
  mutate(overfill.flag = ifelse(simulated.ade >= otg.threshold, 1, 0)) %>% 
  filter(overfill.flag == 1) %>% 
  select(treso.id.pos, overfill.flag) %>% 
  group_by(treso.id.pos) %>% 
  summarise(overfill.flag = max(overfill.flag)) %>% 
  right_join(pos_full, by=c("treso.id.pos" = "dest")) %>% 
  replace_na(list(overfill.flag = 0)) %>% 
  arrange(treso.id.pos) %>% 
  column_to_rownames(var = "treso.id.pos") %>% 
  data.matrix()

# Calculate the total overfilled ADE
overfill_ade <- school_forecast %>% 
  select(-simulated.ade) %>% 
  left_join(select(pos_redist, sfis, simulated.ade.rev), by = c('sfis')) %>% 
  rename(simulated.ade = simulated.ade.rev) %>% 
  mutate(overfill.flag = ifelse(simulated.ade >= otg.threshold, 1, 0),
         overfill.ade = simulated.ade - otg.threshold) %>% 
  filter(overfill.flag == 1) %>% 
  select(overfill.ade) %>% 
  sum()

# Create a POS vector with schools under OTG Threshold - pos_underfill
# Use the difference between OTG Threshold and Simulated ADE as the weight
pos_underfill <- school_forecast %>% 
  select(-simulated.ade) %>% 
  left_join(select(pos_redist, sfis, simulated.ade.rev), by = c('sfis')) %>% 
  rename(simulated.ade = simulated.ade.rev) %>% 
  mutate(underfill.flag = ifelse(simulated.ade < otg.threshold, 1, 0)) %>% 
  filter(underfill.flag == 1) %>%
  mutate(otg.leftover = otg.threshold - simulated.ade) %>% 
  select(treso.id.pos, otg.leftover) %>% 
  group_by(treso.id.pos) %>% 
  summarise(otg = sum(otg.leftover)) %>% 
  right_join(pos_full, by=c("treso.id.pos" = "dest")) %>% 
  replace_na(list(otg = 0)) %>% 
  arrange(treso.id.pos) %>%
  column_to_rownames(var = "treso.id.pos") %>% 
  data.matrix()

# Apply pos_overfill to balanced matrix to obtain origin zones of the overflown schools
por_overfill <- prop_matrix_balanced %*% pos_overfill %>% 
  as_tibble(rownames = NA) %>% 
  rename(ade = overfill.flag) %>% 
  rownames_to_column(var = "treso.id.por") %>% 
  # scale the zone origin ADE to match the overfill ADE total previously calculated (overfill_ade)
  mutate(ade.overfill = ade * overfill_ade / sum(ade)) %>% 
  mutate(sumADE = sum(ade)) %>% 
  select(treso.id.por, ade.overfill)

por_additional <- por_overfill %>% 
  filter(ade.overfill >= 15) %>% 
  select(ade.overfill, treso.id.por) %>% 
  mutate(treso.id.por = as.numeric(treso.id.por))

# Add in any origin zones sending students to school zones still overfilled after several rounds of balancing
por_overfill <- por_overfill %>% 
  column_to_rownames(var = "treso.id.por") %>% 
  data.matrix()

# Sanity check with the dot product operation
print(paste0("The first element of por_overfill is: ", (prop_matrix_balanced %*% pos_overfill)[1,1]))
print(paste0("Compare that with the sum of first column of prop_matrix_balanced: ", sum(prop_matrix_balanced[1,as.logical(pos_overfill)])))

print(paste0("The scaled POR vector sums to: ", sum(por_overfill), ". Which should be the same as the overfill_ade: ", overfill_ade))
```

### Step 5 - Re-balance with ADE overfill and OTG leftover

```{r application of gravity model - step 5}
# Balance the por_overfill against pos_underfill schools to redistribute the overfilled ADE
print(paste0("ADE overfill total is: ", sum(por_overfill), ". OTG remaining is: ", sum(pos_underfill), "."))
    
# TODO: instead of using the OTG remaining as the weight to balance (b/c this is not logical), use OTG total as the weight and remember to add the ADE overflowing on top of the already simulated ADE for these underfilled schools
# 1D balancing
prop_matrix_balanced <- matrix_balancing_1d(prop_matrix, por_overfill, pos_underfill, axis=1, is_weight_continuous=TRUE)
# # 2D balancing
# prop_matrix_balanced <- matrix_balancing_2d(prop_matrix, por_overfill, pos_underfill, totals_to_use = "rows", max_iterations = 1000)
trip_list <- reshape2::melt(prop_matrix_balanced) %>%
    arrange(Var1, Var2)
colnames(trip_list) <- c("treso.id.por", "treso.id.pos", "trips")

# Produce the simulated ADE for each school
school_summary_20xx_iterated <- forecast_school_ade(prop_matrix, trip_list, school_master, eqao_2017, 
                                                    new_school, year_id = year_id, panel_id = panel_id,
                                                    board_id = board_id)[[1]]

# Calculate the ADE overfill for each school, so it can be removed in the summary
school_summary_ade_overfill <- school_forecast %>% 
  mutate(overfill.flag = ifelse(simulated.ade >= otg.threshold, 1, 0),
         overfill.ade = simulated.ade - otg.threshold) %>% 
  filter(overfill.flag == 1) %>% 
  select(sfis, overfill.ade)

school_summary_20xx <- full_join(school_summary_20xx, school_summary_20xx_iterated,
                                 by="sfis", suffix=c("", ".iteration")) %>% 
  replace_na(list(simulated.ade = 0, simulated.ade.iteration = 0)) %>% 
  mutate(simulated.ade = simulated.ade + simulated.ade.iteration) %>% 
  select(-simulated.ade.iteration) %>% 
  left_join(school_summary_ade_overfill, by="sfis") %>% 
  replace_na(list(overfill.ade = 0)) %>% 
  mutate(simulated.ade = simulated.ade - overfill.ade) %>% 
  select(-overfill.ade)

```

### Step 6 - Run 20xx Forecast Model with 2D constrained to the final ADE values to obtain OD pairs

```{r application of gravity model - step 6}
# Take the difference between the simulated ADEs
trip_list_schools_summary_difference <- full_join(school_summary_2017, school_summary_20xx, 
                                                  by="sfis", suffix=c(".2017", ".20xx")) %>% 
  replace_na(list(simulated.ade.2017 = 0, simulated.ade.20xx = 0)) %>% 
  mutate(change.ade = simulated.ade.20xx - simulated.ade.2017)

school_forecast_final <- school_master_2017 %>% 
  filter((status == "Open" | is.na(status)), otg != 0, ade != 0) %>% 
  filter(panel == panel_id, board_type_name == board_id) %>% 
  # Bind in list of new schools
  bind_rows(., new_school) %>% 
  full_join(select(trip_list_schools_summary_difference, sfis, simulated.ade.20xx, simulated.ade.2017, change.ade), 
            by="sfis") %>% 
  replace_na(list(ade = 0, change.ade = 0)) %>% 
  mutate(simulated.ade.raw = ade + change.ade) %>% 
  mutate(simulated.ade = ifelse(ade + change.ade < 0, 0, ade + change.ade)) %>%
  # If simulated.ade.raw < 0 for any school, this value is rounded up to 0 to prevent having a negative number of students at each school. However, by rounding up to 0, the model is adding 'phantom' students to the system, so total ADE as estimated by the distribution model will exceed total ADE estimated in population forecasts. However, in test runs, this did not occur at any schools, so risk appears low. If it were to happen, the result would be a slight increase in the total number of ADE across the province, which would almost certainly be negligible. 
  # Create OTG threshold based on user input
  mutate(otg.threshold = otg * USER_OTG_THRESHOLD) %>% 
  select(treso.id.pos, sfis, school.name, otg, otg.threshold, ade, simulated.ade)

# POR will remain the same
por <- create_por_forecast_vector(treso_forecast_population_board, por_full, 
                                      panel_id=panel_id, board_id=board_id)

# Create final POS with iterated ADE value
pos <- school_forecast_final %>% 
    anti_join(select(schools_consolidated_closed, sfis), by = c('sfis')) %>% 
    select(treso.id.pos, simulated.ade) %>%
    group_by(treso.id.pos) %>%
    summarise(simulated.ade = sum(simulated.ade)) %>%
    right_join(pos_full, by=c("treso.id.pos" = "dest")) %>%
    replace_na(list(simulated.ade = 0)) %>%
    arrange(treso.id.pos) %>%
    column_to_rownames(var = "treso.id.pos") %>%
    data.matrix()

# 2D balancing, scale the total to the POS side to determine final distribution to TRESO zones
prop_matrix_balanced <- matrix_balancing_2d(prop_matrix, por, pos, totals_to_use="columns", max_iterations = 1000)
trip_list <- reshape2::melt(prop_matrix_balanced) %>%
    arrange(Var1, Var2)
colnames(trip_list) <- c("treso.id.por", "treso.id.pos", "trips")

# Produce the simulated ADE for each school within each TRESO zone
school_summary_20xx_final <- forecast_school_ade(prop_matrix, trip_list, school_master, eqao_2017, new_school,
                                                 year_id = year_id, panel_id = panel_id, board_id = board_id)[[1]]

```

## Decision-Making Layer Calculations
### Determine which TRESO zones should be considered for new schools as a function of 'excessive' travel time and population
```{r}

if (dm == TRUE) {

# Determine potential TRESO zones in which to build schools
df_list <- edu_dm(travel_time_skim, trip_list, treso_zone_def, travel_time_threshold_factor, zone_proximity_threshold, min_tt_threshold, por_additional)

# Temporarily set OTG for proposed schools being added to zones with existing schools in order to calculate an appropriate weight factor. OTG to be set to average of existing schools in that zone.

treso_otg_avg <- school_master %>% 
  select(year, treso.id.pos, sfis, otg) %>% 
  filter(year == year_id) %>% 
  group_by(treso.id.pos) %>%
  summarise(avg.otg = round(sum(otg) / n(), 0))

new_school <- df_list[[1]] %>% 
  rename(treso.id.pos = zone) %>% 
  mutate(panel = panel_id,
         board_type_name = board_id,
         year = year_id,
         build.priority = 1:n(),
         sfis = as.numeric(paste0(treso.id.pos, '000'))) %>% 
  # Join to treso_otg_avg to pull average OTG
  left_join(treso_otg_avg, by = c('treso.id.pos')) %>% 
  rename(otg = avg.otg) %>% 
  mutate(otg = replace_na(otg, 1)) # OTG must be > 0 for some distribution functions to run

# Create list of TRESO zones ruled out from consideration due to proximity to higher-ranked zone
proximity_df <- df_list[[2]] %>% 
  anti_join(new_school, by = c('treso.id.por' = 'treso.id.pos'))

}

# Run model capacity unconstrained to see how many students choose each school, new and existing
# Create pos vector and re-run key components of Step 2
pos <- create_pos_vector(school_master, new_school, pos_full, year_id=year_id, panel_id=panel_id, board_id=board_id)

prop_matrix_balanced <- matrix_balancing_1d(prop_matrix, por, pos, axis=1, is_weight_continuous=FALSE)
trip_list <- reshape2::melt(prop_matrix_balanced) %>%
    arrange(Var1, Var2)
colnames(trip_list) <- c("treso.id.por", "treso.id.pos", "trips")

# Produce the raw simulated ADE for each school
school_summary_df_list <- forecast_school_ade(prop_matrix, trip_list, school_master, eqao_2017, new_school,
                                           year_id = year_id, panel_id = panel_id, board_id = board_id)

school_summary_20xx <- school_summary_df_list[[1]]

last_run_step <- 'Determine which TRESO zones should...'

# Run Steps 3, 4 to get adjusted simulated ADE for each school (stored under school_forecast dataframe)

# new_school_check <- new_school %>% 
#   inner_join(df_0, by = 'treso.id.pos')
```

### Delete any new schools with ADE < minimum OTG required for new school
```{r}

# Set minimum and maximum school size
school_sizes <- tibble(panel = c('Elementary', 'Secondary'), min.otg = c(200, 300), max.otg = c(1200, 1700))
min_ade <- school_sizes %>% 
  filter(panel == panel_id) %>% 
  select(min.otg) %>% 
  pull()

# Join in new school table to flag which schools are new
new_school_ade <- school_forecast %>%
  # Filter out existing schools
  filter(sfis > 99000) %>% 
  filter(simulated.ade >= min_ade)

new_school_backup <- new_school

new_school <- new_school %>% 
  right_join(select(new_school_ade, sfis), by = c('sfis'))

# Reassign ADE from deleted schools based on TRESO origin distribution propensity matrix
# Create pos vector and re-run key components of Step 2
pos <- create_pos_vector(school_master, new_school, pos_full, year_id=year_id, panel_id=panel_id, board_id=board_id)

prop_matrix_balanced <- matrix_balancing_1d(prop_matrix, por, pos, axis=1, is_weight_continuous=FALSE)
trip_list <- reshape2::melt(prop_matrix_balanced) %>%
    arrange(Var1, Var2)
colnames(trip_list) <- c("treso.id.por", "treso.id.pos", "trips")

# Produce the raw simulated ADE for each school
school_summary_df_list <- forecast_school_ade(prop_matrix, trip_list, school_master, eqao_2017, new_school,
                                           year_id = year_id, panel_id = panel_id, board_id = board_id)

school_summary_20xx <- school_summary_df_list[[1]]

last_run_step <- 'Delete new schools with ADE <...'

# Run Steps 3, 4 to get adjusted simulated ADE for each school (stored under school_forecast dataframe)

```

### Consolidate existing schools
    - Running this component is optional
    - Delete any existing schools with utilization < utilization_threshold
    - Reassign ADE from deleted schools based on TRESO origin distribution propensity matrix

```{r}

# Check utilization of existing schools; flag underutilized schools for consolidation
existing_school_utilization <- school_master %>% 
  filter(year == year_id, panel == panel_id, board_type_name == board_id) %>% 
  left_join(select(school_forecast, sfis, simulated.ade), by = c('sfis')) %>% 
  mutate(simulated.utilization = simulated.ade / otg) %>% 
  mutate(underused.flag = ifelse(simulated.utilization < consolidation_threshold, 1, 0)) 

# Dataframe containing schools not consolidated as per step above
schools_kept <- existing_school_utilization %>% 
  filter(underused.flag == 0)

# Create a list of all schools closed by scenario year (as projected in EDU data) plus schools consolidated by decision-making layer
schools_consolidated <- existing_school_utilization %>% 
  filter(underused.flag == 1) 

schools_consolidated_closed <- schools_consolidated %>% 
  full_join(select(schools_closed, sfis), by = c('sfis'))

# Remove existing schools from school_master which fall below utilization threshold
school_master_backup <- school_master
school_master <- schools_kept

# Create pos vector and re-run key components of Step 2
pos <- create_pos_vector(school_master, new_school, pos_full, year_id=year_id, panel_id=panel_id, board_id=board_id)

prop_matrix_balanced <- matrix_balancing_1d(prop_matrix, por, pos, axis=1, is_weight_continuous=FALSE)
trip_list <- reshape2::melt(prop_matrix_balanced) %>%
    arrange(Var1, Var2)
colnames(trip_list) <- c("treso.id.por", "treso.id.pos", "trips")

# Produce the raw simulated ADE for each school
school_summary_df_list <- forecast_school_ade(prop_matrix, trip_list, school_master, eqao_2017, new_school,
                                           year_id = year_id, panel_id = panel_id, board_id = board_id)

school_summary_20xx <- school_summary_df_list[[1]]

last_run_step <- 'Consolidate existing schools'

# Run Steps 3, 4 to get adjusted simulated ADE for each school

```

###	Set OTG at new schools to be a function of unconstrained ADE plus OTG from consolidated schools in the CSD

```{r}
new_school_ade <- school_forecast %>%
  # Filter out existing schools
  filter(sfis > 99000) %>% 
  filter(simulated.ade >= min_ade)

# Determine OTG consolidated by CSD for consolidated schools
schools_consolidated_closed_otg <- schools_consolidated_closed %>%
  group_by(csduid) %>% 
  mutate(csd.otg = sum(otg) * consolidation_threshold) %>% 
  ungroup()

# Provide backup copy of new_school
new_school_backup2 <- new_school

# Revise list of new schools to have only the previously identified new schools which exceed the minimum ADE threshold
new_school <- new_school %>% 
  right_join(select(new_school_ade, sfis, simulated.ade), by = c('sfis')) %>% 
  mutate(otg = 1.05*simulated.ade) %>% 
  # Revise OTG of new schools to account for OTG closed by consolidating existing schools in the CSD
  left_join(select(treso_zone_def, treso_id, csduid), by = c('treso.id.pos' = 'treso_id')) %>% 
  left_join(distinct(schools_consolidated_closed_otg, csduid, csd.otg), by = c('csduid')) %>% 
  mutate(csd.otg = replace_na(csd.otg, 0)) %>% 
  group_by(csduid) %>% 
  mutate(additional.otg.percent = simulated.ade / sum(simulated.ade),
         additional.otg = additional.otg.percent * csd.otg,
         revised.otg = round(otg + additional.otg)) %>% 
  ungroup() %>% 
  select(-otg) %>% 
  rename(otg = revised.otg)

last_run_step <- 'Set OTG at new schools...'

```

###	Run capacity constrained to forecast ADE by school for all schools (new and existing)

```{r}
# Reassign ADE from deleted schools based on TRESO origin distribution propensity matrix
# Create pos vector and re-run key components of Step 2 below
pos <- create_pos_vector(school_master, new_school, pos_full, year_id=year_id, panel_id=panel_id, board_id=board_id)

prop_matrix_balanced <- matrix_balancing_1d(prop_matrix, por, pos, axis=1, is_weight_continuous=FALSE)
trip_list <- reshape2::melt(prop_matrix_balanced) %>%
    arrange(Var1, Var2)
colnames(trip_list) <- c("treso.id.por", "treso.id.pos", "trips")

# Produce the raw simulated ADE for each school
school_summary_df_list <- forecast_school_ade(prop_matrix, trip_list, school_master, eqao_2017, new_school,
                                           year_id = year_id, panel_id = panel_id, board_id = board_id)

school_summary_20xx <- school_summary_df_list[[1]]

last_run_step <- 'Run capacity constrained...'

# Rerun steps 3, 4, 5, 6

```

### 'Unconsolidate' schools which preclude long travel times
- If travel times > acceptable travel times for any zone, see if an existing school has been consolidated from the zone, in which case, reinstate

```{r}
# Rerun components of DM calculation to figure out average travel times / travel times by zone, see if they exceed acceptable tolerances

# Start by finding zones with schools which were eliminated due to under-utilization, and keep the largest consolidated school from zones with consolidated schools
# zones_consolidated <- schools_consolidated %>% 
#   group_by(treso.id.pos) %>% 
#   arrange(desc(otg)) %>% 
#   mutate(school.count = 1:n()) %>% 
#   ungroup() %>% 

# Filter trip list down to include only zones which have more than 10 trips to a destination zone AND have long trips
trip_length_check <- cbind(trip_list, travel_time_skim) %>%
  rename(travel.time = value) %>%
  filter(travel.time > 60) %>% 
  filter(trips > 1) %>% 
  group_by(treso.id.por) %>% 
  mutate(total.por.trips = sum(trips)) %>% 
  ungroup() %>% 
  filter(total.por.trips > 10) %>% 
  left_join(select(treso_zone_def, treso_id, treso.por.csduid = csduid, treso.por.cduid = cduid), by = c('treso.id.por' = 'treso_id')) %>% 
   select(-orig, -dest)

# Unconsolidate schools in origin TRESO zones which have long tavel times
unconsolidate_treso_por <- trip_length_check %>% 
  inner_join(schools_consolidated, by = c('treso.id.por' = 'treso.id.pos')) %>%
  mutate(time.critical.flag = 1)
  
# Unconsolidate schools in destination TRESO zones which have long travel times
unconsolidate_treso_pos <- trip_length_check %>% 
  inner_join(schools_consolidated, by = c('treso.id.pos')) %>%
  mutate(time.critical.flag = 1) %>% 
  anti_join(unconsolidate_treso_por, by = c('sfis'))

 # left_join(select(treso_zone_def, treso_id, treso.pos.csduid = csduid, treso.pos.cduid = cduid), by = c('treso.id.pos' = 'treso_id')) %>% 
  # select(-orig, -dest) %>% 
  # inner_join(schools_consolidated, by = c('treso.id.por' = 'treso.id.pos')) %>%
  # rename(treso.id.pos = treso.id.por) %>% 
  # mutate(time.critical.flag = 1)

# Redefine school_master to include existing schools which are in zones with otherwise high travel times
school_master_backup <- school_master
school_master <- school_master %>% 
  filter(year == year_id, panel == panel_id, board_type_name == board_id) %>% 
  select(-simulated.ade) %>% 
  left_join(select(school_forecast, sfis, simulated.ade), by = c('sfis')) %>% 
  mutate(simulated.utilization = simulated.ade / otg) %>% 
  left_join(select(trip_length_check, treso.id.pos, time.critical.flag), by = c('sfis')) %>% 
  mutate(underused.flag = ifelse(simulated.utilization < consolidation_threshold & time.critical.flag == 0, 1, 0)) %>% 
  filter

# Rerun Steps 3, 4, 5, 6

last_run_step <- 'Uncosolidate schools'

```


16. If travel times > acceptable travel times for any zone, see if an existing school has been consolidated from a zone within, say, 40 minutes of the zone with unacccepable travel times, reinstate the closest school

17.	Rerun model capacity constrained to forecast ADE by school for all schools (new and existing)

## Summary of Education Dataset

- Plot a chart showing the average utilization per DSB and board type.

```{r school utilization}
g <- school_sfis_2017 %>%
  left_join(school_board_def, by = c("dsb.index" = "dsb")) %>%
  group_by(dsb.index, panel) %>%
  summarise(
    utilization = mean(utilization),
    board_type_name = first(board_type_name)
  ) %>%
  ggplot(aes(x = dsb.index, y = utilization, fill = board_type_name)) +
  geom_col(position = "dodge") +
  labs(x = "DSB", y = "Average Utilization", fill = "Board Type") +
  theme_minimal()

g <- ggplotly(g)
g
```

- Plot a map of the entire dataset with students and schools

```{r plotting shapefiles, echo = FALSE}
student_xy <- create_student_xy(student_travel_90)
school_xy <- create_school_xy(student_travel_90)

# Convert the SpatialDataframe to normal Dataframe for ggplot()
treso_shp_df <- fortify(treso_shp) %>%
  rename(
    x = long,
    y = lat
  )

school_xy_df <- data.frame(school_xy) %>%
  rename(
    x = long,
    y = lat
  )

student_xy_df <- data.frame(student_xy) %>%
  rename(
    x = long,
    y = lat
  )

ggplot() +
  geom_polygon(data = treso_shp_df, mapping = aes(x = x, y = y, group = group),
               fill = "grey40", color = "grey90", alpha = 1, size = 0.1) +
  geom_point(data = student_xy_df, mapping = aes(x = x, y = y), color = "red", alpha = 0.1, size = 0.01) +
  geom_point(data = school_xy_df, mapping = aes(x = x, y = y), color = "blue", alpha = 0.1, size = 0.01, shape = 2) +
  labs(x = "", y = "", title = "Students and schools in Ontario") +
  theme(axis.ticks.y = element_blank(), axis.text.y = element_blank(),
        axis.ticks.x = element_blank(), axis.text.x = element_blank(),
        plot.title = element_text(lineheight = 0.8, face = "bold", vjust = 1)) +
  coord_equal(ratio = 1)

# Clean up the global environments
rm(school_xy_df, treso_shp_df, student_xy_df)
```

## Obtain socio-economic data for each school

- Loop and do the following for all catchment distances available
- Using `over()` to determine the treso zone number for each student/school point
- Using `gbuffer()` to determine the treso zones that catchment distance touches for each school
- Setting up the multi-core to do `foreach()` loop is worth it once you are doing more than 100 fields
- Combine the the datalist of buffered TRESO zones with the tibble containing socio-economic data
- Combine with the historical ADE and utilization data by school

```{r spatial gymnastics, eval = FALSE}
percentile_dist <- c("90", "80", "70", "60", "50")

for (dist in percentile_dist) {

  # Loop through the different catchment areas by retriving the proper variable.
  student_travel <- get(paste0("student_travel_", dist))

  # Spatial transformation to XY
  student_xy <- create_student_xy(student_travel)
  school_xy <- create_school_xy(student_travel)

  # Create the overlays to get the TRESO zone each XY coordinate falls on
  student_overlay <- create_overlay(student_xy, treso_shp, "student")
  saveRDS(student_overlay, paste0("cache/edu/student_overlay_", dist, ".rds"))
  school_overlay <- create_overlay(school_xy, treso_shp, "school")

  # Join the POR and POS together for distance matrix
  observed_por_pos <- left_join(student_overlay, school_overlay, by = c("school.name", "sfis")) %>%
    saveRDS(paste0("output/edu/observed_por_pos_", dist, ".rds"))

  # Save the zones in each school's catchment area
  buffered_df <- buffer_zones(school_xy, treso_shp)

  # Combine the school's buffered TRESO zones with socio-economic info and group_by school name
  school_tb <- summarize_buffered_zones(buffered_df, treso_tb, school_sfis_2017, school_board_def, treso_zone_def) %>%
    saveRDS(paste0("cache/edu/school_tb_", dist, ".rds"))
}
```

- Test that `gBuffer()` is returning intended results.

```{r test buffer, eval = FALSE, echo = FALSE}
# Select a specific buffer
school_of_interest <- "Holy Trinity CSS"
student_travel <- get("student_travel_90")
student_xy <- create_student_xy(student_travel)
school_xy <- create_school_xy(student_travel)
buffered_points <- gBuffer(school_xy, width = school_xy@data$catchment.dist * 1000, byid = TRUE)
buffer <- buffered_points[buffered_points@data$school.name == school_of_interest, ]

# Get all TRESO zones that touches the buffer with over(), gIntersect() could be another solution
treso_overlay <- over(treso_shp, buffer, returnList = FALSE) %>%
  cbind(treso.id = treso_shp@data$Treso_ID,
        households = treso_shp@data$TotHH,
        persons = treso_shp@data$TotPers) %>%
  as_tibble() %>%
  select(school.name, sfis, dsb.index, catchment.dist, treso.id, households, persons) %>%
  drop_na()

# Select the TRESO zones of interest
treso_zones_interest <- treso_shp[is.element(treso_shp@data$Treso_ID, treso_overlay$treso.id), ] %>%
  fortify() %>%
  rename(
    x = long,
    y = lat
  )

interst_zones <- treso_overlay

# Convert buffer into df
buffer_df <- fortify(buffer) %>%
  rename(
    x = long,
    y = lat
  )

school_xy_df <- data.frame(school_xy) %>%
  rename(
    x = long,
    y = lat
  )

# Plot the school, buffer and the selected TRESO zones
ggplot() +
  geom_polygon(data = treso_zones_interest, mapping = aes(x = x, y = y, group = group),
               fill = "grey40", color = "grey90", alpha = 1, size = 0.1) +
  geom_polygon(data = buffer_df, mapping = aes(x = x, y = y, group = group),
               fill = "red", color = "red", alpha = 0.5) +
  geom_point(data = filter(school_xy_df, school.name == school_of_interest), mapping = aes(x = x, y = y),
               fill = "blue", alpha = 0.5, size = 10) +
  labs(x = "", y = "", title = "Test Buffer") +
  theme(plot.title = element_text(lineheight = 0.8, face = "bold", vjust = 1)) +
  coord_equal(ratio = 1)

# Clean up global environment variables
rm(school_of_interest, buffer, treso_overlay, treso_zones_interest, buffer_df, school_xy_df)
```

## Closest School Theory

- From `student_travel_90`, obtain the travel distance to create a buffer for each student
- Build a buffer with the travel distance and capture any school within that buffer
- Make sure the school is from `school_sfis`
- Calculate the distance to all the schools within its travel distance buffer
  - if no school exist then this student is travelling to closest (1)
  - if there are schools within this buffer, then the label a value equal in rank (>=2)

```{r calculate closest school, eval = FALSE, echo = FALSE}
student_xy_90 <- student_travel_90 %>%
  select(sfis, bsid, school.name, school.lat, school.long, dsb.index, panel, 
         enrolment, student.postal.code, student.lat, student.long, dist, man.dist) %>%
  create_student_xy()
school_xy <- create_school_xy(student_travel_90)

student_buffered <- gBuffer(student_xy_90, width = (student_xy_90@data$manhattan.dist * 1000 + 25), byid = TRUE)

  # Start multi-core clustering for performance
  cores <- parallel::detectCores()
  cl <- parallel::makeCluster(cores[1] - 1)
  registerDoParallel(cl)
  
  # Progress bar
  registerDoSNOW(cl)
  pb <- txtProgressBar(max = nrow(student_buffered@data), style = 3)
  progress <- function(n) setTxtProgressBar(pb, n)
  opts <- list(progress = progress)
  
  tic("using sp::over")
  # foreach() loop to find the TRESO zones touching the school buffers
  datalist <- list()
  datalist <- foreach(i = 1:nrow(student_buffered@data), .combine = rbind,
                  .options.snow = opts, .packages=c("sp", "tidyverse", "rgeos")) %dopar% {
    # Select the buffer
    buffer <- student_buffered[student_buffered@data$id == i, ]
    
    #Get all schools that touches the buffer with over()
    school_overlay <- over(school_xy, buffer, returnList = FALSE) %>%
        cbind(overlay.school.name = school_xy@data$school.name,
              overlay.dsb.index = school_xy@data$dsb.index,
              overlay.sfis = school_xy@data$sfis,
              overlay.panel = school_xy@data$panel,
              overlay.coords = school_xy@coords) %>%
        as_tibble() %>%
        drop_na()
    
    # Save each tibble in a list of tibbles
    datalist[[i]] <- school_overlay
  }
  toc()
  close(pb)
  stopCluster(cl)
  
  # Write the datalist to csv
  saveRDS(datalist, "output/edu/closest_school_full_manhattan_distance.rds")
  rm(student_xy_90, student_buffered, datalist)
```

``` {r test closest school, echo = FALSE, eval = FALSE}
TESTID <- 523550
datalist <- readRDS("output/edu/closest_school_full_manhattan_distance.rds")
# Convert buffer into df
buffer_df <- fortify(student_buffered[student_buffered@data$id == TESTID, ]) %>%
  rename(
    x = long, 
    y = lat
  )

student_interest_df <- student_xy_90[is.element(student_xy_90@data$id, TESTID), ] %>%
  data.frame() %>%
  rename(
    x = long,
    y = lat
  )

# Select the schools of interest that exist in the 
school_interest_df <- school_xy[is.element(school_xy@data$sfis, filter(datalist, id == TESTID)$overlay.sfis), ] %>%
  data.frame() %>%
  rename(
    x = long, 
    y = lat
  )

ggplot() +
  geom_point(data = filter(student_interest_df, id == TESTID), mapping = aes(x = x, y = y), 
               color = "blue", fill = "blue", alpha = 1, size = 3) +
  geom_point(data = school_interest_df, mapping = aes(x = x, y = y), 
               color = "green", fill = "green", alpha = 1, size = 3) +
  geom_text(data = school_interest_df, aes(x = x, y = y, label = school.name), size = 2) +
  geom_polygon(data = buffer_df, mapping = aes(x = x, y = y, group = group),
               fill = "red", color = "red", alpha = 0.01) +
  labs(x = "", y = "", title = "Test Buffer") +
  theme(plot.title = element_text(lineheight = 0.8, face = "bold", vjust = 1)) +
  coord_equal(ratio = 1)

rm(buffer_df, student_interest_df, school_interest_df)

```

```{r closest school results, echo = FALSE}
por_mof <- readRDS("output/edu/observed_por_pos_90.rds") %>%
  select(treso.id.por, student.postal.code) %>%
  mutate(student.postal.code = as.character(student.postal.code)) %>%
  distinct(student.postal.code, .keep_all=TRUE) %>%
  left_join(select(treso_zone_def, treso_id, csdname, mof_region), by = c("treso.id.por" = "treso_id"))

closest_school <- readRDS("output/edu/closest_school_full_manhattan_distance.rds") %>%
  left_join(select(school_board_def, dsb, board_type, board_type_name), by = c("dsb.index" = "dsb")) %>%
  rename(board.type = board_type, board.type.name = board_type_name) %>%
  left_join(select(school_board_def, dsb, board_type, board_type_name), by = c("overlay.dsb.index" = "dsb")) %>%
  rename(overlay.board.type = board_type, overlay.board.type.name = board_type_name) %>% 
  filter(panel == as.character(overlay.panel), board.type == overlay.board.type) %>%
  left_join(por_mof, by = "student.postal.code")

closest_school_summary <- closest_school %>%
  group_by(id) %>%
  summarise(
    euclidean.dist = first(euclidean.dist),
    school.name = first(school.name),
    sfis = first(sfis),
    dsb.index = first(dsb.index),
    panel = first(panel),
    enrolment = first(enrolment),
    student.postal.code = first(student.postal.code),
    board.type = first(board.type),
    board.type.name = first(board.type.name),
    mof_region = first(mof_region),
    csdname = first(csdname),
    num.closer.schools = n()
    )

 closest_school_subtotal <- closest_school_summary %>%
   group_by(board.type.name, panel, mof_region, csdname) %>%
   summarise(
     total.students = sum(enrolment)
   )

 closest_school_summary <- closest_school_summary %>%
   mutate(num.closer.schools.cuts = cut(num.closer.schools, c(0, 1, 2, 3, 4, Inf), labels = c("1", "2", "3", "4", "5+"))) %>%
   group_by(num.closer.schools.cuts, board.type.name, panel, mof_region, csdname) %>%
   summarise(
     num.students = sum(enrolment)
   ) %>%
   left_join(closest_school_subtotal, by = c("board.type.name", "panel", "mof_region", "csdname")) %>%
   mutate(percentage = num.students / total.students) %>%
   mutate(percentage.lable = ifelse(percentage > 0.10, as.character(percent(percentage)), "")) %>%
   saveRDS("output/edu/closest_school_manhattan_summary.rds")

rm(closest_school, closest_school_summary)
```

```{r plot closest school results, fig.height = 12, fig.width = 10, echo=FALSE}
g_subtotal <- readRDS("output/edu/closest_school_manhattan_summary.rds") %>%
  drop_na(mof_region) %>%
  group_by(board.type.name, panel, mof_region) %>%
    summarise(
      total.students = sum(num.students)
    )

g <- readRDS("output/edu/closest_school_manhattan_summary.rds") %>%
  drop_na(mof_region) %>%
  group_by(num.closer.schools.cuts, board.type.name, panel, mof_region) %>%
    summarise(
      num.students = sum(num.students)
    ) %>%
  left_join(g_subtotal, by = c("board.type.name", "panel", "mof_region")) %>%
  mutate(percentage = num.students / total.students) %>%
  mutate(segmentation = paste0(panel, "_", board.type.name, "_", mof_region)) %>%
  ggplot(aes(x = "", y = percentage, fill = num.closer.schools.cuts)) +
  geom_bar(width = 1, stat = "identity", position = "dodge") +
  facet_wrap(vars(segmentation), scales = "free_y") +
  theme_minimal() +
  theme(axis.text.x = element_blank()) +
  labs(x = "", y = "", fill = "Schools within travel distance") +
  ggsave("output/edu/closest_school_manhattan_summary.png", height = 12, width = 10, units = "in")

ggplotly(g)

rm(g, g_subtotal)
```

## Travel Time TLFD plots

### Intra-zonal travel time assumptions

The TLFD estimation has some assumptions made for intra-zonal travel times and extremely large travel times.

- The intra-zonal travel times from TRESO is 0, this requires some extra work to take care of.
- Assumptions made are the following:
  - Known intra-zonal trips which are less than or equal to 2.5 km in length are performed by walking at an average speed of 5 km/hr. 
  - Known intra-zonal trips more than 2.5 km in length are performed by driving at an average speed of 30 km/hr.
  - Extremely long inter-zonal travel times (greater than 30 min difference between travel time skim and euclidean travel time at 30 km/hr) are set to euclidean travel time.
  - Leaving unknown intra-zonal travel time to be estimated from the size of the TRESO shapefile. Four levels of TRESO sizes are determined from quantile calculation. Level 1 and 2 sized shapes are assumed to have a distance that is the square root of its area to be traversed at 15 km/hr. Level 2 and 3 sized shapes are assumed to have a distance that is the square root of its area to be traversed at 60 km/hr.

```{r create travel time master list, echo=FALSE, eval=FALSE}
# The reason for creating a master list is to save time computation time on left_join()
travel_time <- readRDS("output/edu/observed_por_pos_90.rds") %>%
  drop_na(treso.id.por) %>%
  group_by(treso.id.por, treso.id.pos) %>%
  summarise(euclidean.dist = weighted.mean(euclidean.dist, enrolment)) %>%
  ungroup() %>%
  right_join(travel_time_skim, by = c("treso.id.por" = "orig", "treso.id.pos" = "dest")) %>%
  rename(travel.time = value)

summary(travel_time$travel.time)

treso_area <- treso_shp@data %>%
  select(treso.id = Treso_ID, area = Area) %>%
  mutate(area.km = area / 1000000) %>%
  mutate(length = sqrt(area.km))
treso_area_quantile <- quantile(treso_area$area.km)

print(paste0("Zones with an area between ", round(treso_area_quantile[4][[1]], 2), " - ",
             round(treso_area_quantile[5][[1]], 2), " km^2 are categorized as extra large."))
print(paste0("Zones with an area between ", round(treso_area_quantile[3][[1]], 2), " - ",
             round(treso_area_quantile[4][[1]], 2), " km^2 are categorized as large."))
print(paste0("Zones with an area between ", round(treso_area_quantile[2][[1]], 2), " - ",
             round(treso_area_quantile[3][[1]], 2), " km^2 are categorized as medium"))
print(paste0("Zones with an area between ", round(treso_area_quantile[1][[1]], 2), " - ",
             round(treso_area_quantile[2][[1]], 2), " km^2 are categorized as small"))

treso_intrazonal_travel_time <- treso_area %>%
  mutate(size.category = "extra large") %>% 
  mutate(size.category = ifelse(area.km <= treso_area_quantile[4][[1]], "large", size.category)) %>% 
  mutate(size.category = ifelse(area.km <= treso_area_quantile[3][[1]], "medium", size.category)) %>%
  mutate(size.category = ifelse(area.km <= treso_area_quantile[2][[1]], "small", size.category)) %>% 
  mutate(intra.zonal.travel.time = ifelse(size.category %in% c("extra large", "large"), length / 60 * 60, length / 15 * 60))

travel_time1 <- travel_time %>%
  mutate(euclidean.travel.time = ifelse(euclidean.dist <= 2.5,
                                        euclidean.dist / 5 * 60,
                                        euclidean.dist / 30 * 60)) %>%
  mutate(travel.time = ifelse((travel.time == 0 & !is.na(euclidean.travel.time)), 
                              euclidean.travel.time, 
                              travel.time)) %>%
  mutate(compare.travel.time = travel.time - euclidean.travel.time) %>%
  mutate(travel.time = ifelse((compare.travel.time > 30 & !is.na(compare.travel.time)), 
                              euclidean.travel.time, 
                              travel.time)) %>%
  left_join(treso_intrazonal_travel_time, by=c("treso.id.pos"="treso.id")) %>%
  mutate(travel.time = ifelse((travel.time == 0 & treso.id.por == treso.id.pos), 
                              intra.zonal.travel.time,
                              travel.time)) %>%
  select(treso.id.por, treso.id.pos, value = travel.time) %>%
  arrange(treso.id.por, treso.id.pos)

saveRDS(travel_time1, "output/treso/treso_travel_time.rds")
```

### 90th Percentile plots

```{r tlfd plots for 90th percentile, fig.width = 10, fig.height = 28, echo = FALSE}
treso_travel_time <- readRDS("output/treso/treso_travel_time.rds")
student_tlfd_90 <- readRDS("output/edu/observed_por_pos_90.rds") %>%
  # Drop NAs in POR, it didn't overlay on the TRESO shapefile
  drop_na(treso.id.por) %>%
  # Get the travel time skims
  left_join(treso_travel_time, by = c("treso.id.por", "treso.id.pos")) %>%
  rename(travel.time = value) %>%
  # Get the school board type names
  left_join(select(school_board_def, dsb, board_type_name), by = c("dsb.index" = "dsb")) %>%
  # Get the MOF regions
  left_join(select(treso_zone_def, treso_id, area, mof_region), by = c("treso.id.por" = "treso_id")) %>%
  # Get the panel information
  left_join(select(school_sfis_2017, sfis, panel), by = "sfis") %>%
  # expand the rows based on enrollment number
  uncount(enrolment)

summary(student_tlfd_90$travel.time)

ggsave(file = "output/edu/tlfd_90th_percentile.png", plot_travel_time_tlfd(student_tlfd_90), height = 28, width = 10)
g <- plot_travel_time_tlfd(student_tlfd_90)
plot(g)
```

```{r export travel time in 2017, include = FALSE}
treso_travel_time <- readRDS("output/treso/treso_travel_time.rds")
school_travel_time <- readRDS("output/edu/observed_por_pos_90.rds") %>% 
  drop_na(treso.id.por) %>%
  left_join(treso_travel_time, by = c("treso.id.por", "treso.id.pos")) %>%
  rename(travel.time = value) %>%
  group_by(sfis) %>% 
  summarise(avg.travel.time = weighted.mean(travel.time, enrolment),
            avg.travel.dist = weighted.mean(manhattan.dist, enrolment))

saveRDS(school_travel_time, "output/edu/school_travel_2017.rds")
```


## Exploration of demand modelling methods {.tabset .tabset-fade}

### Linear Regressions

- Segment the schools by board (at least)
- Build linear regression 
- Explore other segmentations

```{r data exploration, echo=FALSE}
school_tb <- readRDS("cache/edu/school_tb_90.rds") %>%
  mutate(shape.area_sum = shape.area_sum / 1e6) %>%
  mutate(n_pop_density = n_pop_sum / shape.area_sum) %>%
  mutate(n_sec_pop_density = n_sec_pop_sum / shape.area_sum) %>%
  mutate(n_ele_pop_density = n_ele_pop_sum / shape.area_sum)

summary(school_tb$ade)

g1 <- ggplot(filter(school_tb, panel == "Secondary"), aes(x = ade)) +
  geom_histogram(bins = 50) +
  facet_grid(rows = vars(mof.region), cols = vars(board.type.name), scales = "free") +
  theme_minimal() +
  labs(x = "ADE", y = "Count")

g2 <- ggplot(filter(school_tb, panel == "Secondary"), aes(x = catchment.dist, y = ade, label = school.name.x)) +
  geom_point(alpha = 0.5) +
  facet_grid(rows = vars(mof.region), cols = vars(board.type.name), scales = "free") +
  theme_minimal() +
  labs(x = "Catchment Distance", y = "ADE")

g3 <- ggplot(filter(school_tb, panel == "Secondary", mof.region == "GTA"), aes(x = n_sec_pop_density, y = ade, label = school.name.x)) +
  geom_point(alpha = 0.5) +
  facet_grid(rows = vars(mof.region), cols = vars(board.type.name), scales = "free") +
  theme_minimal() +
  labs(x = "Secondary Population Density", y = "ADE")

g4 <- ggplot(filter(school_tb, panel == "Secondary"), aes(x = attend_school_sum, y = ade, label=school.name.x)) +
  geom_point(alpha = 0.5) +
  facet_grid(rows = vars(mof.region), cols = vars(board.type.name), scales = "free") +
  theme_minimal() +
  labs(x = "Attend School", y = "ADE")


ggplotly(g1)
ggplotly(g2)
ggplotly(g3)
ggplotly(g4)

```

```{r linear regression, eval = FALSE, echo = FALSE}

# Choose the catchment area to explore
school_tb <- readRDS("cache/edu/school_tb_80.rds")

# Join with EQAO Scores
school_tb <- left_join(school_tb, select(eqao_2017, sfis, eqao.standardized), by = "sfis")

# Filter the school database down
school_tb_filtered <- filter(school_tb, panel == "Elementary", board.type.name == "English Public", eqao.standardized != 0, utilization < 1.5)

# Display schools that has captured a large area and their 2011 ADE
school_tb_filtered %>%
  arrange(desc(utilization)) %>%
  select(school.name.x, utilization, ade)


student_tlfd_90_dist <- readRDS("output/edu/observed_por_pos_90.rds") %>%
  drop_na(treso.id.por) %>%
  left_join(travel_time_skim, by = c("treso.id.por" = "orig", "treso.id.pos" = "dest")) %>%
  rename(travel.time = value) %>%
  left_join(select(school_board_def, dsb, board_type_name), by = c("dsb.index" = "dsb")) %>%
  left_join(select(treso_zone_def, treso_id, area, mof_region), by = c("treso.id.por" = "treso_id")) %>%
  left_join(select(school_sfis_2017, sfis, panel), by = "sfis") %>%
  uncount(enrolment)%>%
  mutate(euclidean.travel.time = ifelse(euclidean.dist <= 2.5,
                                        euclidean.dist / 5 * 60,
                                        euclidean.dist / 30 * 60)) %>%
  mutate(travel.time = ifelse(travel.time == 0,
                              euclidean.travel.time,
                              travel.time)) %>%
  mutate(compare.travel.time = travel.time - euclidean.travel.time) %>%
  mutate(travel.time = ifelse(compare.travel.time > 30,
                              euclidean.travel.time,
                              travel.time)) %>%
  group_by(sfis) %>%
  summarise(average.travel.time = mean(travel.time)) 

school_tb_filtered <- left_join(school_tb_filtered, student_tlfd_90_dist, by = "sfis")

# Build linear regression dataset with various transformed x, y variables
linreg <- school_tb_filtered %>%
  select(ade, utilization, eqao.standardized, starts_with("n_"), starts_with("occu_"), starts_with("deg_"), attend_school_sum, shape.area_sum, mean.income, mean.age, average.travel.time) %>%
  mutate(shape.area_sum = shape.area_sum / 1e6) %>%
  mutate(n_pop_density = n_pop_sum / shape.area_sum) %>%
  mutate(n_sec_pop_density = n_sec_pop_sum / shape.area_sum) %>%
  mutate(n_ele_pop_density = n_ele_pop_sum / shape.area_sum) %>%
  mutate(n_two_adult_two_child_density = n_two_adult_two_child_sum / shape.area_sum) %>%
  mutate(n_two_adult_one_child_density = n_two_adult_one_child_sum / shape.area_sum) %>%
  mutate_all(
    funs(ln = log1p(.), sqrt = sqrt(.), sq = .^2)
  ) %>%
  mutate(dummy_large_pop = ifelse(n_pop_sum >= 10e+4, 1, 0)) %>%
  bind_cols(select(school_tb_filtered, sfis, school.name.x))


linreg <- linreg %>%
  select(ade, school.name.x, sfis, average.travel.time, utilization, n_pop_density, eqao.standardized) %>%
  filter(ade < 100)

# Exploring the data relationships
ggplot(linreg, aes(y = utilization, x = attend_school_sum)) +
  geom_point(alpha = 0.5, color = "#F8766D")

# Fully segment the data
linreg_small <- linreg %>%
  filter(n_sec_pop_density_sqrt < 5)
linreg_large <- linreg %>%
  filter(n_sec_pop_density_sqrt >= 5)

# Build models
mod.small <- lm(utilization ~  eqao.standardized, data = linreg_small)
summary(mod.small)
#plot(mod.small)
mod.large <- lm(utilization ~ eqao.standardized, data = linreg_large)
summary(mod.large)
#plot(mod.large)
mod <- lm(ade ~ average.travel.time + n_pop_density, data = linreg)
summary(mod)
plot(mod)
  
# mod.base <- lm(ade_2011 ~ n_sec_pop_sum_sqrt, data = linreg)
# mod.expand <- lm(ade_2011 ~ n_sec_pop_sum_sqrt + n_ele_pop_sum_sqrt, data = linreg)
# anova(mod.base, mod.expand)
# 
# summary(mod.base)
# summary(mod.expand)
# plot(mod.expand)
```

### Gravity model

- Implement sampling procedure
  - Create sampling proportions of stduent board type at the CSD level
  - For each TRESO zone, calculate the students of each board type by applying the sampling proportions
- Calibrate cost functions
  - For each board type, calibrate a cost function that matches the observed TLFD
- Distribution
  - 1D distribute the observed POR to POS using the calibrated cost fuction and OTG as weights
  - Then for each POS, if there are multiple schools further distribute to the individual schools based on EQAO
  - Re-check the distribution with observation and the closest school theory
- There are two versions, one is contrained by capacity and another that doesn't have capacity constrains

The board type sampling proportions are calculated at the CSD level and applied at TRESO level.
  
```{r sampling board type, echo=FALSE, fig.width=10, fig.height=8}
observed_por_pos_90 <- readRDS("output/edu/observed_por_pos_90.rds") %>%
  select(treso.id.por, treso.id.pos, school.name, sfis, enrolment, dsb.index) %>%
  drop_na(treso.id.por) %>%
  left_join(select(school_board_def, dsb, board_type_name), by = c("dsb.index" = "dsb")) %>%
  left_join(select(treso_zone_def, treso_id, csduid, csdname, mof_region), by = c("treso.id.por" = "treso_id")) %>%
  left_join(select(school_sfis_2017, sfis, panel), by = c("sfis"))

# Calculate the board type sample for each CSD
board_type_sample <- observed_por_pos_90 %>%
  group_by(csduid, csdname, board_type_name, panel) %>%
  summarise(enrolment.total = sum(enrolment), mof_region = first(mof_region)) %>%
  group_by(csduid, csdname, panel) %>%
  mutate(sample = enrolment.total / sum(enrolment.total))

g1 <- board_type_sample %>%
  mutate(csduid.prefix = str_trunc(csduid, 4, side="right", ellipsis = "")) %>%
  group_by(csduid.prefix, board_type_name, panel) %>%
  summarise(sample = mean(sample), mof_region = first(mof_region)) %>%
  ggplot(aes(x = csduid.prefix, y = sample, fill = board_type_name)) +
  geom_col(position="stack") +
  facet_grid(cols = vars(panel), rows = vars(mof_region), scales = "free_y") +
  theme_minimal() +
  labs(title = "Average Board Type Sample at CD Level", x = "CD", y = "Porportions", fill = "Board Type")

ggplotly(g1)

elementary_board_type_sample_spread <- board_type_sample %>%
  filter(panel == "Elementary") %>%
  spread(key = board_type_name, value = sample) %>%
  replace_na(list(`English Catholic` = 0, `French Catholic` = 0, `English Public` = 0, `French Public` = 0)) %>%
  group_by(csduid, csdname) %>%
  summarise(
    panel = first(panel),
    enrolment.total = sum(enrolment.total),
    `English Catholic` = sum(`English Catholic`, na.rm = TRUE),
    `English Public` = sum(`English Public`, na.rm = TRUE),
    `French Catholic` = sum(`French Catholic`, na.rm = TRUE),
    `French Public` = sum(`French Public`, na.rm = TRUE)
  ) %>%
  mutate(sample.total = sum(`English Catholic`, `English Public`, `French Catholic`, `French Public`))

secondary_board_type_sample_spread <- board_type_sample %>%
  filter(panel == "Secondary") %>%
  spread(key = board_type_name, value = sample) %>%
  replace_na(list(`English Catholic` = 0, `French Catholic` = 0, `English Public` = 0, `French Public` = 0)) %>%
  group_by(csduid, csdname) %>%
  summarise(
    panel = first(panel),
    enrolment.total = sum(enrolment.total),
    `English Catholic` = sum(`English Catholic`, na.rm = TRUE),
    `English Public` = sum(`English Public`, na.rm = TRUE),
    `French Catholic` = sum(`French Catholic`, na.rm = TRUE),
    `French Public` = sum(`French Public`, na.rm = TRUE)
  ) %>%
  mutate(sample.total = sum(`English Catholic`, `English Public`, `French Catholic`, `French Public`))

board_type_sample_spread <- rbind(elementary_board_type_sample_spread, secondary_board_type_sample_spread)

saveRDS(board_type_sample_spread, "output/edu/board_type_sample_spread.rds")

rm(board_type_sample, elementary_board_type_sample_spread, secondary_board_type_sample_spread, board_type_sample_spread)
```

##### Estimate Friction Function Coefficients

- The estimated `alpha` and `beta` values are saved in .csv file in cache

```{r estimate tlfd friction function, echo=FALSE, eval=FALSE, fig.width=10, fig.height=8}
# Read in the travel time skim with intra-zonal assumptions
treso_travel_time <- readRDS('output/treso/treso_travel_time.rds')
panel_id = "Elementary"
board_id = "English Public"

observed_trips <- read_observed_trips("output/edu/observed_por_pos_90.rds", school_board_def,
                                          treso_zone_def, school_sfis_2017, treso_travel_time,
                                          panel_id = panel_id, board_id = board_id)

# Calculate observed average trip travel time
tlfd_obs <- sum(observed_trips$value * observed_trips$enrolment) / sum(observed_trips$enrolment)
print(paste0("For ", board_id, " ", panel_id, " the average travel time to be calibrated to is " , tlfd_obs))

# Setup parameters for the cost function iteration
initbeta <- -1/log(sum(cost$value)) - runif(1)/10
initalpha <- 1/log(sum(cost$value)) + runif(1)/10
beta <- initbeta
alpha <- initalpha
max_value = 85
bin_size = 1

# Iterate through the alpha and beta
iterations <- 20
for (j in 1:iterations) {
  print(j)
  
  # Calculate the simulated trips
  simulated_trips <- calculate_simulated_trips(observed_trips, treso_travel_time, alpha, beta)

  # Calculate simulated average trip lengths
  tlfd_sim <- sum(simulated_trips$value * simulated_trips$enrolment) / sum(simulated_trips$enrolment)
  print(paste0("The average travel time of simulated is " , tlfd_sim))

  if (j %% 2 == 0) {
    alpha <- alpha * (tlfd_sim/tlfd_obs)
    print(paste0("The alpha value in this iteriation of the combined function is ", alpha))
  } else {
    beta <- beta * (tlfd_sim/tlfd_obs)
    print(paste0("The beta value in this iteriation of the combined function is ", beta))
  }
  
  obs_tlfd <- select(observed_trips, treso.id.por, treso.id.pos, enrolment, value) %>%
    mutate(bin = cut(value, seq(0, max_value, bin_size), labels = seq(bin_size, max_value, bin_size))) %>%
    group_by(bin) %>%
    summarise(enrolment = sum(enrolment)) %>%
    transform(., flag = "obs")
  
  sim_tlfd <- select(simulated_trips, treso.id.por, treso.id.pos, enrolment, value) %>%
    mutate(bin = cut(value, seq(0, max_value, bin_size), labels = seq(bin_size, max_value, bin_size))) %>%
    group_by(bin) %>%
    summarise(enrolment = sum(enrolment)) %>%
    transform(., flag = "model")
  
  join_tlfd <- generate_tlfd(observed_trips, simulated_trips, max_value, bin_size) %>%
    spread(flag, enrolment) %>%
    mutate(max.enrol = pmax(obs, model), min.enrol = pmin(obs, model))
  
  # Calculate the coincidence ratio
  minsum = sum(join_tlfd$min.enrol)
  maxsum = sum(join_tlfd$max.enrol)
  cr = minsum/maxsum
  print(paste0("The CR value for this iteration is ", cr))
}

rm(observed_trips, simulated_trips, obs_tlfd, sim_tlfd, join_tlfd, minsum, maxsum, CR, tlfd_sim, tlfd_obs)

```

#### Generate propensity matrix for each segment

Generate the simulated trips using the estimated `alpha` and `beta` values 

```{r simulate english public elementary trips, eval=FALSE, echo=FALSE}

panel_id = "Elementary"
board_id = "English Public"
segment_id = "EP/ELEM"
max_value = 80
bin_size = 5

observed_trips <- read_observed_trips("output/edu/observed_por_pos_90.rds", school_board_def,
                                          treso_zone_def, school_sfis_2017, treso_travel_time,
                                          panel_id = panel_id, board_id = board_id)

tlfd_parameter <- read_csv("cache/edu/tlfd_parameters.csv")
alpha = filter(tlfd_parameter, panel == panel_id, board_type == board_id)$alpha
beta = filter(tlfd_parameter, panel == panel_id, board_type == board_id)$beta

simulated_trips <- calculate_simulated_trips(observed_trips, treso_travel_time, alpha=alpha, beta=beta)
combined_tlfd <- generate_tlfd(observed_trips, simulated_trips, max_value, bin_size)

ggplot(data=combined_tlfd, aes(x=bin, y=enrolment, group=flag, color=flag)) +
  geom_line(size = 1) +
  theme(axis.text.x = element_text(angle=90, hjust=1)) +
  ggtitle(paste0(segment_id, " - alpha: ", alpha, " beta: ", beta))

tlfdjoin <- spread(combined_tlfd, flag, enrolment) %>%
  mutate(max.enrol = pmax(obs, model)) %>%
  mutate(min.enrol = pmin(obs, model))
minsum = sum(tlfdjoin$min.enrol)
maxsum = sum(tlfdjoin$max.enrol)
CR = minsum/maxsum
print(paste0("The CR value for this iteration is ", CR))

# Save the propensity function from the estimated alpha and beta
cost <- treso_travel_time %>% 
  mutate(value = value^alpha * exp(beta*value)) %>%
  replace_na(value = 0.001) %>%
  arrange(treso.id.por, treso.id.pos) %>% 
  spread(key=treso.id.pos, value=value) %>%
  column_to_rownames(var = "treso.id.por") %>%
  data.matrix() %>% 
  saveRDS("cache/edu/cfunc_EPE.rds") # Rename this appropriately
```

#### Generate full POR and POS vectors

```{r generate full vectors, echo=TRUE}
# Create the full list of POR and POS TRESO zones once and save it in output
por_full <- select(treso_shp@data, Treso_ID) %>%
  rename(orig = Treso_ID)
saveRDS(por_full, "output/treso/por_full.rds")

pos_full <- select(treso_shp@data, Treso_ID) %>%
  rename(dest = Treso_ID)
saveRDS(pos_full, "output/treso/pos_full.rds")
```

#### Calibration of TLFD

```{r calibrate tlfd, eval=FALSE, include=FALSE}
panel_id = "Elementary"
board_id = "English Public"
segment_id = paste0(str_split(str_split(board_id, " ")[[1]][1], "")[[1]][1],
                          str_split(str_split(board_id, " ")[[1]][2], "")[[1]][1],
                          str_split(panel_id, "")[[1]][1])
max_value = 80
bin_size = 3
treso_travel_time <- readRDS("output/treso/treso_travel_time.rds")
tlfd_parameter <- read_csv("cache/edu/tlfd_parameters.csv")
alpha = filter(tlfd_parameter, panel == panel_id, board_type == board_id)$alpha
beta = filter(tlfd_parameter, panel == panel_id, board_type == board_id)$beta

observed_trips <- read_observed_trips("output/edu/observed_por_pos_90.rds", school_board_def,
                                          treso_zone_def, school_sfis_2017, treso_travel_time,
                                          panel_id = panel_id, board_id = board_id) %>% 
  rename(distance = euclidean.dist)

observed_time_mean <- round(trip_mean(observed_trips, 'time'),2)
observed_time_percentile <- round(trip_percentile(observed_trips, 'time', 0.90),2)
observed_distance_mean <- round(trip_mean(observed_trips, 'distance'),2)
observed_distance_percentile <- round(trip_percentile(observed_trips, 'distance', 0.90),2)
print(paste0("The mean observed travel time is: ", observed_time_mean, " ,and observed 90th percentile travel time is: ", observed_time_percentile, " , and observed mean travel distance is: ", observed_distance_mean, " , and the observed 90th percentile travel distance is: ", observed_distance_percentile))

#"The mean observed travel time is: 6.92 ,and observed 90th percentile travel time is: 13.11 , and observed mean travel distance is: 1.79 , and the observed 90th percentile travel distance is: 4.85"

simulated_trips <- readRDS(paste0("cache/edu/balanced_trip_list_", segment_id, "_constrained.rds")) %>%
  rename(enrolment = trips) %>%
  filter(enrolment != 0) %>% 
  left_join(treso_travel_time, by = c('treso.id.por', 'treso.id.pos'))  

simulated_time_mean <- round(trip_mean(simulated_trips, 'time'),2)
simulated_time_percentile <- round(trip_percentile(simulated_trips, 'time', 0.90),2)
print(paste0("The mean simulated school travel time is: ", simulated_time_mean, " ,and simulated school 90th percentile travel time is: ", simulated_time_percentile))

#"The mean simulated school travel time is: 7.41 ,and simulated school 90th percentile travel time is: 14.23"

combined_tlfd <- generate_tlfd(observed_trips, simulated_trips, max_value, bin_size)

ggplot(data=combined_tlfd, aes(x=bin, y=enrolment, fill=flag)) +
  geom_col(position = position_dodge(0.5), alpha = 1) +
  scale_fill_manual(values = c("obs" = "#a73b90", "model" = "#f3aba2")) +
  theme(axis.text.x = element_text(angle=90, hjust=1)) +
  ggtitle(paste0(board_id, "/", panel_id, " - alpha: ", alpha, " beta: ", beta)) +
  theme_bw()

# generate closest school tlfd for comparison
closest_trips <- readRDS("cache/edu/temp_result_student_tlfd.rds") %>% 
  filter(panel == panel_id, board_type_name == board_id) %>% 
  ungroup() %>% 
  select(treso.id.por, treso.id.pos, enrolment = enrolment.assigned) %>% 
  left_join(treso_travel_time, by = c("treso.id.por", "treso.id.pos"))
  
closest_time_mean <- round(trip_mean(closest_trips, 'time'),2)
closest_time_percentile <- round(trip_percentile(closest_trips, 'time', 0.90),2)
print(paste0("The mean closest school travel time is: ", closest_time_mean, " , and closest school 90th percentile travel time is: ", closest_time_percentile))

#"The mean closest school travel time is: 7.14248062109651 ,and closest school 90th percentile travel time is: 14.3017978668213"

combined_tlfd_2 <- generate_tlfd(observed_trips, closest_trips, max_value, bin_size)

ggplot(data=combined_tlfd_2, aes(x=bin, y=enrolment, fill=flag)) +
  geom_col(position = position_dodge(0.5), alpha = 1) +
  scale_fill_manual(values = c("obs" = "#a73b90", "model" = "#f3aba2")) +
  theme(axis.text.x = element_text(angle=90, hjust=1)) +
  ggtitle(paste0("Closest TLFD - ", board_id, "/", panel_id)) +
  theme_bw()
```

### Closest School Probability Choice

- Using the closest school probability to assign students to schools
- Examine if the resulting assignment aligns closely with observed ADE as well as OTG constraints
- Assumes the school board and panel is predetermined

```{r applying closest school probability, echo=FALSE, eval=FALSE}
closest_school_summary <- readRDS("output/edu/closest_school_manhattan_summary.rds") %>%
  group_by(board.type.name, panel, mof_region, csdname) %>%
  summarise(closest.school.list = paste(num.closer.schools.cuts, collapse = ","),
            prob.list = paste(percentage, collapse = ","))

observed_students <- readRDS("output/edu/observed_por_pos_90.rds") %>%
  select(treso.id.por, student.postal.code, enrolment, sfis, dsb.index) %>%
  left_join(select(treso_zone_def, treso_id, mof_region, csdname), by = c("treso.id.por" = "treso_id")) %>%
  left_join(select(school_board_def, dsb, board_type_name), by = c("dsb.index" = "dsb")) %>%
  left_join(select(school_sfis_2017, sfis, panel), by = "sfis") %>%
  left_join(closest_school_summary, by = c("board_type_name" = "board.type.name",
                                          "panel", "mof_region", "csdname")) %>%
  # FIXME this is a hotfix for prob.list and closest.school.list being NA (empty)
  # The reason for empty list is the 25 meter added buffer was not enough to capture the
  # actual school it went to. And, filtering to the panel and board.index resulted
  # in no schools in the selection. Therefore, it is most likely students in these
  # segmentations are going to the closest school.
  drop_na(mof_region, prob.list) %>%
  rowwise() %>%
  mutate(prob.list = list(as.numeric(unlist(strsplit(prob.list, ","))))) %>%
  mutate(closest.school.list = list(as.character(unlist(strsplit(closest.school.list, ",")))))

f2 <- function(row) {
  x = row["closest.school.list"][[1]]
  size = row["enrolment"][[1]]
  pc = row["student.postal.code"][[1]]
  sfis = row["sfis"][[1]]
  
  print(paste0("Student Postal Code: ", pc, ". SFIS: ", sfis))
  
  if (length(x) == 1) {
    if (x == "5+") {
      x <- 5
    }
    else {
      x <- as.numeric(x)
    }
    
    prob <- c(rep(0, x-1), row["prob.list"][[1]])
  } 
  else {
    prob <- row["prob.list"][[1]]
  }
  
  list(sample(x, size=size, replace=TRUE, prob=prob))
}

plan(multiprocess)
results <- future_apply(observed_students, 1, f2)
results_tb = t(as.data.table(results))
observed_students <- cbind(observed_students, results_tb)

summary <- observed_students %>%
  rowwise() %>%
  mutate(school.1 = sum(results_tb == "1"),
         school.2 = sum(results_tb == "2"),
         school.3 = sum(results_tb == "3"),
         school.4 = sum(results_tb == "4"),
         school.5 = sum(results_tb == "5+"))

saveRDS(summary, "output/edu/closest_school_theory_applied.rds")  

```


```{r summarize application, echo=FALSE, eval=FALSE}
student_lat_long <- student_travel_90 %>%
  select(student.postal.code, student.lat, student.long) %>%
  distinct(student.postal.code, .keep_all = TRUE)

student_to_schools <- readRDS("output/edu/closest_school_theory_applied.RDS") %>%
  select(student.postal.code, school.1, school.2, school.3, school.4, school.5, mof_region, panel, board_type_name) %>%
  group_by(student.postal.code, mof_region, panel, board_type_name) %>%
  summarise_all(list(sum)) %>%
  ungroup() %>%
  mutate(student.postal.code = as.character(student.postal.code)) %>%
  left_join(student_lat_long, by = "student.postal.code") %>%
  mutate(id = row_number())

result_school = data.table()
result_student = data.table()
for (i in c("English Catholic", "English Public", "French Catholic", "French Public")) {
  for (j in c("Elementary", "Secondary")) {
    print(paste0(i, "-", j))
    
    student_xy <- student_to_schools %>%
      filter(board_type_name == i, panel == j)
    coordinates(student_xy) <- c("student.long", "student.lat")
    
    school_xy <- student_travel_90 %>%
      left_join(select(school_board_def, dsb, board_type_name), by = c("dsb.index" = "dsb")) %>%
      filter(board_type_name == i, panel == j) %>%
      select(sfis, school.name, school.lat, school.long) %>%
      distinct(sfis, .keep_all=TRUE)
    coordinates(school_xy) <- c("school.long", "school.lat")
    
    nn <- get.knnx(coordinates(school_xy), coordinates(student_xy), k = 5)
    nearest_schools <- nn$nn.index %>%
      as_tibble()

    school_df <- as_tibble(school_xy) %>%
      mutate(index.column = row_number())
    student_df <- as_tibble(student_xy)

    nn_schools_sfis <- nearest_schools %>%
      left_join(select(school_df, index.column, sfis), by=c("V1" = "index.column")) %>%
      rename(sfis.1 = sfis) %>%
      left_join(select(school_df, index.column, sfis), by=c("V2" = "index.column")) %>%
      rename(sfis.2 = sfis) %>%
      left_join(select(school_df, index.column, sfis), by=c("V3" = "index.column")) %>%
      rename(sfis.3 = sfis) %>%
      left_join(select(school_df, index.column, sfis), by=c("V4" = "index.column")) %>%
      rename(sfis.4 = sfis) %>%
      left_join(select(school_df, index.column, sfis), by=c("V5" = "index.column")) %>%
      rename(sfis.5 = sfis) %>%
      select(sfis.1, sfis.2, sfis.3, sfis.4, sfis.5)
    
    students_assigned <- cbind(student_df, nn_schools_sfis)
    
    student_1 <- students_assigned %>%
      group_by(student.postal.code, student.lat, student.long, sfis.1) %>%
      summarise(enrolment = sum(school.1)) %>%
      filter(enrolment > 0) %>%
      ungroup() %>%
      rename(sfis = sfis.1)
    student_2 <- students_assigned %>%
      group_by(student.postal.code, student.lat, student.long, sfis.2) %>%
      summarise(enrolment = sum(school.2)) %>%
      filter(enrolment > 0) %>%
      ungroup() %>%
      rename(sfis = sfis.2)
    student_3 <- students_assigned %>%
      group_by(student.postal.code, student.lat, student.long, sfis.3) %>%
      summarise(enrolment = sum(school.3)) %>%
      filter(enrolment > 0) %>%
      ungroup() %>%
      rename(sfis = sfis.3)
    student_4 <- students_assigned %>%
      group_by(student.postal.code, student.lat, student.long, sfis.4) %>%
      summarise(enrolment = sum(school.4)) %>%
      filter(enrolment > 0) %>%
      ungroup() %>%
      rename(sfis = sfis.4)
    student_5 <- students_assigned %>%
      group_by(student.postal.code, student.lat, student.long, sfis.5) %>%
      summarise(enrolment = sum(school.5)) %>%
      filter(enrolment > 0) %>%
      ungroup() %>%
      rename(sfis = sfis.5)
    
    school_1 <- students_assigned %>%
      group_by(sfis.1) %>%
      summarise(enrolment = sum(school.1)) %>%
      rename(sfis = sfis.1)
    school_2 <- students_assigned %>%
      group_by(sfis.2) %>%
      summarise(enrolment = sum(school.2)) %>%
      rename(sfis = sfis.2)
    school_3 <- students_assigned %>%
      group_by(sfis.3) %>%
      summarise(enrolment = sum(school.3)) %>%
      rename(sfis = sfis.3)
    school_4 <- students_assigned %>%
      group_by(sfis.4) %>%
      summarise(enrolment = sum(school.4)) %>%
      rename(sfis = sfis.4)
    school_5 <- students_assigned %>%
      group_by(sfis.5) %>%
      summarise(enrolment = sum(school.5)) %>%
      rename(sfis = sfis.5)
    
    student_total <- rbind(student_1, student_2, student_3, student_4, student_5) %>%
      group_by(student.postal.code, student.lat, student.long, sfis) %>%
      summarise(enrolment.assigned = sum(enrolment)) %>%
      ungroup()
    
    school_total <- rbind(school_1, school_2, school_3, school_4, school_5) %>%
      group_by(sfis) %>%
      summarise(enrolment.assigned = sum(enrolment))
    
    result_student <- rbind(result_student, student_total)
    result_school <- rbind(result_school, school_total)

  }
}

result_student <- result_student %>%
  group_by(student.postal.code, student.lat, student.long, sfis) %>%
  summarise(enrolment.assigned = sum(enrolment.assigned))
saveRDS(result_student, "output/edu/closest_school_assigned_students.rds")

observed_enrol <- readRDS("output/edu/observed_por_pos_90.rds") %>%
  group_by(sfis)%>%
  summarise (sum.obs.enrolment = sum(enrolment))

join_table <- readRDS("output/edu/observed_por_pos_90.rds") %>%
  left_join(select(school_board_def, dsb, board_type_name), by = c("dsb.index" = "dsb")) %>%
  left_join(select(school_sfis_2017, sfis, panel), by = c("sfis") ) %>%
  select(sfis, school.name, treso.id.pos, dsb.index, board_type_name, panel) %>%
  group_by(sfis) %>%
  left_join(select(observed_enrol, sum.obs.enrolment, sfis), by = "sfis") %>%
  summarise(school.name = first(school.name), treso.id.pos = first(treso.id.pos), dsb.index = first(dsb.index), board_type_name = first(board_type_name), panel = first(panel), sum.obs.enrolment = first(sum.obs.enrolment))

result_school2 <- result_school %>%
  group_by(sfis) %>%
  summarise (enrolment.assigned = sum(enrolment.assigned)) %>%
  left_join(join_table, by = "sfis") %>%
  filter(panel =="Secondary", board_type_name == "English Public") %>%
  mutate(closest_school_to_observed_enrol = enrolment.assigned - sum.obs.enrolment)%>%
  mutate(perc_ade_diff = ((enrolment.assigned - sum.obs.enrolment)/sum.obs.enrolment)*100) %>%
  mutate(rounded_perc_diff = round(perc_ade_diff, 2)) %>%
  left_join(select(treso_zone_def, treso_id, mof_region), by = c("treso.id.pos" = "treso_id")) 

avg_perc2 <- mean(result_school2$rounded_perc_diff)

print(paste0("The average percent change between simulated and 2017 observed ADE for French Public Secondary schools is ", round(avg_perc2, 2)))

result_school2.data <- data.frame("y" = result_school2$rounded_perc_diff, "x" = result_school2$closest_school_to_observed_enrol, "mof_region" = result_school2$mof_region)
ggplot(data=result_school2.data) +
  
  geom_hline(yintercept = 0, colour="pink", size=1) + 
  geom_vline(xintercept = 0, colour="pink", size=1) +
  #geom_point(aes(x = x, y = y, colour = mof_region), size = 1.5, alpha = 0.15) +
  geom_point(aes(x = x, y = y), size = 1.5, alpha = 0.15) +
  coord_cartesian(xlim=c(-400,400), ylim=c(-100,100)) +
  #facet_wrap(~ mof_region, scale = "fixed") +
  theme(legend.position = "none") + 
  labs(x="Enrollment Difference (Count)", y="Percent Difference (%)", subtitle="Elementary - French Catholic", title="Closest School vs. Observed Demand (2017)")
```

```{r tlfd of closest school probability, echo=FALSE, eval=FALSE}

school_overlay <- readRDS("output/edu/observed_por_pos_90.rds") %>%
  distinct(sfis, school.name, treso.id.pos, dsb.index) %>%
  left_join(select(school_sfis_2017, sfis, school.lat, school.long), by = "sfis")

student_overlay <- readRDS("output/edu/observed_por_pos_90.rds") %>%
  distinct(student.postal.code, treso.id.por) %>%
  mutate(student.postal.code = as.character(student.postal.code))

result_student_tlfd <- result_student %>%
  left_join(school_overlay, by="sfis") %>%
  left_join(student_overlay, by="student.postal.code") %>%
  # There are new POR-POS pairs that did not exist before, need to recalculate euclidean_dist
  mutate(euclidean.dist = haverFunctionEuclidean(student.lat, student.long, school.lat, school.long)) %>%
  # Get the travel time skims
  left_join(travel_time_skim, by=c("treso.id.por" = "orig", "treso.id.pos" = "dest")) %>%
  rename(travel.time = value) %>%
  # Get the school board type names
  left_join(select(school_board_def, dsb, board_type_name),
            by = c("dsb.index" = "dsb")) %>%
  # Get the MOF regions
  left_join(select(treso_zone_def, treso_id, area, mof_region),
            by = c("treso.id.por" = "treso_id")) %>%
  # Get the panel information
  left_join(select(school_sfis_2017, sfis, panel), by = "sfis")

summary(result_student_tlfd$travel.time)

ggsave(file = "output/edu/tlfd_closest_school_probability.png",
       plot_travel_time_tlfd(result_student_tlfd), height = 28, width = 10)

```

## Application of Gravity Model to 2011 Data

```{r sample treso population in 2011, include = FALSE}
observed_2011_treso <- readRDS("cache/treso/treso_tb.rds") %>% 
  select(treso_zone, n_ele_pop, n_sec_pop) %>% 
  gather(key = "panel", value = "enrolment", n_ele_pop, n_sec_pop) %>% 
  filter(enrolment > 0) %>% 
  mutate(panel = ifelse(panel == "n_ele_pop", "Elementary", "Secondary")) %>% 
  left_join(select(read.csv("input/treso/treso_zone_system.csv"), csduid, csdname, treso_id),
            by = c("treso_zone" = "treso_id")) %>% 
  rename(treso.id.por = treso_zone)

board_type_sample_spread <- readRDS("output/edu/board_type_sample_spread.rds")

# Apply the board sampling probabilities to the students
treso_level_sampling_2011 <- observed_2011_treso %>%
  select(treso.id.por, enrolment, panel, csduid) %>%
  left_join(select(board_type_sample_spread, -enrolment.total, -sample.total), by = c("panel", "csduid")) %>%
  group_by(treso.id.por, panel) %>%
  summarise(
    csduid = first(csduid),
    csdname = first(csdname),
    enrolment = sum(enrolment),
    `English Catholic` = mean(`English Catholic`),
    `English Public` = mean(`English Public`),
    `French Catholic` = mean(`French Catholic`),
    `French Public` = mean(`French Public`)
  ) %>%
  filter(!is.na(csdname)) %>%
  # Create probability list for sample
  unite(prob, `English Catholic`, `English Public`, `French Catholic`, `French Public`, sep = ",") %>%
  rowwise() %>%
  mutate(prob = list(as.double(unlist(strsplit(prob, ","))))) %>%
  # Sample the different board types 
  mutate(sample.result = list(sample(c("EC", "EP", "FC", "FP"), size=enrolment, replace=TRUE, prob=prob))) %>%
  mutate(`English Catholic` = sum(sample.result == "EC"),
         `English Public` = sum(sample.result == "EP"),
         `French Catholic` = sum(sample.result == "FC"),
         `French Public` = sum(sample.result == "FP"))

# Observed school demand for scaling
school_sfis_2011 <- readRDS("cache/edu/school_treso_master.rds") %>%
  filter(year == 2011) %>% 
  filter(zero_otg_flag == 0 | excessive_util_flag == 0) %>%
  mutate(utilization = ifelse(otg != 0, ade / otg, 0))

#Scale TRESO sampled enrollemnt to observed school demand by board type and panel
board_panel_summary_2011 <- school_sfis_2011 %>%
  group_by(board_type_name, panel)%>%
  summarise (ade.sum = sum(ade)) 

treso_level_sampling_2011_sum <- treso_level_sampling_2011 %>%
  group_by(panel)%>%
  summarise(`English Catholic` = sum(`English Catholic`), 
            `English Public` = sum(`English Public`),
            `French Catholic` = sum(`French Catholic`),
            `French Public` = sum(`French Public`)) %>% 
  gather(key="board_type_name", value="enrolment.sum", `English Catholic`:`French Public`) %>%
  left_join(board_panel_summary_2011, by=c("panel", "board_type_name")) %>%
  mutate(ratio = ade.sum/enrolment.sum)

treso_por_2011 <- select(treso_level_sampling_2011, treso.id.por, panel, csduid, csdname, 
                         `English Catholic`:`French Public`) %>%
  gather(key="board_type_name", value="enrolment", `English Catholic`:`French Public`) %>%
  left_join(select(treso_level_sampling_2011_sum, panel, board_type_name, ratio), by=c("panel", "board_type_name")) %>%
  mutate(enrolment.scaled = enrolment * ratio) %>%
  select(treso.id.por, enrolment.scaled, panel, board_type_name) 
saveRDS(treso_por_2011, "cache/edu/treso_por_2011.rds")
```

#### English Public Elementary

1D balance the POR and POS demand using the calibrated cfunc.

```{r distribute english public elementary POR 2011, echo=FALSE, eval=FALSE}

panel_id = "Elementary"
board_id = "English Public"

input_por <- readRDS("cache/edu/treso_por_2011.rds") %>% 
  filter(panel == panel_id, board_type_name == board_id) %>% 
  select(treso.id.por, enrolment.scaled)

input_pos <- readRDS("cache/edu/school_treso_master.rds") %>% 
  filter(year == "2011", otg != 0, panel == panel_id, board_type_name == board_id) %>% 
  group_by(treso.id.pos, board_type_name, panel) %>% 
  summarise(otg = sum(otg)) %>% 
  ungroup() %>% 
  select(treso.id.pos, otg)

# Read the saved full list of POR and POS TRESO zones
por_full <- readRDS("output/treso/por_full.rds") %>%  #merge treso enrolment to this
  left_join(input_por, by = c("orig" = "treso.id.por")) %>% 
  replace_na(list(enrolment.scaled = 0))
  
pos_full <- readRDS("output/treso/pos_full.rds") %>%  #merge otg to this
  left_join(input_pos, by = c("dest" = "treso.id.pos")) %>% 
  replace_na(list(otg = 0))

por <- por_full %>% #redirect 2 columns into 1 vector
  arrange(orig) %>% 
  column_to_rownames(var = "orig") %>%
  data.matrix()

pos <- pos_full %>% #redirect 2 columns into 1 vector
  arrange(dest) %>% 
  column_to_rownames(var = "dest") %>%
  data.matrix()

prop_matrix_EPE <- readRDS("cache/edu/cfunc_EPE.rds")

# # 1D balance the matrix
# prop_matrix2_EPE <- matrix_balancing_1d(prop_matrix_EPE, por, pos, is_weight_continuous=FALSE)
# 2D balance the matrix
prop_matrix2_EPE <- matrix_balancing_2d(prop_matrix_EPE, por, pos, totals_to_use="rows", max_iterations=100)

# Save the balanced POR-POS trip list
trip_list_EPE_2011 <- reshape2::melt(prop_matrix2_EPE) %>%
  arrange(Var1, Var2)
colnames(trip_list_EPE_2011) <- c('treso.id.por', 'treso.id.pos', 'trips')
saveRDS(trip_list_EPE_2011, "cache/edu/balanced_trip_list_EPE_2011.rds")

# distribute treso level pos demand to individual schools
trip_list_EPE_2011_sum <- trip_list_EPE_2011 %>% 
  group_by(treso.id.pos) %>% 
  summarise(trips = sum(trips))

school_treso_master <- readRDS("cache/edu/school_treso_master.rds")

pos_school_weight <- calculate_school_weight_forecasting(trip_list_EPE_2011_sum, school_treso_master, eqao_2017, 
                                                         year_id = 2011, panel_id = panel_id, board_id = board_id)

print(paste0("For ", panel_id, "-", board_id, ", there are ", nrow(filter(pos_school_weight, length(school.weight.prob.list) == 1)), " TRESO zones with a single school, and ", nrow(filter(pos_school_weight, length(school.weight.prob.list) != 1)), " TRESO zones with multiple schools."))

trip_list_EPE_2011 <- readRDS(paste0("cache/edu/balanced_trip_list_EPE_2011.rds")) %>%
  left_join(pos_school_weight, by = c("treso.id.pos"))

# Apply bucket rounding to chunks of data by TRESO POS
results_EPE <- by(trip_list_EPE_2011$trips, trip_list_EPE_2011[c("treso.id.pos")], smart_round, simplify = TRUE)

# Convert the output of by() to a dataframe
results2_EPE <- sapply(results_EPE, I)
colnames(results2_EPE) <- colnames(prop_matrix2_EPE)
rownames(results2_EPE) <- rownames(prop_matrix2_EPE)

df <- results2_EPE %>%
  reshape2::melt() %>% 
  arrange(Var1, Var2)
colnames(df) <- c('treso.id.por', 'treso.id.pos', 'enrolment.rounded')

trip_list2_EPE_2011 <- bind_cols(trip_list_EPE_2011, df) %>%
  filter(enrolment.rounded != 0) %>%
  select(-treso.id.por, -treso.id.pos)

# Sample the schools by weight
plan(multiprocess)
results_EPE <- future_apply(trip_list2_EPE_2011, 1, sample_by_row)
results_tb_EPE <- t(as.data.table(results_EPE))
trip_list_schools_EPE_2011 <- cbind(trip_list2_EPE_2011, results_tb_EPE)

trip_list_schools_EPE_2011_summed <- trip_list_schools_EPE_2011 %>% 
  unnest(results_tb_EPE) %>%
  mutate(enrol.value = 1) %>%
  rename(sfis = results_tb_EPE) %>% 
  group_by(sfis) %>% 
  summarise(enrol.value = sum(enrol.value)) 

saveRDS(trip_list_schools_EPE_2011_summed, "cache/edu/trip_list_schools_EPE_2011_summed.rds")
```

#### Compare simulated 2011 to market share 2011 and actual 2011

```{r english public elementary results comparison 2011, include = FALSE}

panel_id = "Elementary"
board_id = "English Public"

# observed 2011 enrollment
school_treso_master <- readRDS("cache/edu/school_treso_master.rds") %>% 
  filter(year == 2011)

# marketshare 2011 enrolment diff 
market_2011 <- readRDS("cache/edu/school_2007_market_share.rds") %>% 
  mutate(abs.diff =  (enrol2011.by2007MS - ade2011)) %>% 
  mutate(perc.diff = round((abs.diff/ade2011*100),2))%>% 
  left_join(select(school_treso_master, sfis, board_type_name, treso.id.pos), by="sfis") %>% 
  filter(panel==panel_id, board_type_name==board_id) %>% 
  select(sfis, abs.diff, perc.diff) %>% 
  mutate(method = "market share")

# gravity 2011 enrolment diff 
gravity_2011 <- readRDS("cache/edu/trip_list_schools_EPE_2011_summed.rds") %>% 
  left_join(select(school_treso_master, sfis, ade), by = "sfis") %>% 
  mutate(abs.diff= (enrol.value - ade)) %>%
  mutate(perc.diff = round((abs.diff/ade)*100,2)) %>% 
  filter(perc.diff < 1000, !is.infinite(perc.diff)) %>% 
  select(sfis, abs.diff, perc.diff) %>% 
  mutate(method = "gravity")

data_2011 <- rbind(market_2011, gravity_2011)
  
ggplot(gravity_2011, aes(x=abs.diff, y=perc.diff)) +
  geom_hline(yintercept = 0, colour="pink", size=1) +
  geom_vline(xintercept = 0, colour="pink", size=1) +
  geom_point(size = 1.5, alpha = 0.15) +
  #geom_point(aes(x = x, y = y), size = 1.5, alpha = 0.15) +
  coord_cartesian(xlim=c(-400,400), ylim=c(-250,250)) +
  #facet_wrap(~ mof_region, scale = "fixed") +
  theme(legend.position = "none") +
  labs(x="Enrollment Absolute Difference (Count)", y="Percent Difference (%)",
       subtitle="Elementary - English Public", title="Simulated vs. Observed Demand (2011)")

ggplot(market_2011, aes(abs.diff, perc.diff)) +
  geom_hline(yintercept = 0, colour="pink", size=1) +
  geom_vline(xintercept = 0, colour="pink", size=1) +
  geom_point(size = 1.5, alpha = 0.15) +
  #geom_point(aes(x = x, y = y), size = 1.5, alpha = 0.15) +
  coord_cartesian(xlim=c(-400,400), ylim=c(-250,250)) +
  #facet_wrap(~ mof_region, scale = "fixed") +
  theme(legend.position = "none") +
  labs(x="Enrollment Absolute Difference (Count)", y="Percent Difference (%)",
       subtitle="Elementary - English Public", title="Market Share vs. Observed Demand (2011)")

ggplot(data_2011, aes(abs.diff, perc.diff, color=method)) +
  geom_hline(yintercept = 0, colour="pink", size=1) +
  geom_vline(xintercept = 0, colour="pink", size=1) +
  geom_point(size = 1.5, alpha = 0.15) +
  coord_cartesian(xlim=c(-400,400), ylim=c(-250,250)) +
  #facet_wrap(~ mof_region, scale = "fixed") +
  labs(x="Enrollment Absolute Difference (Count)", y="Percent Difference (%)",
       subtitle="Elementary - English Public", title="Estimated vs. Observed Demand (2011)")
```

## New School Cost Function
```{r school cost function}
# Read in cost function based on square metres per student as a function of number of pupil places, and $/m2
area_per_ade <- read.csv("input/edu/school_cost_benchmark_areas.csv", stringsAsFactors = FALSE)
area_rates <- read.csv("input/edu/school_cost_benchmark_area_rates.csv", stringsAsFactors = FALSE)

# Read in Geographic Adjustment Factor based on postal code of proposed school location
gaf_raw <- read.csv("input/edu/school_cost_benchmark_gaf.csv", stringsAsFactors = FALSE)

# Geographic adjustment factor for specific municipalities on a postal code basis - to be looked up if possible 
gaf_lookup <- gaf_raw %>% 
  mutate(pcode_3_digit = ifelse(str_length(postal_code) == 3, toupper(postal_code), 0),
         pcode_4_digit = ifelse(str_length(postal_code) == 4, toupper(postal_code), 0),
         pcode_5_digit = ifelse(str_length(postal_code) == 5, toupper(postal_code), 0),
         pcode_6_digit = ifelse(str_length(postal_code) == 6, toupper(postal_code), 0))

# Min school size: 200 pupil-places (i.e., ADE) for elementary, 300 pupil-places for secondary

new_school_list <- tibble(user_input_school_size = c(500, 750), user_input_panel = c('Elementary', 'Secondary'), user_input_pcode = c('k0b1e4', 'P6A5K1')) # TODO: Replace this hard-coded value with user-input value from visualization

# Convert area_per_ade to be long format
area_per_ade_long <- area_per_ade %>% 
  rename(Elementary = elementary_sqm_pp, Secondary = secondary_sqm_pp) %>% 
  gather(key = panel, value = 'sqm_pp', 2:3)

# Join new_school_list to join in square metres per student and cost per square metre based on standard values
new_school_list_area <- new_school_list %>% 
  left_join(area_per_ade_long, by = c('user_input_school_size' = 'OTG', 'user_input_panel' = 'panel')) %>% 
  mutate(total_area = user_input_school_size * sqm_pp) %>% 
  left_join(area_rates, by = c('user_input_panel' = 'panel'))

# Determine geogrpahic adjustment factor for each new school in new_school_list_area
#plan(multiprocess)
gaf <- future_apply(new_school_list_area, MARGIN = 1, FUN = school_gaf, gaf_lookup)

new_school_list_complete <- new_school_list_area %>% 
  cbind(gaf) %>% 
  mutate(cost_2018 = round(total_area * cost_per_sqm * gaf, 0))

```

## Cost Annualization 
- Inflate cost for facility construction based on construction year; calculate total cost over time period of interest
```{r}
user_input_inflation <- 0.02 # TODO: Replace this hard-coded value with user-input value from visualization
user_input_scenario_year <- 2025 # TODO: Replace this hard-coded value with user-input value from visualization

currency_year = 2018 # Units of costs; set to 2018 since cost function from EDU assumed to be set in 2018$
current_year = 2019 # Current year used to calculate construction timespan; should be parameterized and put up front for user to choose

annualized_inflated_cost <- construction_cost(user_input_inflation, user_input_scenario_year, currency_year,
                                              current_year, new_school_list_complete)
```


## Decision-Making Layer
```{r implement decision making}
school_asset_2017 <- readRDS("cache/edu/school_treso_master.rds") %>% 
  filter((status == "Open" | is.na(status)), otg != 0, ade != 0, year == 2017) %>% 
  select(sfis, panel, board_type_name)

treso_travel_time <- readRDS("output/treso/treso_travel_time.rds")

# Calculate the average travel time
observed_por_pos <- readRDS("output/edu/observed_por_pos_90.rds") %>% 
  left_join(treso_travel_time, by=c("treso.id.por", "treso.id.pos")) %>% 
  left_join(treso_zone_def, by=c("treso.id.por"="treso_id")) %>% 
  left_join(school_asset_2017, by="sfis")

treso_origin_travel_time <- observed_por_pos %>% 
  group_by(treso.id.por, panel, board_type_name) %>% 
  summarise(avg.travel.time = weighted.mean(value, enrolment),
            enrolment = sum(enrolment))

csd_origin_travel_time <- observed_por_pos %>% 
  group_by(csduid, csdname, panel, board_type_name) %>% 
  summarise(avg.travel.time = weighted.mean(value, enrolment),
            enrolment = sum(enrolment))

```


```{r Sandboxy playground for ARK decision-making functions}
# Decision-making with respect to needed OTG per CSD
# a.	If net new OTG (per CSD) is less than the minimum required for a new school, or if no school in CSD, dont build school and ignore need for more capacity
# b.	If net new OTG is negative but doesnt justify closing a school, do nothing
# c.	If net new OTG is negative enough to justify closing a school, close the largest school in CSD which is smaller than magnitude of negative OTG needed (or take weighted centroid of negative population by TRESO zone to determine which school to close). Start by assuming max of one school per CSD will be closed.
# d.	If net new OTG justifies one or more school, calculate school size = net new OTG / roundup(net new OTG / max school size)


# Set minimum and maximum school size
school_sizes <- tibble(panel = c('elementary', 'secondary'), min.otg = c(200, 300), max.otg = c(1200, 1700))

# Determine how many schools should be built/consolidated.
# TODO: Consider relaxing constraint to allow multiple schools to be consolidated (deleted) per CSD
# TODO: Replace tibble with table of actual OTG per CSD
new_otg_per_csd <- tibble(csduid = c(1000, 1001, 1002, 2124, 2981),
                          total.otg = c(12000, 4000, 1000, 500, 3000), 
                          net.new.otg = c(1000, 600, -500, 100, -50), 
                          panel = c('elementary', 'elementary', 'secondary', 'elementary', 'secondary'),
                          board_type_name = c('English Public', 'English Public', 'French Public', 'English Catholic', 'French Catholic')) %>%
  left_join(school_sizes, by = c('panel')) %>% 
  mutate(new.school.count = ifelse(abs(net.new.otg) < min.otg, 0, ceiling(net.new.otg/max.otg))) %>%
  # TODO: Consider relaxing the following assumption by deleting next line: Assume no more than 1 school will be consolidated per CSD
  mutate(new.school.count = ifelse(new.school.count < 0, -1, new.school.count))
           
  # Calculate number of OTG to add to existing schools - only in cases where change in OTG doesn't justify opening or closing a single school
  # mutate(existing.add.otg = ifelse(new.school.count == 0, net.new.otg, 0))

# Establish existing school size (otg)
school_master_otg <- school_master %>%
  select(year, dsb.index, board.name, board_type_name, panel, sfis, school.name, status, otg, csduid, cduid, treso.id.pos) %>% 
  filter(year == 2025) %>%  # TODO: Replace year with user-input scenario year from visualization
  group_by(csduid, panel, board_type_name) %>% 
  mutate(otg.per.csd = sum(otg)) %>% 
  ungroup()

# Add new schools by CSD
school_master_otg_new <- school_master_otg %>% 
  left_join(select(new_otg_per_csd, csduid, panel, board_type_name, new.school.count), by = c('csduid', 'panel', 'board_type_name')) %>%
  mutate(new.school.size = ifelse(new.school.count > 0, net.new.otg / new.school.count, 0)) %>%
  # If consolidating a school, close the largest school which has OTG lower than the net loss of OTG (i.e., close the biggest school possible while still deleting fewer student places than should be deleted according to calculations)
  group_by(csduid, panel, board_type_name) %>% 
  mutate(consolidated.school.size = ifelse(new.school.count < 0, min(otg[otg > net.new.otg]), 0)) %>% 
  ungroup()

####### NEXT STEP: REPLACE MADE-UP CSDs WITH REAL CSDs TO TEST STEPS CREATED TO DATE #######


```

- Determine which existing schools to consolidate

```{r}



consolidation <- school_sfis_2017 %>% 
  # Use of inner join removes schools from other board-types and panels (from school_Sfis_2017) and proposed/new schools from school_summary_20xx
  inner_join(school_summary_20xx, by = c('sfis')) %>% 
  # Calculate simulated utilization at existing schools once new schools are built
  mutate(simulated.utilization = simulated.ade / otg) %>% 
  filter(simulated.utilization <= consolidation_threshold) %>% 
  select(sfis, dsb.index, board.name, panel, school.name, otg, simulated.ade, simulated.utilization)

# Compare travel times after consolidation of existing schools to travel times if consolidated schools not closed 
  

```



## MOF Projection Double-Check
```{r}
treso_forecast_population <- readRDS("input/edu/treso_population_edu.rds") %>% 
<<<<<<< HEAD
  select(treso.id.por = treso_zone, panel = age.group, csduid, potential.enrolment = population.2027) %>%
  filter(panel != "other")
=======
  select(treso.id.por = treso_zone, panel = age.group, csduid, potential.enrolment = population.2041) %>%
  filter(panel != "other") %>% 
  mutate(potential.enrolment = round(potential.enrolment))
>>>>>>> 68bc4f47e1a85f568f7607702b84ac2e1fceccf1

board_type_sample_spread <- readRDS("output/edu/board_type_sample_spread.rds") 

# Apply the board sampling probabilities to the student population from TRESO
treso_forecast_population_board <- apply_sampling_to_population(forecast_population = treso_forecast_population,
                                                                board_type_sample = board_type_sample_spread)

write_csv(treso_forecast_population_board, "cache/edu/treso_population_edu_2041.csv")

```

