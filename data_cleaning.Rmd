---
title: "MOI Data Clean-up"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(weights)
library(RODBC)
library(sp)
library(rgdal)
library(rgeos)
# library(modeest)
# library(genefilter)
source("helpers.R")
```


# Import data
```{r import, include=FALSE}
# TRESO data
hhld_df <- data.table::fread("input/treso/households_2011.csv.gz")
pop_df <- data.table::fread("input/treso/persons_2011.csv.gz")

# School Data
schoolCap <- read.csv("input/edu/school_capacity.csv", stringsAsFactors = FALSE)
schoolForecast <- read.csv("input/edu/school_forecast.csv", stringsAsFactors = FALSE)
schoolAssets <- read.csv("input/edu/school_assets.csv", stringsAsFactors = FALSE)
schoolAssetsPortables <- read.csv("input/edu/school_assets_portables.csv", stringsAsFactors = FALSE)
schoolAssetsSFIS.BID <- read.csv("input/edu/dbo_AssetInventoryEDULatLong.csv", stringsAsFactors = FALSE)
studentPost <- read.csv('input/edu/sch_enr_pcode.txt', sep = "|", stringsAsFactors = FALSE)
eqao <- read.csv('input/edu/eqao_2017_2018.csv', stringsAsFactors = FALSE, fileEncoding = "UTF-8-BOM")

# Postal code to lat/long conversion file
pccf <- read.csv('input/edu/PCCF_ONT_2018.csv', stringsAsFactors = FALSE, fileEncoding = "UTF-8-BOM") 
```

# TRESO Data cleaning 

- Combine the population, household information
- Summarize by TRESO zones

```{r treso data cleaning, echo=FALSE}
# Clean hhld_df
hhld_tb <- select(hhld_df, hhid, treso_zone, income) %>%
  as_tibble()

# Clean pop_df and join with hhld
socio_economic_tb <- select(pop_df, hhid, treso_zone, age, hdgree, nocs_11, work_status, school_status) %>%
  as_tibble() %>%
  left_join(hhld_tb, by = c("hhid" , "treso_zone")) %>%
  mutate(adult = ifelse(age >= 21, 1, 0)) %>%
  mutate(child = ifelse(age < 21, 1, 0))

hhld_structure <- socio_economic_tb %>%
  group_by(hhid) %>%
  summarise(
    hhld_adult = sum(adult),
    hhld_child = sum(child),
    treso_zone = unique(treso_zone)
  ) %>%
  mutate(n_zero_adult = ifelse(hhld_adult == 0, 1, 0)) %>%
  mutate(n_one_adult_zero_child = ifelse(hhld_adult == 1 & hhld_child == 0, 1, 0)) %>%
  mutate(n_one_adult_one_child = ifelse(hhld_adult == 1 & hhld_child == 1, 1, 0)) %>%
  mutate(n_one_adult_two_child = ifelse(hhld_adult == 1 & hhld_child == 2, 1, 0)) %>%
  mutate(n_one_adult_twoplus_child = ifelse(hhld_adult == 1 & hhld_child > 2, 1, 0)) %>%
  mutate(n_two_adult_zero_child = ifelse(hhld_adult == 2 & hhld_child == 0, 1, 0)) %>%
  mutate(n_two_adult_one_child = ifelse(hhld_adult == 2 & hhld_child == 1, 1, 0)) %>%
  mutate(n_two_adult_two_child = ifelse(hhld_adult == 2 & hhld_child == 2, 1, 0)) %>%
  mutate(n_two_adult_twoplus_child = ifelse(hhld_adult == 2 & hhld_child > 2, 1, 0)) %>%
  mutate(n_twoplus_adult_zero_child = ifelse(hhld_adult > 2 & hhld_child == 0, 1, 0)) %>%
  mutate(n_twoplus_adult_one_child = ifelse(hhld_adult > 2 & hhld_child == 1, 1, 0)) %>%
  mutate(n_twoplus_adult_two_child = ifelse(hhld_adult > 2 & hhld_child == 2, 1, 0)) %>%
  mutate(n_twoplus_adult_twoplus_child = ifelse(hhld_adult > 2 & hhld_child > 2, 1, 0)) %>%
  # Group into treso ID
  select(treso_zone, n_zero_adult:n_twoplus_adult_twoplus_child) %>%
  group_by(treso_zone) %>%
  summarise_all(
    funs(sum)
  )

# Summarize into TRESO Zones
treso_tb <- socio_economic_tb %>%
  group_by(treso_zone) %>%
  summarise(
    n_pop = n(),
    n_hhlds = length(unique(hhid)),
    n_ft = length(treso_zone[work_status == "full_time"]),
    n_pt = length(treso_zone[work_status == "part_time"]),
    n_unemp = length(treso_zone[work_status == "unemployed"]),
    n_sec_pop = length(treso_zone[age <= 18 & age >= 13]),
    n_ele_pop = length(treso_zone[age <= 12 & age >= 3]),
    n_pre_pop = length(treso_zone[age <= 2]),
    
    mean_income = mean(income, na.rm = TRUE),
    mean_age = mean(age, na.rm = TRUE),
    
    occu_management = length(treso_zone[nocs_11 == 1]),
    occu_business = length(treso_zone[nocs_11 == 2]),
    occu_science = length(treso_zone[nocs_11 == 3]),
    occu_health = length(treso_zone[nocs_11 == 4]),
    occu_public = length(treso_zone[nocs_11 == 5]),
    occu_recreation = length(treso_zone[nocs_11 == 6]),
    occu_sales = length(treso_zone[nocs_11 == 7]),
    occu_trades = length(treso_zone[nocs_11 == 8]),
    occu_production = length(treso_zone[nocs_11 == 9]),
    occu_manufacturing = length(treso_zone[nocs_11 == 10]),
    occu_notapplicable = length(treso_zone[nocs_11 == 99]),
    attend_school = length(treso_zone[school_status == 2]),
    deg_none = length(treso_zone[hdgree == 1]),
    deg_hs = length(treso_zone[hdgree == 2]),
    deg_trades = length(treso_zone[hdgree == 3]),
    deg_ra = length(treso_zone[hdgree == 4]),
    deg_col = length(treso_zone[hdgree == 5]),
    deg_uni = length(treso_zone[hdgree == 6]),
    deg_ugrad = length(treso_zone[hdgree == 7]),
    deg_grad = length(treso_zone[hdgree == 8]),
    deg_na = length(treso_zone[hdgree == 88 | hdgree == 99])
  ) %>%
  left_join(hhld_structure, by = "treso_zone") %>%
  saveRDS("cache/treso_tb.rds")

# Clean global variables
rm(hhld_tb, socio_economic_tb, hhld_structure)
```

## Clean and Simplify Portables Data

- Assume that portable units are rounded at 0.75. So a protable with 1.8 units is rounded 2 units and a portable with
1.7 units is rounded to 1 unit
- Assume that 23 elementary or 21 secondary students per unit of portable
- Update the utilization of each school after adding in the portables

```{r clean portables, echo=FALSE}
# Sum total ground floor area and number of portable units by school
filterList <- c('cafe|child care|administration|other|commercial|general|best start|staff')

ELE_STUDENTS_UNIT_CLASS = 23
SEC_STUDENTS_UNIT_CLASS = 21
PORTABLE_UNIT_SIZE = 75

schoolAssetsPortablesSlim <- schoolAssetsPortables %>%
  select(sfis = SFIS_ID, year = Sch_yr, dsb.index = Dsb_index, facility.name = FacilityName, dataset.id = DataSetID,
         current.use = CurrentUse, area.m2 = GFA_m2, num.units = NumberOfUnits) %>%
  filter(dataset.id == 2, area.m2 > 0) %>%
  select(-dataset.id) %>%
  filter(!grepl(filterList, current.use, ignore.case = TRUE)) %>%
  group_by(year, dsb.index, sfis, facility.name) %>%
  summarise(
    area.m2 = sum(area.m2),
    num.units = sum(num.units)
  ) %>%
  ungroup() %>%
  # TODO check this is rounding to 0.75
  mutate(num.units.calculated = round(area.m2 / PORTABLE_UNIT_SIZE, 0))

# schoolSFIS <- readRDS('output/school_sfis_2017.rds') %>%
#   select(-area.m2, -num.units.calculated)

# Join Portables Data to School Data and recalculate utilization based on the size of portable
# schoolSFIS <- left_join(schoolSFIS, select(schoolAssetsPortablesSlim, sfis, area.m2, num.units.calculated), by = 'sfis') %>%
#   replace_na(list(area.m2 = 0, num.units.calculated = 0)) %>%
#   mutate(capacity.portable = ifelse(panel == 'Elementary', num.units.calculated * ELE_STUDENTS_UNIT_CLASS, 
#                                     num.units.calculated * SEC_STUDENTS_UNIT_CLASS)) %>%
#   mutate(capacity.total = otg + capacity.portable) %>%
#   mutate(utilization.total = ade / capacity.total)

# Utilization above 1 at this point could be erroneous data
# TODO check with Alec regarding this.
#print(paste0('There are ', length(filter(schoolSFIS, utilization.total > 1)$sfis), ' schools with utilization greater than 1.2.'))

#saveRDS(schoolSFIS, file = 'cache/school_sfis_2017.rds')
```

# Compile master list of schools, portables, sfis ID, geo coordinates, TRESO zone

- Produce dataframe with geocoordinates for all schools (past & present)

```{r}
# Read in geocoordinates for schools with missing data
# Geocoordinates were found using separate program and stored in CSV
missingCoords <- read_csv('input/edu/school_missing_geocoordinates.csv')
schoolBoardTypes <- read_csv('input/edu/school_board_types.csv')

# Create a table called schoolLoc to house master list for school geocoordinates, etc.
schoolLoc <- schoolCap %>%
  select(year = Sch_yr, 
         dsb.index = DSB_Index, 
         panel = Panel, 
         sfis = `SFIS_ID`,
         school.name = `FacilityName`, 
         status = Status,
         school.lat = `Latitude`, 
         school.long = `longitude`,
         otg = OTG,
         ade = ADE,
         board.name = BoardName,
         dataset.id = dataSetID) %>%
  filter(dataset.id == 2) %>%
  left_join(select(schoolBoardTypes, dsb, board_type_name), by = c('dsb.index' = 'dsb')) %>%
  mutate_if(is.factor, as.character) -> schoolLoc

# Join in geocoordinate data for missing schools
schoolLocUpdated <- schoolLoc %>%
  left_join(distinct(select(missingCoords, SFIS_ID, altLat = finalLatitude, altLon = finalLongitude)), by = c('sfis' = 'SFIS_ID')) %>%
  mutate(school.lat = ifelse(is.na(school.lat), altLat, school.lat)) %>%
  mutate(school.long = ifelse(is.na(school.long), altLon, school.long)) %>%
  select(-altLat, -altLon) %>% 
  arrange(status, otg, desc(ade))

# Keep a record of schools for which a lat/long cannot be determined
schoolLocMissing <- schoolLocUpdated %>%
  filter(is.na(school.lat)|is.na(school.long))

# Filter wacky results incl. remove NA values of lat/long from school location dataframe in order to run x/y retrieval
schoolLocClean <- schoolLocUpdated %>%
  filter(!is.na(school.lat) & !is.na(school.long)) %>%
  group_by(sfis) %>%
  mutate(otg = ifelse(status == 'Open' & otg == 0, max(ade), otg)) %>%
  ungroup()

# Simplify school forecast data (ADE and OTG) to join to historical school data, and
# filter out forecast data for years in which historical data is available
schoolForecastSimple <- schoolForecast %>%
  select(year = SCH_YR, 
         dsb.index = DSBINDEX,
         panel = PANEL,
         sfis = SFIS,
         school.name = School.Name, 
         ade = ADE,
         latitude,
         longitude) %>% 
  anti_join(distinct(select(schoolLocClean, sfis, year)), by = c('sfis', 'year')) %>% 
  mutate_if(is.factor, as.character) -> schoolForecastSimple

# Join board type, lat, long, otg to school forecast dataset

school_recent_data <- schoolLocClean %>%
  group_by(sfis) %>%
  filter(year == max(year), status == 'Open' | status == 'Holding' | status == 'Under Construction') %>%
  ungroup()

schoolForecastSimpleJoin <- schoolForecastSimple %>% 
  left_join(select(school_recent_data, sfis, board_type_name, board.name, school.lat, school.long, otg), by = c('sfis')) %>% 
  mutate(school.lat = ifelse(is.na(school.lat), latitude, school.lat)) %>% 
  mutate(school.long = ifelse(is.na(school.long), longitude, school.long)) %>%
  mutate(panel = ifelse(panel == 'E', 'Elementary', ifelse(panel == 'S', 'Secondary', 'ERROR')))

# Bind Historical school data to forecast school data

schoolLocCombined <- bind_rows(schoolLocClean, schoolForecastSimpleJoin)

# Choose single most common lat/long for schools to avoid row duplication and conflicts

schoolLatMode <- schoolLocCombined %>% 
  group_by(sfis) %>%
  count(school.lat, sort=TRUE) %>%
  slice(1)

schoolLongMode <- schoolLocCombined %>% 
  group_by(sfis) %>%
  count(school.long, sort=TRUE) %>%
  slice(1)

schoolLocCombinedFix <- schoolLocCombined %>% 
  select(-school.lat, -school.long) %>% 
  left_join(select(schoolLatMode, sfis, school.lat), by = c('sfis')) %>% 
  left_join(select(schoolLongMode, sfis, school.long), by = c('sfis')) %>% 
  select(-latitude, -longitude)

# Determine x & y coordinates for schools based on TRESO zone shapefile
schoolLocCombinedDistinct <- schoolLocCombinedFix %>%
  distinct(sfis, school.lat, school.long)

treso_shp <- readOGR(dsn = "input/treso", layer = "TRESO_Zones_SocioData_Gatineau_LCC")
school_xy <- create_school_xy_simple(schoolLocCombinedDistinct)

# Determine TRESO zone associated with each school's x & y coordinates
schoolTRESO <- create_overlay(school_xy, treso_shp, 'schoolSimple')

# Join schoolTRESO table to CD/CSD info 
tresoCSDmatch <- read_csv('input/treso/treso_zone_system.csv')
schoolTRESOcsd <- schoolTRESO %>%
  left_join(select(tresoCSDmatch, treso_id, csduid, cduid), by = c('treso.id.pos' = 'treso_id')) %>%
  mutate_if(is.factor, as.character) -> schoolTRESOcsd

# Join TRESO/CSD data to main schools dataframe; add in flags for OTG = 0, Utilization > 200%
school_treso_data <- schoolLocCombinedFix %>%
  left_join(select(schoolTRESOcsd, sfis, treso.id.pos, csduid, cduid), by = c('sfis')) %>%
  mutate(zero_otg_flag = ifelse(otg == 0, 1, 0)) %>%
  mutate(excessive_util_flag = ifelse(ade/otg >= 2, 1, 0)) %>%
  mutate(excessive_util_flag = replace_na(excessive_util_flag, 0))

# Join to portables data
school_treso_master <- school_treso_data %>%
  left_join(select(schoolAssetsPortablesSlim, sfis, area.m2, num.units.calculated, year), by = c('sfis' = 'sfis', 'year' = 'year')) %>%
  replace_na(list(area.m2 = 0, num.units.calculated = 0)) %>%
  mutate(num.units.calculated = round(num.units.calculated,0)) %>%
  mutate(capacity.portable = ifelse(panel == 'Elementary', num.units.calculated * ELE_STUDENTS_UNIT_CLASS, 
                                    num.units.calculated * SEC_STUDENTS_UNIT_CLASS))%>%
  rename(portable.units = num.units.calculated)

# Export to RDS
saveRDS(school_treso_master, 'output/school_treso_master.rds')

```

# Education Data cleaning
 
- Clean the school asset data
- Clean the school forecast data
- Then, clean school capacity and historical demand data
- Combine together 
- Clean the student postal code data

## Add FCI, renewal to asset data
```{r clean school assets, echo=FALSE}
# Retrieve FCI and renewal values
schoolAssetsSlim <- schoolAssets %>%
  filter(DataSetId == 2, Status == 'Open', Panel == 'School') %>%
  select(bid = BID, lat = Latitude, long = Longitude, ade = ADE,
         asset.name = AssetName, fci = FCI, year.built = YearBuilt, renewal.needs = RenewalNeeds.TotalRenewalAdj.,
         replacement.value = ReplacementValue, assessment.year = AssessmentYear) %>%
  drop_na(bid, lat, long, ade) %>% 
  left_join(select(schoolAssetsSFIS.BID, SFIS_ID, BUILDING.ID), by = c('bid' = 'BUILDING.ID')) %>% 
  mutate(sfis = as.numeric(SFIS_ID)) %>%
  select(-SFIS_ID, -bid, -lat, -long, -ade, -asset.name) %>% 
  arrange(sfis)

```

## Clean school capacity dataset
```{r education data cleaning, echo=FALSE}
# The school capacity dataset contains the correct lat/long for schools
schoolCapSlim <- schoolCap %>%
  select(year = Sch_yr, 
         dsb.index = DSB_Index, 
         board.name = BoardName, 
         panel = Panel, 
         sfis = `SFIS_ID`,
         school.name = `FacilityName`, 
         ade = ADE,
         otg = OTG, 
         school.lat = `Latitude`, 
         school.long = `longitude`, 
         status = Status, 
         dataset.id = dataSetID) %>%
  mutate(utilization = ifelse(otg != 0, ade / otg, 0)) %>%
  filter(year == 2017, status == "Open", dataset.id == 2, !is.na(school.lat), !is.na(school.long)) %>%
  # Remove schools with capacity of 0
  filter(otg != 0, ade != 0) %>%
  # Remove schools with ADE that is less than 50
  filter(ade >= 50) %>% 
  left_join(schoolAssetsSlim, by = c('sfis'))

# The school forecast dataset contains BSID which is needed to merge student postal code
# From inspection, there are same amount of school in each forecast year.
schoolForecastSlim <- schoolForecast %>%
  select(year = SCH_YR, 
         sfis = SFIS,
         bsid = BSID,
         dsb.index = DSBINDEX,
         school.name = School.Name, 
         ade.forecast = ADE,
         ade.sec.forecast = ADE_SEC,
         ade.elem.forecast = ADE_ELEM,
         ade.jksk.forecast = ADE_JKSK,
         ade.g1g3.forecast = ADE_G1G3, 
         ade.g4g8.forecast = ADE_G4G8) %>%
  filter(year == 2017, bsid != 0)

# Combine the School capacity data with the forecast data on SFIS
schoolSFIS <- left_join(schoolCapSlim, schoolForecastSlim, by = c('sfis')) %>%
  select(-school.name.y, -dsb.index.y) %>%
  rename(school.name = school.name.x, dsb.index = dsb.index.x) %>%
  arrange(sfis)

# Drop any school that does not have a corresponding forecast
unmatched_schools <- sum(is.na(schoolSFIS$bsid))                       
print(paste0('A total of ', unmatched_schools, ' schools are unmatched between capacity and forecast'))
schoolSFIS <- schoolSFIS %>%
  drop_na(bsid)

# The postal code and enrollment dataset is cleaned here
# We are looking at 2017 student data at this time.
studentPostSlim <- studentPost %>%
  select(year = Sch_YR,
         bsid = BSID, 
         dsb.index = dsbindex,
         school.name = School.Name, 
         student.postal.code = Student.Postal.Code,
         enrolment = Enrolment) %>%
  filter(year == 2017) %>%
  filter(str_length(student.postal.code) == 6) %>%
  mutate(enrolment = as.integer(enrolment))

num_schools_from_student_post <- length(unique(studentPostSlim$bsid))
num_schools_from_school_sfis <- length(unique(schoolSFIS$bsid))
print(paste0('A total of ', num_schools_from_student_post, ' unique schools are contained in student postal code dataset'))
print(paste0('A total of ', num_schools_from_school_sfis, ' unique schools are contained in the school dataset'))

# Clean global variables
rm(num_schools_from_student_post, num_schools_from_school_sfis)
```

## Create historical education dataset

- The historical trends of ADE is a valuable

```{r historical education data, echo=FALSE}
# The school capacity dataset contains the correct lat/long for schools
schoolCapHistorical <- schoolCap %>%
  select(year = Sch_yr, 
         dsb.index = DSB_Index, 
         board.name = BoardName, 
         panel = Panel, 
         sfis = `SFIS_ID`,
         school.name = `FacilityName`, 
         ade = ADE,
         otg = OTG,
         status = Status, 
         dataset.id = dataSetID) %>%
  mutate(utilization = ifelse(otg != 0, ade / otg, 0)) %>%
  filter(status == "Open", dataset.id == 2) %>%
  # Remove schools with capacity of 0
  filter(otg != 0, ade != 0) %>%
  # Remove schools with ADE that is less than 50
  filter(ade >= 50) %>%
  select(year, sfis, ade, otg, utilization) %>%
  saveRDS("input/edu/school_historical_capacity.rds")

```


## Calculate School Catchment Lengths

- First, join the school and student's together into one table based on `bsid`
- Then, join the postal code centroids with lat/long information to each student based on `postal.code`
- Filter the unmatched records from the table
- Find any schools with a ratio of ADE to enrolment below 0.8 and above 1.0 between the school and student data, remove these outliers
- Calculate the straight line travel distance between student to school based on lat/long information and `haverFunction()`
- Calcualte the manhattan line travel distance between student to school based on lat/long information and `manhattan()`

```{r join edu data, echo=FALSE}
# Join postal code centroids to student's postal code data
pccfSlim <- pccf %>%
  filter(SLI == 1) %>%
  select(postal.code = PostalCode,
         lat = LAT,
         long = LONG,
         retirement.date = Ret_Date) %>%
  group_by(postal.code) %>%
  filter(retirement.date == max(retirement.date))

# Create a list of postal codes with SLI == 1 but different lat/long
pccfSlim[duplicated(pccfSlim$postal.code) | duplicated(pccfSlim$postal.code, fromLast = TRUE), ] %>%
  arrange(postal.code) %>%
  group_by(postal.code, lat, long, retirement.date) %>%
  summarise(n = n()) %>%
  filter(n == 1)

# Combine school, student and postal data together
schoolCatchment <- schoolSFIS %>%
  select(sfis, bsid, school.name, school.lat, school.long, dsb.index, panel, ade) %>%
  left_join(select(studentPostSlim, bsid, student.postal.code, enrolment), by = c('bsid' = 'bsid'))

unmatched_schools <- schoolCatchment %>%
  filter(is.na(enrolment)) %>%
  group_by(sfis) %>%
  summarise(school.name = first(school.name), unmatched.enrollment = n())

unmatched_school_pct <- round(length(unique(unmatched_schools$sfis)) / length(unique(schoolSFIS$sfis)) * 100, 2)
print(paste0(unmatched_school_pct, '% of shcools are unmatched, and ', sum(unmatched_schools$unmatched.enrollment),
             ' students are unmatched after combining with student postal code'))

schoolCatchment <- schoolCatchment %>%
  drop_na(enrolment) %>%
  left_join(select(pccfSlim, student.lat = lat, student.long = long, postal.code), by = c('student.postal.code' = 'postal.code'))

unmatched_students <- round((length(unique(filter(schoolCatchment, is.na(student.lat))$student.postal.code)) / 
                             length(unique(filter(schoolCatchment, !is.na(student.lat))$student.postal.code))) * 100, 2)
print(paste0(unmatched_students, '% of students did not have a match between postal code and lat/long'))

schoolCatchment <- schoolCatchment %>%
  drop_na(student.lat, student.long)

# Check very low or very high Enrolment/ADE ratios and remove these
temp1 <- schoolSFIS %>%
  select(bsid, school.name, ade)
  
temp2 <- studentPostSlim %>%
  group_by(bsid) %>%
  summarise(
    enrolment = sum(enrolment)
  )

temp_tb <- left_join(temp1, temp2, by = 'bsid') %>%
  mutate(ratio = ade / enrolment) %>%
  arrange(ratio) %>%
  filter(ratio <= 0.8 | ratio >= 1.02)

num_outlier_matched <- round(length(temp_tb$bsid) / length(schoolSFIS$bsid) * 100, 2)
print(paste0(num_outlier_matched, '% of all schools is flagged due to a large mismatch between ADE and enrolment'))

schoolCatchment <- anti_join(schoolCatchment, temp_tb, by = 'bsid')

# Calculate straight-line home-to-school distances
schoolCatchment <- schoolCatchment %>%
  mutate(dist = haverFunction(school.lat, school.long, student.lat, student.long)) %>% 
  mutate(man.dist = manhattan(school.lat, school.long, student.lat, student.long))
```

## Remove outlier students

The data provided contains students travelling extremely far distances. This can be a source of error when calculating
the catchment areas for schools. For each school, the students outside of the whiskers of a typical boxplot are removed. 

- The end of whiskers is defined as [Q_1 - 1.5*IQR, Q_3 + 1.5IQR], and IQR is the difference between Q_3 and Q_1. 

```{r distance threshold filtering, fig.width=15}

schoolCatchmentThreshold <- schoolCatchment %>%
  uncount(enrolment) %>%
  group_by(school.name, school.lat, school.long) %>%
  summarise(
    lower_adj = boxplot.stats(man.dist)$stats[1],
    upper_adj = boxplot.stats(man.dist)$stats[5]
  )

schoolCatchment <- left_join(schoolCatchment, schoolCatchmentThreshold, by = c('school.name', 'school.lat', 'school.long')) %>%
  mutate(keep = as.factor(ifelse(man.dist <= upper_adj & man.dist >= lower_adj, 1, 0)))

# Plot stacked barplots of students within vs outside of threshold
schoolCatchment %>%
  uncount(enrolment) %>%
  ggplot(aes(x = panel, fill = keep)) +
  geom_bar() +
  facet_wrap(vars(dsb.index), scales = 'free_y')  +
  theme_minimal() + 
  labs(x = '', y = 'Enrolment', title = 'Threshold Analysis by DSB') +
  scale_fill_discrete(name = '', labels = c('Dropped', 'Kept')) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

num_outlier_students <- sum(filter(schoolCatchment, keep == '0')$enrolment)
num_within_students <- sum(filter(schoolCatchment, keep == '1')$enrolment)
print(paste0('Dropped ', num_outlier_students, ' students because they fall outside of acceptable threshold range.'))
print(paste0('Kept ', num_within_students, ' students because they fall inside of acceptable threshold range.'))

schoolCatchment <- schoolCatchment %>%
  filter(keep == '1')

# schoolCatchment %>%
#   filter(panel == 'Secondary', dsb.index == 14) %>%
#   uncount(enrolment) %>%
#   ggplot(aes(x = school.name, y = dist)) +
#   geom_boxplot(outlier.color = 'red')

```

``` {r students within catchment, echo=FALSE}
# Calculate the catchment distance by a specified quantile weighted with the enrolment of the school
percentileList <- c(0.9, 0.8, 0.7, 0.6, 0.5)
schoolCatchmentDistPercent <- schoolCatchment %>%
  group_by(sfis, school.name, school.lat, school.long) %>%
  # use a weighted quantile function to select the distance by enrolment
  summarise(
    panel = first(panel),
    list(
      enframe(
        wtd.quantile(man.dist, probs = percentileList, na.rm = FALSE, weight = enrolment)
        )
      )
    ) %>%
  unnest %>%
  ungroup() %>%
  rename(perc.value = name, perc.dist = value) %>%
  mutate(perc.value = as.numeric(sub("%", "", perc.value))/100)

schoolCatchmentDistPercent %>%
  group_by(perc.value, panel) %>%
  summarise(average.distance = mean(perc.dist)) %>%
  ggplot(aes(x = perc.value, y = average.distance, fill = panel)) +
  geom_bar(stat = 'identity', position = 'dodge') +
  labs(x = "Quantile", y = "Distance (KM)", title = "Average Catchment Distance of Schools") +
  theme_minimal()

# Select students within the catchment distance and export it
for (catchment_dist in percentileList){
  schoolCatchment %>%
    left_join(select(schoolCatchmentDistPercent, sfis, perc.dist, perc.value), by = c('sfis' = 'sfis')) %>%
    filter(perc.value == catchment_dist) %>%
    filter(man.dist <= perc.dist) %>%
    saveRDS(file = paste0('cache/student_travel_', as.character(catchment_dist), '.rds'))
}

rm(schoolCatchment, schoolCatchmentDistPercent, schoolCatchmentThreshold, percentileList, temp_tb)
```

### Quick Check of ADE vs Enrollment

```{r quick check, fig.height = 50, fig.width = 10}
# Check the enrollment total vs ADE numbers
temp1 <- schoolSFIS %>%
  select(bsid, school.name, ade, ade.forecast) %>%
  arrange(school.name)
  
temp2 <- studentPostSlim %>%
  group_by(bsid) %>%
  summarise(
    enrolment = sum(enrolment),
    school.name = first(school.name)
  ) %>%
  arrange(school.name)

temp <- left_join(temp1, temp2, by = "bsid") %>%
  drop_na(enrolment) %>%
  gather(key = 'key', value = 'value', ade, enrolment) %>%
  select(-school.name.y) %>%
  arrange(school.name.x) %>%
  mutate(facet_index = factor(row_number() %/% 100))

ggplot(data = temp, aes(fill = key, x = school.name.x, y = value)) +
  geom_bar(stat = "identity", position = 'dodge') +
  facet_wrap(~facet_index, ncol = 5, scales = 'free_x') +
  labs(x = '')

rm(temp1, temp2, temp)
```


### Visualization of percentile travel distance

```{r visualize travel distance}
student_travel <- readRDS(file = 'cache/student_travel_0.9.rds') %>%
  as_tibble() %>%
  group_by(sfis, school.name, school.lat, school.long) %>%
  summarise(distance = first(perc.dist))

ggplot(data = student_travel, aes(distance)) +
  geom_freqpoly(stat = "bin", binwidth = 5, size = 1) +
  labs(x = "Distance (KM)", y = "Count", title = "") +
  theme_minimal()

```

## Clean EQAO Data

- Remove not reported (N/R) and no data (N/D)
- Remove suppressed (SP)
- Keep only public and catholic school types
- Calculate mean and standard deviations for reading, writing, and mathematics across the same board/panel

```{r eqao, eval=FALSE}
eqaoSlim <- eqao %>%
  select(School.Number, School.Name, School.Type, School.Level, School.Language, Enrolment, Latitude, Longitude,
         Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Reading:Change.in.Grade.10.OSSLT.Literacy.Achievement.Over.Three.Years) %>%
  mutate_at(vars(matches("Percentage|Change")), list(~gsub(" *%", "", .))) %>%
  # Remove N/R (not-reported) and N/D (no-data)
  mutate_at(vars(matches("Percentage|Change")), list(~gsub("[A-z]\\/[A-z]", NA, .))) %>%
  # Remove SP (suppressed)
  mutate_at(vars(matches("Percentage|Change")), list(~gsub("[A-z][A-z]", NA, .))) %>%
  mutate_at(vars(matches("Percentage|Change")), list(~as.numeric(.))) %>%
  # Keep only "public" and "catholic"
  filter(School.Type %in% c("Public", "Catholic"))

eqao_distribution <- eqaoSlim %>%
  select_at(vars("School.Type", "School.Language", "School.Level", matches("Achieving.the.Provincial"))) %>%
  group_by(School.Type, School.Language, School.Level) %>%
  summarise_all(list(mean = mean, std = sd), na.rm = TRUE)

eqao_standardized <- left_join(eqaoSlim, eqao_distribution, by = c("School.Type", "School.Language", "School.Level")) %>%
  mutate(Grade.3.Reading.Standardized = (Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Reading - 
                                         Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Reading_mean) /
                                         Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Reading_std) %>%
  mutate(Grade.3.Writing.Standardized = (Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Writing - 
                                         Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Writing_mean) /
                                         Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Writing_std) %>%
  mutate(Grade.3.Mathematics.Standardized = (Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Mathematics - 
                                         Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Mathematics_mean) /
                                         Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Mathematics_std) %>%
  mutate(Grade.6.Reading.Standardized = (Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Reading - 
                                         Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Reading_mean) /
                                         Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Reading_std) %>%
  mutate(Grade.6.Writing.Standardized = (Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Writing - 
                                         Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Writing_mean) /
                                         Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Writing_std) %>%
  mutate(Grade.6.Mathematics.Standardized = (Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Mathematics - 
                                         Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Mathematics_mean) /
                                         Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Mathematics_std) %>%
  mutate(Grade.9.Academic.Mathematics.Standardized = (Percentage.of.Grade.9.Students.Achieving.the.Provincial.Standard.in.Academic.Mathematics - 
                                         Percentage.of.Grade.9.Students.Achieving.the.Provincial.Standard.in.Academic.Mathematics_mean) /
                                         Percentage.of.Grade.9.Students.Achieving.the.Provincial.Standard.in.Academic.Mathematics_std) %>%
  mutate(Grade.9.Applied.Mathematics.Standardized = (Percentage.of.Grade.9.Students.Achieving.the.Provincial.Standard.in.Applied.Mathematics - 
                                         Percentage.of.Grade.9.Students.Achieving.the.Provincial.Standard.in.Applied.Mathematics_mean) /
                                         Percentage.of.Grade.9.Students.Achieving.the.Provincial.Standard.in.Applied.Mathematics_std) %>%
  select_at(vars(School.Name, School.Number, School.Type, School.Language, School.Level, matches("Standardized"))) %>%
  mutate(eqao = select(., Grade.3.Reading.Standardized, Grade.3.Writing.Standardized, Grade.3.Mathematics.Standardized,
                           Grade.6.Reading.Standardized, Grade.6.Writing.Standardized, Grade.6.Mathematics.Standardized,
                           Grade.9.Academic.Mathematics.Standardized, Grade.9.Applied.Mathematics.Standardized) %>% rowSums(na.rm = TRUE)) %>%
  mutate(eqao.normalized = (eqao - min(eqao)) / (max(eqao) - min(eqao))) %>%
  mutate(eqao.standardized = eqao.normalized * 10) %>%
  select(School.Name, School.Number, School.Type, School.Language, School.Level, eqao.standardized)

saveRDS(eqao_standardized, file = 'cache/eqao_standardized_2017.rds')

```

# Health Data Cleaning

## Import Health Data

```{r, include=FALSE}
healthRodbc <-odbcConnect("NourDSN")

#Bed Census Data
healthDailyBedHistory <- sqlFetch(healthRodbc, "cap.MOH_DailyBedCensus_Historical")
healthDailyBedCensus <- sqlFetch(healthRodbc, "cap.MOH_DailyBedCensus_Summary")
healthDischarges <- sqlFetch(healthRodbc, "cap.MOH_Discharges")

#HBAM Data
# healthHBAMhistorical <- sqlFetch(healthRodbc, "cap.MOH_HBAM_HIS")
# healthHBAMprojected <- sqlFetch(healthRodbc, "cap.MOH_HBAM_Proj")
#Upload Updated HBAM Data (as per update from 06 Aug 2019)
healthHBAMhistorical <- read.csv('P:/Y362/2019/191-00826-00 MOI Capacity and Demand Model/3. Modelling/moi_cu_project/input/health/cap.MOH_HBAM_HIS.csv')
healthHBAMprojected <- read.csv('P:/Y362/2019/191-00826-00 MOI Capacity and Demand Model/3. Modelling/moi_cu_project/input/health/cap.MOH_HBAM_Proj.csv')

#Facility Data
healthLHINfacilityList <- sqlFetch(healthRodbc, "cap.MOH_LHIN_Hosp_Fac_List")
healthHospitalLocations <- sqlFetch(healthRodbc, "dbo.MOH_Hospital_Locations")

#LHIN Data
healthPopulationLHIN <- sqlFetch(healthRodbc, "dbo.Population_LHIN")
healthBedDays <- sqlFetch(healthRodbc, "cap.MOH_Pat_Bed_Days")

#Wait Times
healthWaitTime <- sqlFetch(healthRodbc, "cap.HospitalWaitTime")

#ALC Data
healthALCAge <- sqlFetch(healthRodbc, "cap.ALCAge")
healthALCAnnualVolume <- sqlFetch(healthRodbc, "cap.ALCAnnualVolumeAndTotalDays")
healthALCCases <- sqlFetch(healthRodbc, "cap.ALCCases")
healthALCDesignations <- sqlFetch(healthRodbc, "cap.ALCDesignations")
healthALCDischarge <- sqlFetch(healthRodbc, "cap.ALCDischargeDestination")
healthALCInpatientBedType <- sqlFetch(healthRodbc, "cap.ALCInpatientBedType")
healthALCMonthlyRatebySite <- sqlFetch(healthRodbc, "cap.ALCMonthlyRateByProvinceLHINFacilitySite")
healthALCMonthlyVolume <- sqlFetch(healthRodbc, "cap.ALCMonthlyVolumeAndTotalDays")
healthALCmostappropriate <- read_csv('P:/Y362/2019/191-00826-00 MOI Capacity and Demand Model/3. Modelling/moi_cu_project/input/health/ALC.MostAppropriateDischage from CCO_2019-06-28.csv')

#CIHI Data
healthCIHIFacilityNameID <- sqlFetch(healthRodbc, "cap.CIHI_FacilityName_FacilityID")
healthCIHIFacilityNumberOld <- sqlFetch(healthRodbc, "cap.CIHI_FacilityNumber_OLD")
healthCIHIHospitalBeds <- sqlFetch(healthRodbc, "cap.CIHI_Hospital_Beds")
healthCIHIWaitTimesRegion <- sqlFetch(healthRodbc, "cap.CIHI_Wait Times by Region")
healthCIHIWaitTimesProvince <- sqlFetch(healthRodbc, "cap.CIHI_Wait_Time_Data_by_Province")

#Health Asset Inventory
healthInventoryMOHLTC <- sqlFetch(healthRodbc, "dbo.AssetInventoryMOHLTC")
healthInventoryMOHLTCfid <- sqlFetch(healthRodbc, "dbo.AssetInventoryMOHLTC_FID_Map")
healthMOHLocations <- sqlFetch(healthRodbc, "dbo.MOH_Hospital_Locations")

#Lookup Tables
healthHospitalSiteLookup <- sqlFetch(healthRodbc, "xRef.HC_HospitalSite_Lookup")
healthLHINLookup <- sqlFetch(healthRodbc, "xRef.HC_LHIN_Lookup")

#Sample Population Extraction by LHIN
healthPopulationLHIN %>%
  filter(LHIN=='South West') %>%
  arrange(Year, Gender, Age)

#List of Care-Types
caretypes <- healthHBAMprojected %>%
  distinct(Care_Type)
```

##Bed Census Data Cleaning and Analysis
```{r}
bedhistoryslim <- healthDailyBedHistory %>% 
  group_by('Facility #', 'Master #', 'Care Type', 'Fiscal Year')

bedcensusslim <- healthDailyBedCensus %>% 
  drop_na(FISCALYEAR) %>% #Years with NULL under FISCALYEAR also have empty rows
  mutate(HALLWAYPATIENTS = ERSTRETCHERSUSED + UNCONVENTIONALBEDSUSED) %>%
  arrange(FACILITY_NO, INST, FISCALYEAR, CENSUSDATE)

#Max Bed-count per Hospital
bedcensustotal <- bedcensusslim %>% 
  group_by(INST, FISCALYEAR, TYPE) %>% 
  summarise(maxbeds = max(BEDSWITHSTAFFAVAILABLE, na.rm = TRUE)
            )
#Count Daily Entries by Year
bedcensusslim %>% 
  ungroup(INST, TYPE) %>%
  group_by(FISCALYEAR) %>% 
  distinct(CENSUSDATE) %>% 
  count(CENSUSDATE) %>% 
  summarise(totaldays = sum(n, na.rm = TRUE))

#Total Daily Entries by SiteID: 2017:294 / 2018: 234
bedcensusslim %>% 
  group_by(INST,FISCALYEAR) %>% 
  count(INST)

#Count Total Site IDs: 448
bedcensusslim %>% 
  group_by(INST) %>% 
  distinct(INST)

#Bed-Days by Census Total
beddaystotal <- bedcensusslim %>% 
  group_by(INST, FISCALYEAR) %>% 
  summarise(bedaystotal = sum(BEDSWITHSTAFFAVAILABLE, na.rm = TRUE))

#Check if Hospitals have multiple care-types per year
bedcensustotal %>% 
  count(INST) %>% 
  filter(n > 2)

#List of Care-Types
bedcensusslim %>% 
  distinct(TYPE)
```

##Discharge Data
```{r}
#Health Discharges
totaldaystest <- healthDischarges %>% 
  select(SITE_ID, Total_Days, TOTAL_DAYS1, DaysInYear)

discharges <- healthDischarges %>% 
  mutate(totaldays = Total_Days + as.numeric(TOTAL_DAYS1),
         agegroup = as.character(AGE_GROUP)) %>% 
  select(fiscalyear = FY, 
         hospitalcorporation = HOSPITAL_CORPORATION, 
         facilityid = FACILITY_NO,
         hospitalname = HOSPITAL_NAME, 
         siteid = SITE_ID,
         agegroup,
         bedtype = "Bed Type",
         discharges = Discharges,
         totaldays,
         activecases = Active_Cases
         ) %>% 
  separate(agegroup, c("agegroup", "agedef"), sep = " ") %>%
  mutate(agegroup = replace(agegroup, agegroup == 0, 1)) %>%
  mutate(agegroup = replace(agegroup, agegroup == 7, 6)) %>%
  select(-agedef)
 
#Total Discharges and Days by CT (Test for AT/ED = NA)
discharges %>% 
  group_by(bedtype) %>% 
  summarise(totaldays = sum(totaldays),
            totalcases = sum(activecases)
            )

```
##HBAM Data
```{r}
#Age Group Testing - Age groups replaced with dates ("07-Jan") tested as proportion of 0-17
healthHBAMhistorical %>% 
  filter(grepl("<1|07-Jan|17-Aug|0-17", Age_Group)) %>% 
  group_by(Age_Group) %>% 
  summarise(totalagegroup = sum(Number_of_Cases))

#HBAM Historical Data
hbamhistorical <- healthHBAMhistorical %>% 
  select(year = YR, 
         totalcases = Number_of_Cases,
         hospitalname = Hospital_Site_Name, 
         siteid = Hospital_Site_ID, 
         agegroup = Age_Group, 
         caretype = Care_Type,
         csd = CSD) %>%
  filter(agegroup != "07-Jan", 
         agegroup != "17-Aug", 
         agegroup != "<1")

healthHBAMprojected %>% 
  filter(grepl("<1|07-Jan|17-Aug|0-17", Age_Group)) %>% 
  group_by(Age_Group) %>% 
  summarise(totalagegroup = sum(Number_of_Cases))

#HBAM Projected Data
hbamproj <- healthHBAMprojected %>% 
  select(year = Yr, 
         totalcases = Number_of_Cases,
         totalweightedcases = Number_of_Weighted_Cases,
         hospitalname = Hospital_Site_Name, 
         siteid = Hospital_Site_ID, 
         agegroup = Age_Group, 
         lengthofstay = Length_of_Stay,
         caretype = Care_Type)

```

## ALC Data

- ALC Site number Counts: Total SiteID 647, ALC Total Counts 348, ALC Counts 4-digit IDs 201, Total Joined IDs 169      
```{r}
#ALC Annual Volume
ALCannualvol <- healthALCAnnualVolume %>% 
  filter(CaseType == 9, 
         AgeGroup != 9,
         AgeGroup != 7,
         DischargeDestination != "ALL") %>% 
  select(year = Year,
         facilityid = SiteNumber,
         freq = Frequency,
         casetype = CaseType,
         bedtype = InPatientBedType,
         agegroup = AgeGroup,
         dd = DischargeDestination,
         losmean = Mean,
         losmed = Median,
         los90thp = "90thP",
         totalALCdays = TotalALCDays,
          )

#Join to Facility Data to Eliminate Overcounted IDs (from 145k entries to 61k entries)
ALCannualjoin <- ALCannualvol %>% 
  inner_join(healthMOHLocations, by = c('facilityid' = 'Master Number'))

ALCannualjoin %>% 
  group_by(year) %>% 
  drop_na(totalALCdays) %>% 
  summarise(annualALC = sum(totalALCdays))

#ALC by Age Group
ALCvolage <- ALCannualvol %>%
  left_join(healthALCAge, by=c('agegroup' = 'Id')) %>%
  group_by(year, AgeRange) %>%
  summarise(annualALCdays = sum(totalALCdays),
            annualALCcases = sum(freq)) %>% 
  drop_na(AgeRange)

#ALC Percentage by DD (test)
ALCbydd <- ALCannualvol %>% 
  group_by(year, dd) %>% 
  summarise(annualALCdaysbydd = sum(totalALCdays)) %>% 
  mutate(percent = percent(annualALCdaysbydd / sum(annualALCdaysbydd)))

#ALC Most Appropriate
ALCmaddvol <- healthALCmostappropriate %>% 
  filter(TYPEFLAG == 'MADD', 
         madd != 'ALL', #filter out sum values for DD
         Agerange != 9,
         casetype == 9) %>%
  separate(period, c("year", "month"), sep = "_") %>%
  filter(SUM != "LV") %>% #filter out NA values
  select(year,
         month,
         facilityid = sitenumber,
         freq = "_FREQ_",
         casetype,
         bedtype = INPATIENTBEDTYPE,
         agegroup = Agerange,
         dd = DD,
         madd,
         losmean = MEAN,
         losmedian = MEDIAN,
         los90thp = P90,
         totalALCdays = SUM) %>% 
  mutate(totalALCdays = as.numeric(totalALCdays),
         losmean = as.numeric(losmean),
         losmedian = as.numeric(losmedian),
         los90thp = as.numeric(los90thp))
  
#ALC MADD Annual Totals (test)
ALCmaddtotalvol <- ALCmaddvol %>% 
  inner_join(healthMOHLocations, by = c("facilityid" = "Master Number")) %>% 
  group_by(year) %>%
  summarise(annualALCdays = sum(totalALCdays, na.rm = TRUE),
            annualALCcases = sum(freq))  

#ALC Percentage by MADD (test)
ALCbymadd <- ALCmaddvol %>% 
  group_by(year, madd) %>% 
  summarise(ALCdaysbymadd = sum(totalALCdays)) %>% 
  mutate(percent = ALCdaysbymadd / sum(ALCdaysbymadd))

```
