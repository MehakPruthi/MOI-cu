---
title: "MOI Data Clean-up"
Feb-Apr 2019
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(weights)
source("helpers.R")
```


# Import data
```{r}

# TRESO data
hhld_df <- data.table::fread("input/households_2011.csv.gz")
pop_df <- data.table::fread("input/persons_2011.csv.gz")

# School Data
schoolCap <- read.csv("input/school_capacity.csv", stringsAsFactors = FALSE)
schoolForecast <- read.csv("input/school_forecast.csv", stringsAsFactors = FALSE)
SchoolAssets <- read.csv("input/school_assets.csv", stringsAsFactors = FALSE)
schoolAssetsPortables <- read.csv("input/school_assets_portables.csv", stringsAsFactors = FALSE)
schoolPost <- read.csv('input/sch_enr_pcode.txt', sep = "|", stringsAsFactors = FALSE)
# postal code to lat/long conversion file
pccf <- read.csv('input/PCCF_ONT_2018.csv', stringsAsFactors = FALSE, fileEncoding = "UTF-8-BOM") 

# Office Data
#officeSpace <- sqlFetch(schoolRodbc, "cap.IOAnnualSpaceBaselineBuilding")
#officeSpace %>%
#  write.csv('P:/Y362/2019/191-00826-00 MOI Capacity and Demand Model/3. Modelling/OfficeSpaceData.csv', row.names = FALSE)

#officeSpaceAssets <- sqlFetch(schoolRodbc, "dbo.AssetInventoryIO")
#officeSpaceAssets %>%
#  write.csv('P:/Y362/2019/191-00826-00 MOI Capacity and Demand Model/3. Modelling/OfficeSpaceAssetData.csv', row.names = FALSE)

```

## TRESO Data cleaning 

- Combine the population, household information
- Summarize by TRESO zones

```{r treso data cleaning}
# Clean hhld_df
hhld_tb <- select(hhld_df, hhid, treso_zone, income) %>%
  as.tibble()

# Clean pop_df and join with hhld
socio_economic_tb <- select(pop_df, hhid, treso_zone, age, hdgree, nocs_11, work_status, school_status) %>%
  as.tibble() %>%
  left_join(hhld_tb, by = c("hhid" , "treso_zone"))

# Summarize into TRESO Zones
treso_tb <- socio_economic_tb %>%
  group_by(treso_zone) %>%
  summarise(
    n_pop = n(),
    n_hhlds = length(unique(hhid)),
    n_ft = length(treso_zone[work_status == "full_time"]),
    n_pt = length(treso_zone[work_status == "part_time"]),
    n_unemp = length(treso_zone[work_status == "unemployed"]),
    n_sec_pop = length(treso_zone[age <= 18 & age >= 13]),
    n_ele_pop = length(treso_zone[age <= 12 & age >= 3]),
    n_pre_pop = length(treso_zone[age <= 2]),
    
    mean_income = mean(income, na.rm = TRUE),
    mean_age = mean(age, na.rm = TRUE),
    
    occu_management = length(treso_zone[nocs_11 == 1]),
    occu_business = length(treso_zone[nocs_11 == 2]),
    occu_science = length(treso_zone[nocs_11 == 3]),
    occu_health = length(treso_zone[nocs_11 == 4]),
    occu_public = length(treso_zone[nocs_11 == 5]),
    occu_recreation = length(treso_zone[nocs_11 == 6]),
    occu_sales = length(treso_zone[nocs_11 == 7]),
    occu_trades = length(treso_zone[nocs_11 == 8]),
    occu_production = length(treso_zone[nocs_11 == 9]),
    occu_manufacturing = length(treso_zone[nocs_11 == 10]),
    occu_notapplicable = length(treso_zone[nocs_11 == 99]),
    attend_school = length(treso_zone[school_status == 2]),
    deg_none = length(treso_zone[hdgree == 1]),
    deg_hs = length(treso_zone[hdgree == 2]),
    deg_trades = length(treso_zone[hdgree == 3]),
    deg_ra = length(treso_zone[hdgree == 4]),
    deg_col = length(treso_zone[hdgree == 5]),
    deg_uni = length(treso_zone[hdgree == 6]),
    deg_ugrad = length(treso_zone[hdgree == 7]),
    deg_grad = length(treso_zone[hdgree == 8]),
    deg_na = length(treso_zone[hdgree == 88 | hdgree == 99])
  ) %>%
  saveRDS("output/treso_tb.rds")

# Clean global variables
rm(hhld_tb, socio_economic_tb)
```


## Education Data cleaning

First, clean the school forecast data.

```{r}
schoolForecastSlim <- schoolForecast %>%
  rename(projectionYear = `Projection.Year`) %>%
  # select(projectionYear, SCH_YR, DSBINDEX, PANEL, ADE_JKSK, ADE_G1G3, ADE_G4G8, ADE_SEC, ADE)
  group_by(SCH_YR, DSBINDEX) %>%
  mutate(boardADE = sum(ADE), boardADEsec = sum(ADE_SEC), boardADEelem = sum(ADE_ELEM), boardADEjksk = sum(ADE_JKSK), 
         boardADEg1g3 = sum(ADE_G1G3), boardADEg4g8 = sum(ADE_G4G8)) %>%
  distinct(projectionYear, SCH_YR, DSBINDEX, boardADE, boardADEsec, boardADEelem, boardADEjksk, boardADEg1g3, boardADEg4g8) %>%
  arrange(DSBINDEX, SCH_YR)
```

Then, cleaning school capacity and historical demand data
```{r}
schoolCapSlim <- schoolCap %>%
  select(Sch_yr, DSB_Index, BoardName, Panel, SFIS_ID, FacilityName, ADE, OTG, Latitude, longitude, Status, dataSetID) %>%
  mutate(utilization = ADE / OTG) %>%
  filter(Status == "Open", dataSetID == 2) %>%
  arrange(desc(utilization), Sch_yr, SFIS_ID)

```

## Calculate School Catchment Areas
```{r}
#Step 1: Student Postal Code Data Cleanup
schoolPostSlim <- schoolPost %>%
  filter(Sch_YR == 2017) %>%
  filter(str_length(Student.Postal.Code) == 6) %>%
  mutate(Enrolment = as.integer(Enrolment), student_postal_id = row_number())

#Step 2: Join School forecast data to Postal Code data to match SFIS_ID to BSID
schoolBSID <- schoolForecast %>%
  filter(SCH_YR == 2017) %>%
  select(BSID, schoolName = `School.Name`, SFIS, schoolLat = latitude, schoolLong = longitude, DSBINDEX, PANEL) %>%
  group_by(BSID, schoolName, SFIS, schoolLat, schoolLong) %>%
  arrange(schoolName)

#Step 3: Join postal code centroids to school data
pccfSlim <- pccf %>%
  filter(SLI == 1)

schoolCatchment <- schoolBSID %>%
  select(BSID, SFIS, schoolName, schoolLat, schoolLong, DSBINDEX, PANEL) %>%
  left_join(select(schoolPostSlim, BSID, Student.Postal.Code, Enrolment, student_postal_id), by = c('BSID' = 'BSID')) %>%
  left_join(select(pccfSlim, studentLat = LAT, studentLong = LONG, PostalCode), by = c('Student.Postal.Code' = 'PostalCode')) %>%
  drop_na(studentLat, studentLong)

#Step 4: Calculate straight-line home-to-school distances by BSID
schoolCatchmentDist <- schoolCatchment %>%
  mutate(dist = haverFunction(schoolLat, schoolLong, studentLat, studentLong))
  #mutate(dist = mapply(function(haverFunction(lat1, long1, lat2, long2), schoolLat, schoolLong, studentLat, studentLong))
  #mutate(dist = pmap(haverFunction(lat1, long1, lat2, long2), schoolLat, schoolLong, studentLat, studentLong))

#Step 5: Calculate the catchment distance by a specified quantile weight by enrolment of the school
percentileList <- c(0.9, 0.8, 0.7, 0.5, 0.1)
schoolCatchmentDistPercent <- schoolCatchmentDist %>%
  arrange(schoolName, dist) %>%
  group_by(BSID, schoolName, schoolLat, schoolLong, DSBINDEX) %>%
  # use a weighted quantile function to select the distance by enrolment
  summarise(
    PANEL = first(PANEL),
    list(
      enframe(
        wtd.quantile(dist, probs = percentileList, na.rm = FALSE, weight = Enrolment)
        )
      )
    ) %>%
  unnest %>%
  ungroup() %>%
  rename(perc_name = name, percDist = value) %>%
  mutate(perc_value = as.numeric(sub("%","",perc_name))/100)

#Step 6: Select students within the catchment distance and export it
for (catchment_dist in percentileList){
  schoolCatchmentDist %>%
    left_join(select(schoolCatchmentDistPercent, BSID, percDist, perc_value), by = c('BSID' = 'BSID')) %>%
    filter(perc_value == catchment_dist) %>%
    filter(dist <= percDist) %>%
    saveRDS(file = paste0('output/student_travel_', as.character(catchment_dist), '.rds'))
}

```

## Clean and Simplify Portables Data
```{r}
#Select most recent Portable Data year for each school
#schoolPortableYears <- schoolAssetsPortables %>%
  #filter(DataSetID == 2, sch_yr = 2017) %>%
  #select(SFIS_ID, Sch_yr) %>%
  #group_by(SFIS_ID) %>%
  #summarise(Sch_yr_max = max(Sch_yr))

#Join most recent portable data to School Asset data, and sum total Ground Floor Area and Number of Portable Units by school
filtList <- c('cafe|child care|administration|other|commercial|general|best start|staff')

schoolAssetsPortablesSlim <- schoolAssetsPortables %>%
  filter(DataSetID == 2, Sch_yr == 2017) %>%
  #filter out non-classroom room types
  filter(!grepl(filtList, CurrentUse, ignore.case = TRUE)) %>%
  #inner_join(schoolPortableYears, by = c('SFIS_ID' = 'SFIS_ID', 'Sch_yr' = 'Sch_yr_max')) %>%
  select(Sch_yr, Dsb_index, SFIS_ID, FacilityName, GFA_m2, NumberOfUnits) %>%
  group_by(Sch_yr, Dsb_index, SFIS_ID, FacilityName) %>%
  summarise(sum(GFA_m2), sum(NumberOfUnits))

```

Join Portables Data to School Cap/ADE Data
```{r}
#BID is unique field in AssetInventoryEDU when using only DataSetID = 2 and BID is not null
schoolCapSlim %>%
  left_join(schoolAssetsPortablesSlim, by = c('SFIS_ID' = 'SFIS_ID')) %>%
  arrange(SFIS_ID)
  #write.csv(.,file = "P:/Y362/2019/191-00826-00 MOI Capacity and Demand Model/3. Modelling/schoolCapPortables.csv")
```

Plot School Data
```{r}
options(scipen=999) # turn off scientific notation like 1e+06
g <- ggplot(schoolCapSlim, aes(x=SFIS_ID, y=utilization)) +
  geom_bar(stat="identity") +
  ggtitle("School Utilization") + 
  theme_grey() +
  ylim(c(0, 10))
#max(SchoolCapSlim$utilization)))

g
```


```{r}
SchoolAssets %>%
  filter(DataSetId == 2)
  #filter(!is.na(BID)) %>%

#schoolAssetsLatLong %>%
  #select(`BUILDING ID`, X_COORD, Y_COORD) %>%
  #drop_na(`BUILDING ID`) %>%
  #mutate(X_COORD_round = round(X_COORD, 3), Y_COORD_round = round(Y_COORD, 3)) %>%
  #distinct(`BUILDING ID`, X_COORD_round, Y_COORD_round) %>%
  #Several BUILDING IDs are being repeated because coordinates are recorded differently for duplicate copies of the Building ID; this happens at all scales of precision; must choose acceptable level of precision and then choose mechanism for selecting "correct" lat/long
  #summarise(n())
schoolCap
```


*Push Health Data into SQL Server
```{r}
#Loading Health Bed Census Summary data into SQL Server
#healthBedsSummary <- read.csv('P:/Y362/2019/191-00826-00 MOI Capacity and Demand Model/3. Modelling/Received files/Data received 2019-03-01/MOH_DailyBedCensus_Summary.txt')
#sqlSave(healthRodbc,healthBedsSummary,"cap.MOH_DailyBedCensus_Summary",safer=FALSE, fast=TRUE)
```



*Import Health Data
```{r}
healthRodbc <-odbcConnect("SQLDNS")

healthDailyBedHistory <- sqlFetch(healthRodbc, "cap.MOH_DailyBedCensus_Historical")
healthDailyBedCensus <- sqlFetch(healthRodbc, "cap.MOH_DailyBedCensus_Summary")
healthDischarges <- sqlFetch(healthRodbc, "cap.MOH_Discharges")

healthHBAMhistorical <- sqlFetch(healthRodbc, "cap.MOH_HBAM_HIS")
healthHBAMprojected <- sqlFetch(healthRodbc, "cap.MOH_HBAM_Proj")

healthLHINfacilityList <- sqlFetch(healthRodbc, "cap.MOH_LHIN_Hosp_Fac_List")
healthHospitalLocations <- sqlFetch(healthRodbc, "dbo.MOH_Hospital_Locations")

healthPopulationLHIN <- sqlFetch(healthRodbc, "dbo.Population_LHIN")
healthBedDays <- sqlFetch(healthRodbc, "cap.MOH_Pat_Bed_Days")

healthWaitTime <- sqlFetch(healthRodbc, "cap.HospitalWaitTime")

#ALC Data
healthALCAge <- sqlFetch(healthRodbc, "cap.ALCAge")
healthALCAnnualVolume <- sqlFetch(healthRodbc, "cap.ALCAnnualVolumeAndTotalDays")
healthALCCases <- sqlFetch(healthRodbc, "cap.ALCCases")
healthALCDesignations <- sqlFetch(healthRodbc, "cap.ALCDesignations")
healthALCDischarge <- sqlFetch(healthRodbc, "cap.ALCDischargeDestination")
healthALCInpatientBedType <- sqlFetch(healthRodbc, "cap.ALCInpatientBedType")
healthALCMonthlyRatebySite <- sqlFetch(healthRodbc, "cap.ALCMonthlyRateByProvinceLHINFacilitySite")
healthALCMonthlyVolume <- sqlFetch(healthRodbc, "cap.ALCMonthlyVolumeAndTotalDays")

#CIHI Data
healthCIHIFacilityNameID <- sqlFetch(healthRodbc, "cap.CIHI_FacilityName_FacilityID")
healthCIHIFacilityNumberOld <- sqlFetch(healthRodbc, "cap.CIHI_FacilityNumber_OLD")
healthCIHIHospitalBeds <- sqlFetch(healthRodbc, "cap.CIHI_Hospital_Beds")
healthCIHIWaitTimesRegion <- sqlFetch(healthRodbc, "cap.CIHI_Wait Times by Region")
healthCIHIWaitTimesProvince <- sqlFetch(healthRodbc, "cap.CIHI_Wait_Time_Data_by_Province")

#Health Asset Inventory
healthInventoryMOHLTC <- sqlFetch(healthRodbc, "dbo.AssetInventoryMOHLTC")
healthInventoryMOHLTCfid <- sqlFetch(healthRodbc, "dbo.AssetInventoryMOHLTC_FID_Map")

#Lookup Tables
healthHospitalSiteLookup <- sqlFetch(healthRodbc, "xRef.HC_HospitalSite_Lookup")
healthLHINLookup <- sqlFetch(healthRodbc, "xRef.HC_LHIN_Lookup")

healthPopulationLHIN %>%
  filter(LHIN=='South West') %>%
  arrange(Year, Gender, Age)

healthHBAMprojected %>%
  distinct(Care_Type)

```

*Import MAG Data
```{r}

```




