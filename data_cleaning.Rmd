---
title: "MOI Data Clean-up"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(weights)
library(RODBC)
library(sp)
library(rgdal)
library(rgeos)
source("helpers.R")
```


# TRESO Data Cleaning

## TRESO Travel Time Skim Prep

- The intra-zonal travel times from TRESO is 0, this requires some extra work to take care of.
- Assumptions made are the following:
  - Known intra-zonal trips which are less than or equal to 2.5 km in length are performed by walking at an average speed of 5 km/hr. 
  - Known intra-zonal trips more than 2.5 km in length are performed by driving at an average speed of 30 km/hr.
  - Extremely long inter-zonal travel times (greater than 30 min difference between travel time skim and euclidean travel time at 30 km/hr) are set to euclidean travel time.
  - Leaving unknown intra-zonal travel time to be estimated from the size of the TRESO shapefile. Four levels of TRESO sizes are determined from quantile calculation. Level 1 and 2 sized shapes are assumed to have a distance that is the square root of its area to be traversed at 15 km/hr. Level 2 and 3 sized shapes are assumed to have a distance that is the square root of its area to be traversed at 60 km/hr.

```{r treso travel time prep, echo=FALSE, eval=FALSE}
# TRESO time skim
travel_time_skim_square <- read_csv("input/treso/mf224.csv.gz")

travel_time_skim <- travel_time_skim_square %>%
  reshape2::melt(id = c("p/q/[val]")) %>%
  rename(orig = "p/q/[val]", dest = variable) %>%
  mutate(orig = as.numeric(orig), dest = as.numeric(levels(dest))[dest]) %>%
  filter(orig %in% treso_shp@data$Treso_ID) %>%
  filter(dest %in% treso_shp@data$Treso_ID)

# The reason for creating a master list is to save time computation time on left_join()
travel_time <- readRDS("output/edu/observed_por_pos_90.rds") %>%
  drop_na(treso.id.por) %>%
  group_by(treso.id.por, treso.id.pos) %>%
  summarise(euclidean.dist = weighted.mean(euclidean.dist, enrolment)) %>%
  ungroup() %>%
  right_join(travel_time_skim, by = c("treso.id.por" = "orig", "treso.id.pos" = "dest")) %>%
  rename(travel.time = value)

summary(travel_time$travel.time)

treso_area <- treso_shp@data %>%
  select(treso.id = Treso_ID, area = Area) %>%
  mutate(area.km = area / 1000000) %>%
  mutate(length = sqrt(area.km))
treso_area_quantile <- quantile(treso_area$area.km)

print(paste0("Zones with an area between ", round(treso_area_quantile[4][[1]], 2), " - ",
             round(treso_area_quantile[5][[1]], 2), " km^2 are categorized as extra large."))
print(paste0("Zones with an area between ", round(treso_area_quantile[3][[1]], 2), " - ",
             round(treso_area_quantile[4][[1]], 2), " km^2 are categorized as large."))
print(paste0("Zones with an area between ", round(treso_area_quantile[2][[1]], 2), " - ",
             round(treso_area_quantile[3][[1]], 2), " km^2 are categorized as medium"))
print(paste0("Zones with an area between ", round(treso_area_quantile[1][[1]], 2), " - ",
             round(treso_area_quantile[2][[1]], 2), " km^2 are categorized as small"))

treso_intrazonal_travel_time <- treso_area %>%
  mutate(size.category = "extra large") %>% 
  mutate(size.category = ifelse(area.km <= treso_area_quantile[4][[1]], "large", size.category)) %>% 
  mutate(size.category = ifelse(area.km <= treso_area_quantile[3][[1]], "medium", size.category)) %>%
  mutate(size.category = ifelse(area.km <= treso_area_quantile[2][[1]], "small", size.category)) %>% 
  mutate(intra.zonal.travel.time = ifelse(size.category %in% c("extra large", "large"), length / 60 * 60, length / 15 * 60))

travel_time1 <- travel_time %>%
  mutate(euclidean.travel.time = ifelse(euclidean.dist <= 2.5,
                                        euclidean.dist / 5 * 60,
                                        euclidean.dist / 30 * 60)) %>%
  mutate(travel.time = ifelse((travel.time == 0 & !is.na(euclidean.travel.time)), 
                              euclidean.travel.time, 
                              travel.time)) %>%
  mutate(compare.travel.time = travel.time - euclidean.travel.time) %>%
  mutate(travel.time = ifelse((compare.travel.time > 30 & !is.na(compare.travel.time)), 
                              euclidean.travel.time, 
                              travel.time)) %>%
  left_join(treso_intrazonal_travel_time, by=c("treso.id.pos"="treso.id")) %>%
  mutate(travel.time = ifelse((travel.time == 0 & treso.id.por == treso.id.pos), 
                              intra.zonal.travel.time,
                              travel.time)) %>%
  select(treso.id.por, treso.id.pos, value = travel.time) %>%
  arrange(treso.id.por, treso.id.pos)

saveRDS(travel_time1, "cache/treso/treso_travel_time.rds")
```

## TRESO Data cleaning 
```{r treso data cleaning, echo=FALSE}
# Clean hhld_df
hhld_tb <- select(hhld_df, hhid, treso_zone, income) %>%
  as_tibble()

# Clean pop_df and join with hhld
socio_economic_tb <- select(pop_df, hhid, treso_zone, age, hdgree, nocs_11, work_status, school_status) %>%
  as_tibble() %>%
  left_join(hhld_tb, by = c("hhid" , "treso_zone")) %>%
  mutate(adult = ifelse(age >= 21, 1, 0)) %>%
  mutate(child = ifelse(age < 21, 1, 0))

hhld_structure <- socio_economic_tb %>%
  group_by(hhid) %>%
  summarise(
    hhld_adult = sum(adult),
    hhld_child = sum(child),
    treso_zone = unique(treso_zone)
  ) %>%
  mutate(n_zero_adult = ifelse(hhld_adult == 0, 1, 0)) %>%
  mutate(n_one_adult_zero_child = ifelse(hhld_adult == 1 & hhld_child == 0, 1, 0)) %>%
  mutate(n_one_adult_one_child = ifelse(hhld_adult == 1 & hhld_child == 1, 1, 0)) %>%
  mutate(n_one_adult_two_child = ifelse(hhld_adult == 1 & hhld_child == 2, 1, 0)) %>%
  mutate(n_one_adult_twoplus_child = ifelse(hhld_adult == 1 & hhld_child > 2, 1, 0)) %>%
  mutate(n_two_adult_zero_child = ifelse(hhld_adult == 2 & hhld_child == 0, 1, 0)) %>%
  mutate(n_two_adult_one_child = ifelse(hhld_adult == 2 & hhld_child == 1, 1, 0)) %>%
  mutate(n_two_adult_two_child = ifelse(hhld_adult == 2 & hhld_child == 2, 1, 0)) %>%
  mutate(n_two_adult_twoplus_child = ifelse(hhld_adult == 2 & hhld_child > 2, 1, 0)) %>%
  mutate(n_twoplus_adult_zero_child = ifelse(hhld_adult > 2 & hhld_child == 0, 1, 0)) %>%
  mutate(n_twoplus_adult_one_child = ifelse(hhld_adult > 2 & hhld_child == 1, 1, 0)) %>%
  mutate(n_twoplus_adult_two_child = ifelse(hhld_adult > 2 & hhld_child == 2, 1, 0)) %>%
  mutate(n_twoplus_adult_twoplus_child = ifelse(hhld_adult > 2 & hhld_child > 2, 1, 0)) %>%
  # Group into treso ID
  select(treso_zone, n_zero_adult:n_twoplus_adult_twoplus_child) %>%
  group_by(treso_zone) %>%
  summarise_all(
    funs(sum)
  )

# Summarize into TRESO Zones
treso_tb <- socio_economic_tb %>%
  group_by(treso_zone) %>%
  summarise(
    n_pop = n(),
    n_hhlds = length(unique(hhid)),
    n_ft = length(treso_zone[work_status == "full_time"]),
    n_pt = length(treso_zone[work_status == "part_time"]),
    n_unemp = length(treso_zone[work_status == "unemployed"]),
    n_sec_pop = length(treso_zone[age <= 18 & age >= 13]),
    n_ele_pop = length(treso_zone[age <= 12 & age >= 3]),
    n_pre_pop = length(treso_zone[age <= 2]),
    
    mean_income = mean(income, na.rm = TRUE),
    mean_age = mean(age, na.rm = TRUE),
    
    occu_management = length(treso_zone[nocs_11 == 1]),
    occu_business = length(treso_zone[nocs_11 == 2]),
    occu_science = length(treso_zone[nocs_11 == 3]),
    occu_health = length(treso_zone[nocs_11 == 4]),
    occu_public = length(treso_zone[nocs_11 == 5]),
    occu_recreation = length(treso_zone[nocs_11 == 6]),
    occu_sales = length(treso_zone[nocs_11 == 7]),
    occu_trades = length(treso_zone[nocs_11 == 8]),
    occu_production = length(treso_zone[nocs_11 == 9]),
    occu_manufacturing = length(treso_zone[nocs_11 == 10]),
    occu_notapplicable = length(treso_zone[nocs_11 == 99]),
    attend_school = length(treso_zone[school_status == 2]),
    deg_none = length(treso_zone[hdgree == 1]),
    deg_hs = length(treso_zone[hdgree == 2]),
    deg_trades = length(treso_zone[hdgree == 3]),
    deg_ra = length(treso_zone[hdgree == 4]),
    deg_col = length(treso_zone[hdgree == 5]),
    deg_uni = length(treso_zone[hdgree == 6]),
    deg_ugrad = length(treso_zone[hdgree == 7]),
    deg_grad = length(treso_zone[hdgree == 8]),
    deg_na = length(treso_zone[hdgree == 88 | hdgree == 99])
  ) %>%
  left_join(hhld_structure, by = "treso_zone") %>%
  saveRDS("cache/treso_tb.rds")

# Clean global variables
rm(hhld_tb, socio_economic_tb, hhld_structure)
```


# EDU Data Cleaning


## EDU Data Import

```{r edu mport, include=FALSE}
# TRESO data
hhld_df <- data.table::fread("input/treso/households_2011.csv.gz")
pop_df <- data.table::fread("input/treso/persons_2011.csv.gz")

# School Data
schoolCap <- read.csv("input/edu/school_capacity.csv", stringsAsFactors = FALSE)
schoolForecast <- read.csv("input/edu/school_forecast.csv", stringsAsFactors = FALSE)
schoolAssets <- read.csv("input/edu/school_assets.csv", stringsAsFactors = FALSE)
schoolAssetsPortables <- read.csv("input/edu/school_assets_portables.csv", stringsAsFactors = FALSE)
schoolAssetsSFIS.BID <- read.csv("input/edu/dbo_AssetInventoryEDULatLong.csv", stringsAsFactors = FALSE)
studentPost <- read.csv('input/edu/sch_enr_pcode.txt', sep = "|", stringsAsFactors = FALSE)
eqao <- read.csv('input/edu/eqao_2017_2018.csv', stringsAsFactors = FALSE, fileEncoding = "UTF-8-BOM")

pccf <- read.csv('input/edu/PCCF_ONT_2018.csv', stringsAsFactors = FALSE, fileEncoding = "UTF-8-BOM") 
```

### Clean and Simplify Portables Data

- Assume that portable units are rounded at 0.75. So a protable with 1.8 units is rounded 2 units and a portable with
1.7 units is rounded to 1 unit
- Assume that 23 elementary or 21 secondary students per unit of portable
- Update the utilization of each school after adding in the portables

```{r clean portables, echo=FALSE}
# Sum total ground floor area and number of portable units by school
filterList <- c('cafe|child care|administration|other|commercial|general|best start|staff')

ELE_STUDENTS_UNIT_CLASS = 23
SEC_STUDENTS_UNIT_CLASS = 21
PORTABLE_UNIT_SIZE = 75

schoolAssetsPortablesSlim <- schoolAssetsPortables %>%
  select(sfis = SFIS_ID, year = Sch_yr, dsb.index = Dsb_index, facility.name = FacilityName, dataset.id = DataSetID,
         current.use = CurrentUse, area.m2 = GFA_m2, num.units = NumberOfUnits) %>%
  filter(dataset.id == 2, area.m2 > 0) %>%
  select(-dataset.id) %>%
  filter(!grepl(filterList, current.use, ignore.case = TRUE)) %>%
  group_by(year, dsb.index, sfis, facility.name) %>%
  summarise(
    area.m2 = sum(area.m2),
    num.units = sum(num.units)
  ) %>%
  ungroup() %>%
  # TODO check this is rounding to 0.75
  mutate(num.units.calculated = round(area.m2 / PORTABLE_UNIT_SIZE, 0))

# schoolSFIS <- readRDS('output/school_sfis_2017.rds') %>%
#   select(-area.m2, -num.units.calculated)

# Join Portables Data to School Data and recalculate utilization based on the size of portable
# schoolSFIS <- left_join(schoolSFIS, select(schoolAssetsPortablesSlim, sfis, area.m2, num.units.calculated), by = 'sfis') %>%
#   replace_na(list(area.m2 = 0, num.units.calculated = 0)) %>%
#   mutate(capacity.portable = ifelse(panel == 'Elementary', num.units.calculated * ELE_STUDENTS_UNIT_CLASS, 
#                                     num.units.calculated * SEC_STUDENTS_UNIT_CLASS)) %>%
#   mutate(capacity.total = otg + capacity.portable) %>%
#   mutate(utilization.total = ade / capacity.total)

# Utilization above 1 at this point could be erroneous data
# TODO check with Alec regarding this.
#print(paste0('There are ', length(filter(schoolSFIS, utilization.total > 1)$sfis), ' schools with utilization greater than 1.2.'))

#saveRDS(schoolSFIS, file = 'cache/school_sfis_2017.rds')
```

## Compile master list of schools, portables, sfis ID, geo coordinates, TRESO zone

- Produce dataframe with geocoordinates for all schools (past & present)

### Add FCI, renewal to asset data
```{r clean school assets, echo=FALSE}
# Retrieve FCI and renewal values
schoolAssetsSlim <- schoolAssets %>%
  filter(DataSetId == 2, Status == 'Open', Panel == 'School') %>%
  select(bid = BID, lat = Latitude, long = Longitude, ade = ADE,
         asset.name = AssetName, fci = FCI, year.built = YearBuilt, renewal.needs = RenewalNeeds.TotalRenewalAdj.,
         replacement.value = ReplacementValue, assessment.year = AssessmentYear) %>%
  drop_na(bid, lat, long, ade) %>% 
  left_join(select(schoolAssetsSFIS.BID, SFIS_ID, BUILDING.ID), by = c('bid' = 'BUILDING.ID')) %>% 
  mutate(sfis = as.numeric(SFIS_ID)) %>%
  select(-SFIS_ID, -bid, -lat, -long, -ade, -asset.name) %>% 
  arrange(sfis)

```

```{r}
# Read in geocoordinates for schools with missing data
# Geocoordinates were found using separate program and stored in CSV
missingCoords <- read_csv('input/edu/school_missing_geocoordinates.csv')
schoolBoardTypes <- read_csv('input/edu/school_board_types.csv')

# Create a table called schoolLoc to house master list for school geocoordinates, etc.
schoolLoc <- schoolCap %>%
  select(year = Sch_yr, 
         dsb.index = DSB_Index, 
         panel = Panel, 
         sfis = `SFIS_ID`,
         school.name = `FacilityName`, 
         status = Status,
         school.lat = `Latitude`, 
         school.long = `longitude`,
         otg = OTG,
         ade = ADE,
         board.name = BoardName,
         dataset.id = dataSetID) %>%
  filter(dataset.id == 2) %>%
  left_join(select(schoolBoardTypes, dsb, board_type_name), by = c('dsb.index' = 'dsb')) %>%
  mutate_if(is.factor, as.character) -> schoolLoc

# Join in geocoordinate data for missing schools
schoolLocUpdated <- schoolLoc %>%
  left_join(distinct(select(missingCoords, SFIS_ID, altLat = finalLatitude, altLon = finalLongitude)), by = c('sfis' = 'SFIS_ID')) %>%
  mutate(school.lat = ifelse(is.na(school.lat), altLat, school.lat)) %>%
  mutate(school.long = ifelse(is.na(school.long), altLon, school.long)) %>%
  select(-altLat, -altLon) %>% 
  arrange(status, otg, desc(ade))

# Keep a record of schools for which a lat/long cannot be determined
schoolLocMissing <- schoolLocUpdated %>%
  filter(is.na(school.lat)|is.na(school.long))

# Filter wacky results incl. remove NA values of lat/long from school location dataframe in order to run x/y retrieval
schoolLocClean <- schoolLocUpdated %>%
  filter(!is.na(school.lat) & !is.na(school.long)) %>%
  group_by(sfis) %>%
  mutate(otg = ifelse(status == 'Open' & otg == 0, max(ade), otg)) %>%
  ungroup()

# Simplify school forecast data (ADE and OTG) to join to historical school data, and
# filter out forecast data for years in which historical data is available
schoolForecastSimple <- schoolForecast %>%
  select(year = SCH_YR, 
         dsb.index = DSBINDEX,
         panel = PANEL,
         sfis = SFIS,
         school.name = School.Name, 
         ade = ADE,
         latitude,
         longitude) %>% 
  anti_join(distinct(select(schoolLocClean, sfis, year)), by = c('sfis', 'year')) %>% 
  mutate_if(is.factor, as.character) -> schoolForecastSimple

# Join board type, lat, long, otg to school forecast dataset

school_recent_data <- schoolLocClean %>%
  group_by(sfis) %>%
  filter(year == max(year), status == 'Open' | status == 'Holding' | status == 'Under Construction') %>%
  ungroup()

schoolForecastSimpleJoin <- schoolForecastSimple %>% 
  left_join(select(school_recent_data, sfis, board_type_name, board.name, school.lat, school.long, otg), by = c('sfis')) %>% 
  mutate(school.lat = ifelse(is.na(school.lat), latitude, school.lat)) %>% 
  mutate(school.long = ifelse(is.na(school.long), longitude, school.long)) %>%
  mutate(panel = ifelse(panel == 'E', 'Elementary', ifelse(panel == 'S', 'Secondary', 'ERROR')))

# Bind Historical school data to forecast school data

schoolLocCombined <- bind_rows(schoolLocClean, schoolForecastSimpleJoin)

# Choose single most common lat/long for schools to avoid row duplication and conflicts

schoolLatMode <- schoolLocCombined %>% 
  group_by(sfis) %>%
  count(school.lat, sort=TRUE) %>%
  slice(1)

schoolLongMode <- schoolLocCombined %>% 
  group_by(sfis) %>%
  count(school.long, sort=TRUE) %>%
  slice(1)

schoolLocCombinedFix <- schoolLocCombined %>% 
  select(-school.lat, -school.long) %>% 
  left_join(select(schoolLatMode, sfis, school.lat), by = c('sfis')) %>% 
  left_join(select(schoolLongMode, sfis, school.long), by = c('sfis')) %>% 
  select(-latitude, -longitude)

# Determine x & y coordinates for schools based on TRESO zone shapefile
schoolLocCombinedDistinct <- schoolLocCombinedFix %>%
  distinct(sfis, school.lat, school.long)

create_school_xy_simple <- function(school_sfis) {
  '
  This function differs from `create_school_xy` in that this takes in the school dataframe
  without the catchment distnace. This function differs from `create_school_xy_from_schools`
  in that it pulls different metadata fields.
  
  input: Dataframe of school with lat long
  output: SpatialPointsDataFrame of each school
  '
  # Convert the school dataframe into SpatialPointsDataframe
  school_spdf <- school_sfis %>%
    ungroup() %>%
    select(sfis, school.lat, school.long) %>%
    mutate(schoolLat = school.lat, schoolLong = school.long) %>%
    mutate(id = row_number())
  coordinates(school_spdf) <- c('schoolLong', 'schoolLat')
  
  # Project the student and school points from lat/long to TRESO's LCC specification
  proj4string(school_spdf) <- CRS('+proj=longlat +datum=WGS84')
  treso_projarg = treso_shp@proj4string@projargs
  
  school_xy <- spTransform(school_spdf, CRS(treso_projarg))
  
  return(school_xy)
}

treso_shp <- readOGR(dsn = "input/treso", layer = "TRESO_Zones_SocioData_Gatineau_LCC")
school_xy <- create_school_xy_simple(schoolLocCombinedDistinct)

# Determine TRESO zone associated with each school's x & y coordinates
schoolTRESO <- create_overlay(school_xy, treso_shp, 'schoolSimple')

# Join schoolTRESO table to CD/CSD info 
tresoCSDmatch <- read_csv('input/treso/treso_zone_system.csv')
schoolTRESOcsd <- schoolTRESO %>%
  left_join(select(tresoCSDmatch, treso_id, csduid, cduid), by = c('treso.id.pos' = 'treso_id')) %>%
  mutate_if(is.factor, as.character) -> schoolTRESOcsd

# Join TRESO/CSD data to main schools dataframe; add in flags for OTG = 0, Utilization > 200%
school_treso_data <- schoolLocCombinedFix %>%
  left_join(select(schoolTRESOcsd, sfis, treso.id.pos, csduid, cduid), by = c('sfis')) %>%
  mutate(zero_otg_flag = ifelse(otg == 0, 1, 0)) %>%
  mutate(excessive_util_flag = ifelse(ade/otg >= 2, 1, 0)) %>%
  mutate(excessive_util_flag = replace_na(excessive_util_flag, 0))

# Join to portables data
school_treso_master <- school_treso_data %>%
  left_join(select(schoolAssetsPortablesSlim, sfis, area.m2, num.units.calculated, year), by = c('sfis' = 'sfis', 'year' = 'year')) %>%
  replace_na(list(area.m2 = 0, num.units.calculated = 0)) %>%
  mutate(num.units.calculated = round(num.units.calculated,0)) %>%
  mutate(capacity.portable = ifelse(panel == 'Elementary', num.units.calculated * ELE_STUDENTS_UNIT_CLASS, 
                                    num.units.calculated * SEC_STUDENTS_UNIT_CLASS))%>%
  rename(portable.units = num.units.calculated) %>% 
  left_join(schoolAssetsSlim, by = 'sfis')

# Export to RDS
saveRDS(school_treso_master, 'output/school_treso_master.rds')

```

## Data Structuring
 
- Clean the school asset data
- Clean the school forecast data
- Then, clean school capacity and historical demand data
- Combine together 
- Clean the student postal code data

### Clean school capacity dataset
```{r education data cleaning, echo=FALSE}
# The school capacity dataset contains the correct lat/long for schools
schoolCapSlim <- schoolCap %>%
  select(year = Sch_yr, 
         dsb.index = DSB_Index, 
         board.name = BoardName, 
         panel = Panel, 
         sfis = `SFIS_ID`,
         school.name = `FacilityName`, 
         ade = ADE,
         otg = OTG, 
         school.lat = `Latitude`, 
         school.long = `longitude`, 
         status = Status, 
         dataset.id = dataSetID) %>%
  mutate(utilization = ifelse(otg != 0, ade / otg, 0)) %>%
  filter(year == 2017, status == "Open", dataset.id == 2, !is.na(school.lat), !is.na(school.long)) %>%
  # Remove schools with capacity of 0
  filter(otg != 0, ade != 0) %>%
  # Remove schools with ADE that is less than 50
  filter(ade >= 50)

# The school forecast dataset contains BSID which is needed to merge student postal code
# From inspection, there are same amount of school in each forecast year.
schoolForecastSlim <- schoolForecast %>%
  select(year = SCH_YR, 
         sfis = SFIS,
         bsid = BSID,
         dsb.index = DSBINDEX,
         school.name = School.Name, 
         ade.forecast = ADE,
         ade.sec.forecast = ADE_SEC,
         ade.elem.forecast = ADE_ELEM,
         ade.jksk.forecast = ADE_JKSK,
         ade.g1g3.forecast = ADE_G1G3, 
         ade.g4g8.forecast = ADE_G4G8) %>%
  filter(year == 2017, bsid != 0)

# Combine the School capacity data with the forecast data on SFIS
schoolSFIS <- left_join(schoolCapSlim, schoolForecastSlim, by = c('sfis')) %>%
  select(-school.name.y, -dsb.index.y) %>%
  rename(school.name = school.name.x, dsb.index = dsb.index.x) %>%
  arrange(sfis)

# Drop any school that does not have a corresponding forecast
unmatched_schools <- sum(is.na(schoolSFIS$bsid))                       
print(paste0('A total of ', unmatched_schools, ' schools are unmatched between capacity and forecast'))
schoolSFIS <- schoolSFIS %>%
  drop_na(bsid)

# The postal code and enrollment dataset is cleaned here
# We are looking at 2017 student data at this time.
# TO-DO: Look at all years of student postal code data.
studentPostSlim <- studentPost %>%
  select(year = Sch_YR,
         bsid = BSID, 
         dsb.index = dsbindex,
         school.name = School.Name, 
         student.postal.code = Student.Postal.Code,
         enrolment = Enrolment) %>%
  filter(year == 2017) %>%
  filter(str_length(student.postal.code) == 6) %>%
  mutate(enrolment = as.integer(enrolment))

num_schools_from_student_post <- length(unique(studentPostSlim$bsid))
num_schools_from_school_sfis <- length(unique(schoolSFIS$bsid))
print(paste0('A total of ', num_schools_from_student_post, ' unique schools are contained in student postal code dataset'))
print(paste0('A total of ', num_schools_from_school_sfis, ' unique schools are contained in the school dataset'))

# Clean global variables
rm(num_schools_from_student_post, num_schools_from_school_sfis)
```

### Create historical education dataset

- The historical trends of ADE is a valuable

```{r historical education data, echo=FALSE}
# The school capacity dataset contains the correct lat/long for schools
schoolCapHistorical <- schoolCap %>%
  select(year = Sch_yr, 
         dsb.index = DSB_Index, 
         board.name = BoardName, 
         panel = Panel, 
         sfis = `SFIS_ID`,
         school.name = `FacilityName`, 
         ade = ADE,
         otg = OTG,
         status = Status, 
         dataset.id = dataSetID) %>%
  mutate(utilization = ifelse(otg != 0, ade / otg, 0)) %>%
  filter(status == "Open", dataset.id == 2) %>%
  # Remove schools with capacity of 0
  filter(otg != 0, ade != 0) %>%
  # Remove schools with ADE that is less than 50
  filter(ade >= 50) %>%
  select(year, sfis, ade, otg, utilization) %>%
  saveRDS("input/edu/school_historical_capacity.rds")

```


### Calculate School Catchment Lengths

- First, join the school and student's together into one table based on `bsid`
- Then, join the postal code centroids with lat/long information to each student based on `postal.code`
- Filter the unmatched records from the table
- Find any schools with a ratio of ADE to enrolment below 0.8 and above 1.0 between the school and student data, remove these outliers
- Calculate the straight line travel distance between student to school based on lat/long information and `haverFunction()`
- Calcualte the manhattan line travel distance between student to school based on lat/long information and `manhattan()`

```{r join edu data, echo=FALSE}
# Join postal code centroids to student's postal code data
pccfSlim <- pccf %>%
  filter(SLI == 1) %>%
  select(postal.code = PostalCode,
         lat = LAT,
         long = LONG,
         retirement.date = Ret_Date) %>%
  group_by(postal.code) %>%
  filter(retirement.date == max(retirement.date))

# Create a list of postal codes with SLI == 1 but different lat/long
pccfSlim[duplicated(pccfSlim$postal.code) | duplicated(pccfSlim$postal.code, fromLast = TRUE), ] %>%
  arrange(postal.code) %>%
  group_by(postal.code, lat, long, retirement.date) %>%
  summarise(n = n()) %>%
  filter(n == 1)

# Combine school, student and postal data together
schoolCatchment <- schoolSFIS %>%
  select(sfis, bsid, school.name, school.lat, school.long, dsb.index, panel, ade) %>%
  left_join(select(studentPostSlim, bsid, student.postal.code, enrolment), by = c('bsid' = 'bsid'))

unmatched_schools <- schoolCatchment %>%
  filter(is.na(enrolment)) %>%
  group_by(sfis) %>%
  summarise(school.name = first(school.name), unmatched.enrollment = n())

unmatched_school_pct <- round(length(unique(unmatched_schools$sfis)) / length(unique(schoolSFIS$sfis)) * 100, 2)
print(paste0(unmatched_school_pct, '% of shcools are unmatched, and ', sum(unmatched_schools$unmatched.enrollment),
             ' students are unmatched after combining with student postal code'))

schoolCatchment <- schoolCatchment %>%
  drop_na(enrolment) %>%
  left_join(select(pccfSlim, student.lat = lat, student.long = long, postal.code), by = c('student.postal.code' = 'postal.code'))

unmatched_students <- round((length(unique(filter(schoolCatchment, is.na(student.lat))$student.postal.code)) / 
                             length(unique(filter(schoolCatchment, !is.na(student.lat))$student.postal.code))) * 100, 2)
print(paste0(unmatched_students, '% of students did not have a match between postal code and lat/long'))

schoolCatchment <- schoolCatchment %>%
  drop_na(student.lat, student.long)

# Check very low or very high Enrolment/ADE ratios and remove these
temp1 <- schoolSFIS %>%
  select(bsid, school.name, ade)
  
temp2 <- studentPostSlim %>%
  group_by(bsid) %>%
  summarise(
    enrolment = sum(enrolment)
  )

temp_tb <- left_join(temp1, temp2, by = 'bsid') %>%
  mutate(ratio = ade / enrolment) %>%
  arrange(ratio) %>%
  filter(ratio <= 0.8 | ratio >= 1.02)

num_outlier_matched <- round(length(temp_tb$bsid) / length(schoolSFIS$bsid) * 100, 2)
print(paste0(num_outlier_matched, '% of all schools is flagged due to a large mismatch between ADE and enrolment'))

schoolCatchment <- anti_join(schoolCatchment, temp_tb, by = 'bsid')

# Calculate straight-line home-to-school distances
schoolCatchment <- schoolCatchment %>%
  mutate(dist = haverFunctionEuclidean(school.lat, school.long, student.lat, student.long)) %>% 
  mutate(man.dist = haverFunctionManhattan(school.lat, school.long, student.lat, student.long))
```

### Remove outlier students

The data provided contains students travelling extremely far distances. This can be a source of error when calculating
the catchment areas for schools. For each school, the students outside of the whiskers of a typical boxplot are removed. 

- The end of whiskers is defined as [Q_1 - 1.5*IQR, Q_3 + 1.5IQR], and IQR is the difference between Q_3 and Q_1. 

```{r distance threshold filtering, fig.width=15}

schoolCatchmentThreshold <- schoolCatchment %>%
  uncount(enrolment) %>%
  group_by(school.name, school.lat, school.long) %>%
  summarise(
    lower_adj = boxplot.stats(man.dist)$stats[1],
    upper_adj = boxplot.stats(man.dist)$stats[5]
  )

schoolCatchment <- left_join(schoolCatchment, schoolCatchmentThreshold, by = c('school.name', 'school.lat', 'school.long')) %>%
  mutate(keep = as.factor(ifelse(man.dist <= upper_adj & man.dist >= lower_adj, 1, 0)))

# Plot stacked barplots of students within vs outside of threshold
schoolCatchment %>%
  uncount(enrolment) %>%
  ggplot(aes(x = panel, fill = keep)) +
  geom_bar() +
  facet_wrap(vars(dsb.index), scales = 'free_y')  +
  theme_minimal() + 
  labs(x = '', y = 'Enrolment', title = 'Threshold Analysis by DSB') +
  scale_fill_discrete(name = '', labels = c('Dropped', 'Kept')) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

num_outlier_students <- sum(filter(schoolCatchment, keep == '0')$enrolment)
num_within_students <- sum(filter(schoolCatchment, keep == '1')$enrolment)
print(paste0('Dropped ', num_outlier_students, ' students because they fall outside of acceptable threshold range.'))
print(paste0('Kept ', num_within_students, ' students because they fall inside of acceptable threshold range.'))

schoolCatchment <- schoolCatchment %>%
  filter(keep == '1')

# schoolCatchment %>%
#   filter(panel == 'Secondary', dsb.index == 14) %>%
#   uncount(enrolment) %>%
#   ggplot(aes(x = school.name, y = dist)) +
#   geom_boxplot(outlier.color = 'red')

```

``` {r students within catchment, echo=FALSE}
# Calculate the catchment distance by a specified quantile weighted with the enrolment of the school
percentileList <- c(0.9, 0.8, 0.7, 0.6, 0.5)
schoolCatchmentDistPercent <- schoolCatchment %>%
  group_by(sfis, school.name, school.lat, school.long) %>%
  # use a weighted quantile function to select the distance by enrolment
  summarise(
    panel = first(panel),
    list(
      enframe(
        wtd.quantile(man.dist, probs = percentileList, na.rm = FALSE, weight = enrolment)
        )
      )
    ) %>%
  unnest %>%
  ungroup() %>%
  rename(perc.value = name, perc.dist = value) %>%
  mutate(perc.value = as.numeric(sub("%", "", perc.value))/100)

schoolCatchmentDistPercent %>%
  group_by(perc.value, panel) %>%
  summarise(average.distance = mean(perc.dist)) %>%
  ggplot(aes(x = perc.value, y = average.distance, fill = panel)) +
  geom_bar(stat = 'identity', position = 'dodge') +
  labs(x = "Quantile", y = "Distance (KM)", title = "Average Catchment Distance of Schools") +
  theme_minimal()

# Select students within the catchment distance and export it
for (catchment_dist in percentileList){
  schoolCatchment %>%
    left_join(select(schoolCatchmentDistPercent, sfis, perc.dist, perc.value), by = c('sfis' = 'sfis')) %>%
    filter(perc.value == catchment_dist) %>%
    filter(man.dist <= perc.dist) %>%
    saveRDS(file = paste0('cache/student_travel_', as.character(catchment_dist), '.rds'))
}

rm(schoolCatchment, schoolCatchmentDistPercent, schoolCatchmentThreshold, percentileList, temp_tb)
```

#### Quick Check of ADE vs Enrollment

```{r quick check, fig.height = 50, fig.width = 10}
# Check the enrollment total vs ADE numbers
temp1 <- schoolSFIS %>%
  select(bsid, school.name, ade, ade.forecast) %>%
  arrange(school.name)
  
temp2 <- studentPostSlim %>%
  group_by(bsid) %>%
  summarise(
    enrolment = sum(enrolment),
    school.name = first(school.name)
  ) %>%
  arrange(school.name)

temp <- left_join(temp1, temp2, by = "bsid") %>%
  drop_na(enrolment) %>%
  gather(key = 'key', value = 'value', ade, enrolment) %>%
  select(-school.name.y) %>%
  arrange(school.name.x) %>%
  mutate(facet_index = factor(row_number() %/% 100))

ggplot(data = temp, aes(fill = key, x = school.name.x, y = value)) +
  geom_bar(stat = "identity", position = 'dodge') +
  facet_wrap(~facet_index, ncol = 5, scales = 'free_x') +
  labs(x = '')

rm(temp1, temp2, temp)
```


#### Visualization of percentile travel distance

```{r visualize travel distance}
student_travel <- readRDS(file = 'cache/student_travel_0.9.rds') %>%
  as_tibble() %>%
  group_by(sfis, school.name, school.lat, school.long) %>%
  summarise(distance = first(perc.dist))

ggplot(data = student_travel, aes(distance)) +
  geom_freqpoly(stat = "bin", binwidth = 5, size = 1) +
  labs(x = "Distance (KM)", y = "Count", title = "") +
  theme_minimal()

```

### Clean EQAO Data

- Remove not reported (N/R) and no data (N/D)
- Remove suppressed (SP)
- Keep only public and catholic school types
- Calculate mean and standard deviations for reading, writing, and mathematics across the same board/panel

```{r eqao, eval=FALSE}
eqaoSlim <- eqao %>%
  select(School.Number, School.Name, School.Type, School.Level, School.Language, Enrolment, Latitude, Longitude,
         Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Reading:Change.in.Grade.10.OSSLT.Literacy.Achievement.Over.Three.Years) %>%
  mutate_at(vars(matches("Percentage|Change")), list(~gsub(" *%", "", .))) %>%
  # Remove N/R (not-reported) and N/D (no-data)
  mutate_at(vars(matches("Percentage|Change")), list(~gsub("[A-z]\\/[A-z]", NA, .))) %>%
  # Remove SP (suppressed)
  mutate_at(vars(matches("Percentage|Change")), list(~gsub("[A-z][A-z]", NA, .))) %>%
  mutate_at(vars(matches("Percentage|Change")), list(~as.numeric(.))) %>%
  # Keep only "public" and "catholic"
  filter(School.Type %in% c("Public", "Catholic"))

eqao_distribution <- eqaoSlim %>%
  select_at(vars("School.Type", "School.Language", "School.Level", matches("Achieving.the.Provincial"))) %>%
  group_by(School.Type, School.Language, School.Level) %>%
  summarise_all(list(mean = mean, std = sd), na.rm = TRUE)

eqao_standardized <- left_join(eqaoSlim, eqao_distribution, by = c("School.Type", "School.Language", "School.Level")) %>%
  mutate(Grade.3.Reading.Standardized = (Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Reading - 
                                         Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Reading_mean) /
                                         Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Reading_std) %>%
  mutate(Grade.3.Writing.Standardized = (Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Writing - 
                                         Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Writing_mean) /
                                         Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Writing_std) %>%
  mutate(Grade.3.Mathematics.Standardized = (Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Mathematics - 
                                         Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Mathematics_mean) /
                                         Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Mathematics_std) %>%
  mutate(Grade.6.Reading.Standardized = (Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Reading - 
                                         Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Reading_mean) /
                                         Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Reading_std) %>%
  mutate(Grade.6.Writing.Standardized = (Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Writing - 
                                         Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Writing_mean) /
                                         Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Writing_std) %>%
  mutate(Grade.6.Mathematics.Standardized = (Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Mathematics - 
                                         Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Mathematics_mean) /
                                         Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Mathematics_std) %>%
  mutate(Grade.9.Academic.Mathematics.Standardized = (Percentage.of.Grade.9.Students.Achieving.the.Provincial.Standard.in.Academic.Mathematics - 
                                         Percentage.of.Grade.9.Students.Achieving.the.Provincial.Standard.in.Academic.Mathematics_mean) /
                                         Percentage.of.Grade.9.Students.Achieving.the.Provincial.Standard.in.Academic.Mathematics_std) %>%
  mutate(Grade.9.Applied.Mathematics.Standardized = (Percentage.of.Grade.9.Students.Achieving.the.Provincial.Standard.in.Applied.Mathematics - 
                                         Percentage.of.Grade.9.Students.Achieving.the.Provincial.Standard.in.Applied.Mathematics_mean) /
                                         Percentage.of.Grade.9.Students.Achieving.the.Provincial.Standard.in.Applied.Mathematics_std) %>%
  select_at(vars(School.Name, School.Number, School.Type, School.Language, School.Level, matches("Standardized"))) %>%
  mutate(eqao = select(., Grade.3.Reading.Standardized, Grade.3.Writing.Standardized, Grade.3.Mathematics.Standardized,
                           Grade.6.Reading.Standardized, Grade.6.Writing.Standardized, Grade.6.Mathematics.Standardized,
                           Grade.9.Academic.Mathematics.Standardized, Grade.9.Applied.Mathematics.Standardized) %>% rowSums(na.rm = TRUE)) %>%
  mutate(eqao.normalized = (eqao - min(eqao)) / (max(eqao) - min(eqao))) %>%
  mutate(eqao.standardized = eqao.normalized * 10) %>%
  select(School.Name, School.Number, School.Type, School.Language, School.Level, eqao.standardized)

saveRDS(eqao_standardized, file = 'cache/eqao_standardized_2017.rds')

```








# Health Data Import
```{r health import, include=FALSE}
# Bed Census data
dailybedcensus <- read_csv('input/moh/cap.MOH_DailyBedCensus_Summary.csv')

# Health Asset Inventory
hospitallocations <- read_csv('input/moh/dbo.MOH_Hospital_Locations.csv')

# HBAM Historical
HBAMhistorical <- read_csv('input/moh/cap.MOH_HBAM_HIS.csv')

# HBAM Projected
HBAMprojected <- read_csv('input/moh/cap.MOH_HBAM_Proj.csv')

#LHIN Data
populationLHIN <- read_csv('input/moh/dbo.Population_LHIN.csv')

#ALC Datasets
#For CCO Linkage Table
ALC_idcrosswalk <- read_csv('input/moh/SiteID_Linkage_Table.csv')
ALCannualvolume <- read_csv('input/moh/cap.ALCAnnualVolumeAndTOtalDays.csv')

#Most recent updated ALC Data from CCO w/ MADD and DD typeflags
ALC_madd_raw <- read_csv('input/moh/ALC_Data.2019-09-09.csv', col_types = list('VOL' = col_character()))

#CIHI Data
CIHIhospitalbeds <- read_csv('input/moh/cap.CIHI_Hospital_Beds.csv')

#LTC Facility Data
ltc_homes <- read_csv('input/moh/20190628_LTC Homes Query.csv')

##TRESO Data Input
  # Segment TRESO population data to match HBAM age group classifications: Index 1-6 w/ pediatric breakdown (ped) 1-3
treso_population_moh <- readRDS('input/moh/treso_population_moh.rds')

# PCCF
pccf <- read.csv('input/moh/PCCF_ONT_2018.csv', stringsAsFactors = FALSE, fileEncoding = "UTF-8-BOM") 

```

# Health Data Cleaning

Preparation of Health Import Data
  - Clean and organize provided data to maintain variable-name consistency across all datasets and filter for data entry errors
  - Age group filters exclude agegroup index "9 (total)" to prevent double counting
  - Age group filters exclude "7 (Missing)"
  - Filter only for totalling Case-type and Bed-type classifications (9 and AP)
  - Filter HBAM CSDs to remove origin CSDs not in Ontario
  - Join HBAM with Asset data to establish master ID list (loss of 1,151,954 cases to join)
  
## Bed & Asset Import Prep for Data Cleaning Use
```{r health bed & discharge & asset import data prep, include=FALSE, eval=TRUE}
# Bed Census Data

dailybedcensusprep <- dailybedcensus %>% 
  drop_na(FISCALYEAR) %>% #Years with NULL under FISCALYEAR also have empty rows
  select(facilityid = FACILITY_NO,
         siteid = INST,
         type = TYPE,
         year = FISCALYEAR,
         censusdate = CENSUSDATE,
         admission = ADMISSION,
         discharge = DISCHARGE,
         death = DEATHS,
         atbeds = INACUTEBEDS,
         mhbeds = INMHBEDS,
         cccbeds = INCCCBEDS,
         grbeds = INGRBEDS,
         srbeds = INSRBEDS,
         patientbeds = PATIENTSINDESIGNATEDBEDS,
         staffedbeds = BEDSWITHSTAFFAVAILABLE,
         erstretchers = ERSTRETCHERSUSED,
         uncovnentionalbeds = UNCONVENTIONALBEDSUSED,
         overflowpatients = OVERFLOWPATIENTS,
         totalpatients = TOTALPATIENTS) %>% 
  mutate(type = replace(type, type == 'SR', 'GR'))

# Health Asset Inventory
hospitallocationsprep <- hospitallocations %>%
  spread(key = DatasetId, value = 'Master Number') %>% 
  select(lhin = LHIN,
         lhinlocation = Location,
         name = Name,
         caretype = Type,
         facilityid = 'Facility Number',
         hospitalcorp = 'Provider Legal Name',
         address = 'Address Line 1',
         city = City,
         pcode = 'Postal Code',
         lat = latitude,
         long = longitude,
         datasetID1.siteid = '1',
         datasetID2.siteid = '2',
         datasetID3.siteid = '3',
         datasetID4.siteid = '4',
         datasetID5.siteid = '5',
         datasetID6.siteid = '6') %>%
  mutate(datasetID1.siteid = as.numeric(replace_na(datasetID1.siteid, 0)), 
         datasetID2.siteid = as.numeric(replace_na(datasetID2.siteid, 0)), 
         datasetID3.siteid = as.numeric(replace_na(datasetID3.siteid, 0)), 
         datasetID4.siteid = as.numeric(replace_na(datasetID4.siteid, 0)), 
         datasetID5.siteid = as.numeric(replace_na(datasetID5.siteid, 0)),
         datasetID6.siteid = as.numeric(replace_na(datasetID6.siteid, 0))) %>%
  group_by(pcode) %>% 
  mutate(id = group_indices()) %>% # Assign a unique hospital ID per hospital campus/site 
  ungroup() %>% 
  mutate(caretype = replace(caretype, caretype == 'SR', 'GR')) %>%
  # Choose first name in list for each hospital
  group_by(id) %>% 
  mutate(name = first(name)) %>% 
  ungroup() %>% 
  # Lat/long incorrect in raw input data for Providence Care Hospital
  mutate(lat = replace(lat, id == 33, 44.217317),
         long = replace(long, id == 33, -76.527267))
```

## Asset Location Prep W/Output
```{r asset location prep, include=FALSE, eval=TRUE}

# Join postal code centroids to hospital postal code data
pccfSlimHosp <- pccf %>%
  filter(SLI == 1) %>%
  select(postal.code = PostalCode,
         lat = LAT,
         long = LONG,
         retirement.date = Ret_Date,
         csduid = CSDuid,
         csdname = CSDname) %>%
  group_by(postal.code) %>%
  filter(retirement.date == max(retirement.date))

# Create a list of postal codes with SLI == 1 but different lat/long
pccfSlimHosp[duplicated(pccfSlimHosp$postal.code) | duplicated(pccfSlimHosp$postal.code, fromLast = TRUE), ] %>%
  arrange(postal.code) %>%
  group_by(postal.code, lat, long, retirement.date) %>%
  summarise(n = n()) %>%
  filter(n == 1)

# Fill in unknown lat/long
hospitallocationsapp <- hospitallocationsprep %>% 
  mutate(pcode.clean = gsub("\\s+", "", pcode)) %>%
  left_join(select(pccfSlimHosp, hospital.lat = lat, hospital.long = long, postal.code), by = c('pcode.clean' = 'postal.code')) %>%
  mutate(lat = ifelse(is.na(lat), hospital.lat, lat),
         long = ifelse(is.na(long), hospital.long, long)) %>%
  group_by(id) %>% 
  mutate(lat = first(lat), long = first(long), address = first(address)) %>%
  ungroup() %>% 
  select(-pcode.clean, -hospital.lat, -hospital.long)

#Output cach hospital location data file (hospitallocationsapp) for import into hospitals.rmd
saveRDS(hospitallocationsapp, file = 'cache/moh/hospitallocations.rds')
```

## HBAM Historical and Projected Data Prep W/Output
```{r hbam cleaning, include=FALSE, eval=TRUE}

# HBAM Historical
HBAMhistoricalprep <- HBAMhistorical %>% 
  select(year = Year, 
         siteid = Hospital_Site_ID,
         hospitalname = Hospital_Site_Name,
         caretype = Care_Type,
         agegroup = Age_Group, 
         cases = Number_of_Cases,
         orig_csd = CSD) %>% 
  # filter(year == 2016) %>% 
  # select(-year) %>% 
  filter(orig_csd < 4600000,
         orig_csd > 3501000) %>% 
  mutate(agegroup = replace(agegroup, agegroup == '0-17', 1),
         agegroup = replace(agegroup, agegroup == '18-44', 2),
         agegroup = replace(agegroup, agegroup == '45-64', 3),
         agegroup = replace(agegroup, agegroup == '65-74', 4),
         agegroup = replace(agegroup, agegroup == '75-84', 5),
         agegroup = replace(agegroup, agegroup == '>85', 6),
         agegroup = replace(agegroup, agegroup == '<1', 1),
         agegroup = replace(agegroup, agegroup == '1-7', 1),
         agegroup = replace(agegroup, agegroup == '8-17', 1),
         caretype = replace(caretype, caretype == 'IP', 'AT'),
         caretype = replace(caretype, caretype == 'CCC', 'CR'),
         caretype = replace(caretype, caretype == 'Rehab', 'GR')) %>% 
  left_join(select(hospitallocationsapp, datasetID1.siteid, id), by = c('siteid' = 'datasetID1.siteid')) %>% 
  left_join(select(hospitallocationsapp, datasetID2.siteid, id), by = c('siteid' = 'datasetID2.siteid')) %>% 
  left_join(select(hospitallocationsapp, datasetID3.siteid, id), by = c('siteid' = 'datasetID3.siteid')) %>% 
  left_join(select(hospitallocationsapp, datasetID4.siteid, id), by = c('siteid' = 'datasetID4.siteid')) %>% 
  left_join(select(hospitallocationsapp, datasetID5.siteid, id), by = c('siteid' = 'datasetID5.siteid')) %>% 
  left_join(select(hospitallocationsapp, datasetID6.siteid, id), by = c('siteid' = 'datasetID6.siteid')) %>% 
  ungroup() %>% 
  mutate(id = pmax(replace_na(id.x, 0), replace_na(id.x.x, 0), replace_na(id.x.x.x,0), replace_na(id.y, 0), replace_na(id.y.y, 0), replace_na(id.y.y.y, 0))) %>% 
  select(-id.x, -id.x.x, -id.x.x.x, -id.y, -id.y.y, -id.y.y.y) %>% 
  mutate(id = replace(id, id == 0, -9999))

# Historical HBAM Master Dataset
HBAMhistorical_master <- HBAMhistoricalprep %>% 
  mutate(caretype = replace(caretype, caretype == "ER", "AM"),
         caretype = replace(caretype, caretype == "DS", "AM")) %>% 
  left_join(distinct(hospitallocationsapp, id, name, facilityid, pcode, lat, long), by = c('id'))

#Output cache historical HBAM for use in hospitals.rmd
saveRDS(HBAMhistorical_master, file = 'cache/moh/hbamhistorical_master.rds')

# HBAM Projected
HBAMprojectedprep <- HBAMprojected %>% 
  select(year = Year, 
         siteid = Hospital_Site_ID, 
         hospitalname = Hospital_Site_Name,
         caretype = Care_Type,
         agegroup = Age_Group, 
         cases = Number_of_Cases,
         lengthofstay = Length_of_Stay) %>% 
  mutate(agegroup = replace(agegroup, agegroup == '0-17', 1),
         agegroup = replace(agegroup, agegroup == '18-44', 2),
         agegroup = replace(agegroup, agegroup == '45-64', 3),
         agegroup = replace(agegroup, agegroup == '65-74', 4),
         agegroup = replace(agegroup, agegroup == '75-84', 5),
         agegroup = replace(agegroup, agegroup == '>85', 6),
         agegroup = replace(agegroup, agegroup == '<1', 1),
         agegroup = replace(agegroup, agegroup == '1-7', 1),
         agegroup = replace(agegroup, agegroup == '8-17', 1),
         caretype = replace(caretype, caretype == 'IP', 'AT'),
         caretype = replace(caretype, caretype == 'CCC', 'CR'),
         caretype = replace(caretype, caretype == 'Rehab', 'GR'),
         caretype = replace(caretype, caretype == 'ER', 'AM'),
         caretype = replace(caretype, caretype == 'DS', 'AM')) %>% 
  left_join(select(hospitallocationsapp, datasetID1.siteid, id), by = c('siteid' = 'datasetID1.siteid')) %>% 
  left_join(select(hospitallocationsapp, datasetID2.siteid, id), by = c('siteid' = 'datasetID2.siteid')) %>% 
  left_join(select(hospitallocationsapp, datasetID3.siteid, id), by = c('siteid' = 'datasetID3.siteid')) %>% 
  left_join(select(hospitallocationsapp, datasetID4.siteid, id), by = c('siteid' = 'datasetID4.siteid')) %>% 
  left_join(select(hospitallocationsapp, datasetID5.siteid, id), by = c('siteid' = 'datasetID5.siteid')) %>% 
  left_join(select(hospitallocationsapp, datasetID6.siteid, id), by = c('siteid' = 'datasetID6.siteid')) %>% 
  ungroup() %>% 
  mutate(id = pmax(replace_na(id.x, 0), replace_na(id.x.x, 0), replace_na(id.x.x.x,0), replace_na(id.y, 0), replace_na(id.y.y, 0), replace_na(id.y.y.y, 0))) %>% 
  select(-id.x, -id.x.x, -id.x.x.x, -id.y, -id.y.y, -id.y.y.y) %>% 
  mutate(id = replace(id, id == 0, -9999))

# Projected HBAM Master Dataset
HBAMprojected_master <- HBAMprojectedprep %>% 
  group_by(year, id, caretype, agegroup) %>% 
  summarise(cases = sum(cases),
            los = sum(lengthofstay)) %>% 
  mutate(beddays = (cases*los)) %>% 
  left_join(distinct(hospitallocationsapp, id, name, facilityid, pcode, lat, long), by = c('id')) %>% 
  filter(!is.na(pcode))

#Output cache historical HBAM for use in hospitals.rmd
saveRDS(HBAMprojected_master, file = 'cache/moh/hbamprojected_master.rds')

```

## ALC Data Cleaning W/Output
```{r alc data cleaning, include=FALSE, eval=TRUE}

#ALC Datasets
#CCO Linkage Table

ALC_idcrosswalkprep <- ALC_idcrosswalk %>%
  filter(!is.na(WTISSiteNum)) %>% 
  select(lhin = WTISLHINNum,
         name = MNSName,
         alcname = WTISSiteName,
         type = MNSType,
         siteid = MNSMaster,
         ALCsite_id = WTISSiteNum,
         facilityid = MNSFacNum) %>%
  # join to hospital locations on all possible historical datasetID values
  left_join(select(hospitallocationsapp, datasetID1.siteid, id), by = c('siteid' = 'datasetID1.siteid')) %>% 
  left_join(select(hospitallocationsapp, datasetID2.siteid, id), by = c('siteid' = 'datasetID2.siteid')) %>% 
  left_join(select(hospitallocationsapp, datasetID3.siteid, id), by = c('siteid' = 'datasetID3.siteid')) %>% 
  left_join(select(hospitallocationsapp, datasetID4.siteid, id), by = c('siteid' = 'datasetID4.siteid')) %>% 
  left_join(select(hospitallocationsapp, datasetID5.siteid, id), by = c('siteid' = 'datasetID5.siteid')) %>% 
  left_join(select(hospitallocationsapp, datasetID6.siteid, id), by = c('siteid' = 'datasetID6.siteid')) %>%
  ungroup() %>% 
  mutate(id = pmax(replace_na(id.x, 0), replace_na(id.x.x, 0), replace_na(id.x.x.x,0), replace_na(id.y, 0), replace_na(id.y.y, 0), replace_na(id.y.y.y, 0))) %>% 
  select(-id.x, -id.x.x, -id.x.x.x, -id.y, -id.y.y, -id.y.y.y, -alcname, -facilityid, -siteid, -type) %>% 
  # Bring in postal code from hospital locations
  distinct() %>% 
  left_join(distinct(hospitallocationsapp, id, pcode), by = 'id') %>% 
  mutate(pcode.clean = gsub("\\s+", "", pcode)) %>%
  left_join(select(pccfSlimHosp, alc.lat = lat, alc.long = long, postal.code, csduid, csdname), by = c('pcode.clean' = 'postal.code')) %>%
  select(-pcode.clean, -alc.lat, -alc.long) %>% 
  select(lhin, name, pcode, id, ALCsite_id, csduid, csdname) %>% 
  # Clean dataset
  group_by(id) %>%
  # Remove duplicate entries where ALCsite_id is NA
  mutate(duplicate_count = n(), remove = ifelse((duplicate_count > 1) & (is.na(ALCsite_id)) & id > 0, 1, 0)) %>%
  filter(remove != 1) %>%
  # Remove rows where ALCsite_id is duplicated in another row but CSD info is missing
  group_by(ALCsite_id) %>%
  mutate(duplicate_count = n(), id_check = max(id), remove = ifelse((duplicate_count > 1) & (is.na(id_check) == FALSE) & (is.na(csduid)), 1, 0)) %>%
  filter(remove != 1) %>%
  select(-duplicate_count, -remove, -id_check) %>% 
  # Remove truly duplicate entries
  group_by(id, ALCsite_id) %>%
  arrange(id, name) %>%
  filter(row_number()==1) %>% 
  ungroup()

# Output ALC ID Crosswalk cache for input into hospitals.rmd
saveRDS(ALC_idcrosswalkprep, file = 'cache/moh/ALC_crosswalk.rds')

#Most recent updated ALC Data from CCO w/ MADD and DD typeflags
ALC_madd_rawprep <- ALC_madd_raw %>%
  filter(INPATIENTBEDTYPE == 'AP',
         casetype == 9,
         TYPEFLAG == 'MADD')%>% 
  select(year = period,
         number,
         siteid = sitenumber,
         madd,
         agegroup = Agerange,
         patients = '_FREQ_',
         avg.los = MEAN,
         alcdays = SUM) %>% 
  mutate(year = replace(year, year == '1112', 2011),
         year = replace(year, year == '1213', 2012),
         year = replace(year, year == '1314', 2013),
         year = replace(year, year == '1415', 2014),
         year = replace(year, year == '1516', 2015),
         year = replace(year, year == '1617', 2016),
         year = replace(year, year == '1718', 2017))

#output to cache for use in hospitals.rmd
saveRDS(ALC_madd_rawprep, file = 'cache/moh/ALC_madd_raw.rds')



```

## CIHI & LTC Prep W/Output
```{r}
#CIHI Data
CIHIhospitalbeds <- read_csv('input/moh/cap.CIHI_Hospital_Beds.csv') %>% 
  select(year = Year,
         prov = Province,
         name = 'Hospital Name',
         hosp_type = 'Type of Hospital',
         cihi_total = Total) %>%  
  mutate(name = toupper(name))

#output for hospitals.rmd use
saveRDS(CIHIhospitalbeds, file = 'cache/moh/CIHI_hospitalbeds.rds')

#LTC Facility Data
ltc_homes <- read_csv('input/moh/20190628_LTC Homes Query.csv') %>% 
  select(sector = Sector,
         city = 'Homes City',
         postal.code = 'Homes Postal Code',
         beds = 'Total Beds') %>% 
  mutate(pcode.clean = gsub("\\s+", "", postal.code)) %>%
  left_join(select(pccfSlimHosp, ltc.lat = lat, ltc.long = long, postal.code, csduid, csdname), by = c('pcode.clean' = 'postal.code')) %>%
  select(-pcode.clean, -ltc.lat, -ltc.long) 

#output for hospitals.rmd use
saveRDS(ltc_homes, file = 'cache/moh/ltc_homes.rds')
```


##Daily Bed Census Data Cleaning and Aggregation W/ Output
  - Simplify and aggregate daily census to annual figures
  - Calculate the number of daily entries available for each site id
  - Calculate Annualization factor
  - Calculate Operational and Physical Capacity
```{r}
#Count Daily Entries by Year: 2017:294 / 2018: 324
dailybedcensusprepagg <- dailybedcensusprep %>%
  filter(year == 2017) %>% 
  group_by(censusdate) %>% 
  mutate(sumbeds = sum())
  # group_by(year) %>% 
  # distinct(censusdate) %>% 
  # count(censusdate) %>% 
  # summarise(totaldays = sum(n, na.rm = TRUE))

#Total Daily Entries by SiteID
dailyentrycount <- dailybedcensusprepagg %>% 
  group_by(siteid, year) %>% 
  count(siteid) %>% 
  rename('entrycount' = 'n')

# Total bed counts by year by care type, province-wide, for reference only - not used in downstream calculations
num_beds_province <- dailybedcensusprepagg %>%
  mutate(siteid = as.numeric(siteid)) %>%
  group_by(year, censusdate, type) %>%
  mutate(totstaffbeds = sum(staffedbeds)) %>%
  ungroup() %>%
  group_by(year, type) %>%
  mutate(maxstaffedbeds = max(totstaffbeds, na.rm = TRUE)) %>%
  distinct(year, type, maxstaffedbeds)

# Bed counts by year by caretype by siteid
num_beds <- dailybedcensusprepagg %>%
  mutate(siteid = as.numeric(siteid)) %>%
  group_by(year, censusdate, type) %>%
  mutate(totstaffbeds = sum(staffedbeds)) %>%
  ungroup() %>%
  group_by(year, type) %>%
  mutate(maxstaffedbeds = max(totstaffbeds, na.rm = TRUE)) %>%
  # Take the census day which has the highest staffed beds
  filter(totstaffbeds == maxstaffedbeds) %>% 
  # Filter data since there may be more than one census day tied for having max staffed beds - this occurs for one care type in 2018
  filter(censusdate == first(censusdate)) %>% 
  distinct(year, type, siteid, censusdate, staffedbeds, totstaffedbeds) %>% 
  group_by(year) %>%
  mutate(maxbeds.annual = sum(staffedbeds))

#Output num_beds to cache for input into hospitals.rmd
saveRDS(num_beds, file = 'cache/moh/num_beds.rds')

#Annual Bed-Days Observed
beddaysobserved <- dailybedcensusprepagg %>% 
  group_by(siteid,
           type,
           year) %>% 
  summarise(atbedsobs = sum(atbeds, na.rm = TRUE),
            mhbedsobs = sum(mhbeds, na.rm = TRUE),
            cccbedsobs = sum(cccbeds, na.rm = TRUE),
            grbedsobs = sum(grbeds, na.rm = TRUE),
            srbedsobs = sum(grbeds, na.rm = TRUE),
            patientbedsobs = sum(patientbeds, na.rm = TRUE),
            staffedbedsobs = sum(staffedbeds, na.rm = TRUE))

#Annualization Factor from Residual Day-Count
annualizationfactor <- dailybedcensusprepagg %>% 
  group_by(siteid,
           type,
           year) %>% 
  left_join(dailyentrycount, by = c('siteid' = 'siteid', 'year' = 'year')) %>% 
  mutate(remainingdays = 365 - entrycount,
         atbedsaf = mean(atbeds, na.rm = TRUE, trim = 1)*remainingdays,
         mhbedsaf = mean(mhbeds, na.rm = TRUE, trim = 1)*remainingdays,
         cccbedsaf = mean(cccbeds, na.rm = TRUE, trim = 1)*remainingdays,
         grbedsaf = mean(grbeds, na.rm = TRUE, trim = 1)*remainingdays,
         srbedsaf = mean(grbeds, na.rm = TRUE, trim = 1)*remainingdays,
         patientbedsaf = mean(patientbeds, na.rm = TRUE, trim =1)*remainingdays,
         staffedbedsaf = mean(staffedbeds, na.rm = TRUE, trim = 1)*remainingdays) %>% 
  distinct(siteid,type, year, atbedsaf, mhbedsaf, cccbedsaf, grbedsaf, srbedsaf, patientbedsaf, staffedbedsaf)


#FOR INFO
##Count Total Site IDs: 448
dailybedcensusprepagg %>%
  distinct(siteid) %>%
  tally

##List of Care-Types
dailybedcensusprepagg %>%
  group_by(type) %>%
  distinct(type)
```



# MAG Data Import
```{r mag import, include=FALSE}
courthouse_asset <- read_csv("input/mag/Court asset data.csv")
courthouse_hours <- read_csv("input/mag/MAG_CRT_HRS_DB.csv")
```

# MAG Data Cleaning

## Import Data Prep
```{r import court data prepping}
courthouse_asset <- courthouse_asset %>% 
  select(year = Collection_Year, bid = BID, name = BuildingName, address = Address1,
         postal.code = PostalCode, city = City, courthouse.lat = Latitude, courthouse.long = Longitude,
         building.type = BuildingType, courtrooms = Courtrooms, region = Region, 
         rentable.square.feet = Rentable_square_feet,
         gross.square.feet = Gross_square_feet) %>% 
  mutate(gross.square.feet = as.numeric(gross.square.feet), courtrooms = as.numeric(courtrooms)) %>% 
  replace_na(list(gross.square.feet = 0, courtrooms = 0)) %>% 
  # Remove entries which are not base court or satelite court
  filter(building.type %in% c("Base Court", "Satellite Court") | name == "Napanee OCJ Courthouse + VWAP Office" |
           name == "Timmins OCJ Courthouse" | name == "Toronto SCJ + Family Courthouse") %>%
  # Assume satellite courthouses with 0 courtrooms to be 1
  mutate(courtrooms = ifelse(building.type == "Satellite Court" & courtrooms == 0, 1, courtrooms)) %>% 
  mutate(courtrooms = replace(courtrooms, name == "Smith Falls Satellite Court", 1)) %>% 
  # Remove entries manually after the base court and satellite court filters
  filter(name != "Milton Courthouse (Double with 18784)") %>% 
  filter(name != "Sarnia Courthouse- Land Registry Office Building") %>% 
  filter(name != "Newmarket Courthouse - Modular Addition") %>% 
  filter(name != "Parry Sound Jail - Holding Cells") %>% 
  filter(name != "Temp Swing Space for 361 University Ave relocation for Firepanel Project") %>% 
  filter(name != "OPP Sally Port") %>% 
  filter(name != "Elliot Lake Victim Witness Assiatance Program Office") %>% 
  filter(name != "Renfrew SCJ Small Claims Administration Office") %>% 
  filter(!(city == "St. Thomas" & courtrooms == 0)) %>% 
  filter(!(city == "Barrie" & courtrooms == 0)) %>% 
  filter(!(city == "Sault Ste. Marie" & courtrooms == 0)) %>% 
  filter(!(city == "Sudbury" & courtrooms == 0)) %>% 
  # Misaligned data for city entry
  mutate(city = replace(city, name == "Toronto SCJ + Family Courthouse", "Toronto")) %>% 
  mutate(city = replace(city, name == "Toronto Courthouse", "Toronto"))
  

courthouse_hours <- courthouse_hours %>% 
  rename(year = Year, region = REGION, city = LOCATION, address = ADDRESS) %>% 
  rename_at(vars(contains("CJ"), contains("COURT"), contains("TOTAL"), contains("CIVIL")), tolower) %>% 
  rename_at(vars(contains(",_")), funs(sub(",_", "_", .))) %>% 
  rename(number_of_courtrooms = "number of courtrooms") %>% 
  mutate(SCJfam = family_court_branch + scj_family, smac = divisional_court+small_claims_court) %>% 
  select(-family_court_branch, -scj_family, -divisional_court, -small_claims_court) %>%
  rename(OCJcrim= 'ocj_criminal', OCJfam= 'ocj_family', SCJcrim= 'scj_criminal') %>% 
  mutate(year = as.numeric(substr(year, 1, 4))) %>% 
  mutate(city = stringr::str_to_title(city),
         region = toupper(tolower(region))) %>% 
  mutate(city = replace(city, city == "L'orignal", "L'Orignal")) %>% 
  mutate(address = ifelse(is.na(address), address, paste0(address, " St"))) %>% 
  mutate(address = replace(address, address == "36 Wyndham St", "36 Wyndham St S")) %>% 
  mutate(address = replace(address, address == "245 Windsor St", "245 Windsor Ave")) %>% 
  mutate(address = replace(address, address == "48 Spruce St", "48 Spruce Street North")) %>% 
  mutate(address = replace(address, address == "1023 King St", "1023-1025 King St")) %>% 
  mutate(address = replace(address, address == "97 Thomas St", "97 Thomas St E")) %>% 
  mutate(address = replace(address, address == "49 Place D'Armes St", "49 Place D'Armes")) %>% 
  mutate(address = replace(address, address == "55 Main St", "55 Main St W")) %>% 
  mutate(address = replace(address, address == "45 Main St", "45 Main Street E")) %>% 
  mutate(address = replace(address, address == "70 Simcoe St", "70-110 Simcoe St")) %>% 
  mutate(address = replace(address, address == "1000 FINCH St", "1000 Finch Ave W")) %>% 
  mutate(address = replace(address, address == "2201 FINCH St", "2201 Finch Ave W")) %>% 
  mutate(address = replace(address, address == "361 UNIVERSITY St", "361 University Ave")) %>%
  mutate(address = replace(address, address == "130 QUEEN, 330/393 UNIVERSITY St", "393 University Ave")) %>% 
  mutate(address = replace(address, address == "311 JARVIS St", "311 Jarvis St")) %>% 
  mutate(address = replace(address, address == "COLLEGE PARK St", "444 Yonge Street")) %>% 
  mutate(address = replace(address, address == "OLD CITY HALL St", "60 Queen St W")) %>% 
  mutate(address = replace(address, address == "38 Pine St", "38 Pine St N")) %>% 
  mutate(address = replace(address, address == "41 Dundas St", "41 Dundas St W")) %>% 
  mutate(address = replace(address, address == "1911 EGLINTON St", "1911 Eglinton Ave E")) %>% 
  mutate(address = replace(address, address == "47 SHEPPARD St", "47 Sheppard Ave E"))
```

## Data Cleaning Court Master List W/ Output
- Combine the asset data (`courthouse_asset`) with the 5 year historical court-hour data (`courthouse_hours`) to give location informaiton
- It is assumed that the dataset with historical court-hour is the source of truth
  - There is a mismatch between asset data and historical data, the asset data splits up the satellite courthouses while the historical data combines them as one entry. Since the source of truth is in the court-hour data, it is assumed that all satellite courthouses have 1 court room and they belong to the base courthouse of the CD.
  - If there are multiple base courthouse in the CD; the closer base courthouse is taken to be the base of the satellite courthouses
  - The total number of courtrooms in the satellite courthouses and their base courthouse will be equal to the value in the court-hour dataset

```{r clean courthouse hours}

# Group the 3 Toronto Courthouses into 1 entry at 130 QUEEN, 330/393 UNIVERSITY St
temp <- filter(courthouse_asset, address %in% c("130 Queen St W", "393 University Ave", "330 University Ave")) %>% 
  group_by(city) %>% 
  summarise(courtrooms = sum(courtrooms),
            rentable.square.feet = sum(rentable.square.feet), 
            gross.square.feet = sum(gross.square.feet))

courthouse_asset <- courthouse_asset %>% 
  filter(!(address %in% c("130 Queen St W", "330 University Ave"))) %>% 
  mutate(courtrooms = replace(courtrooms, address == "393 University Ave", temp$courtrooms)) %>% 
  mutate(rentable.square.feet = replace(rentable.square.feet, address == "393 University Ave", temp$rentable.square.feet)) %>% 
  mutate(gross.square.feet = replace(gross.square.feet, address == "393 University Ave", temp$gross.square.feet))

# Spread the 5 year data into wide format
courthouse_hours_wide <- courthouse_hours %>% 
  gather(variable, value, -(year:address)) %>% 
  unite(temp, year, variable) %>%
  spread(key = "temp", value = "value") 

# Join courthouse_hours_wide with courthouse_asset dataset to get lat/long information
courthouse_hours_wide_location <- courthouse_hours_wide %>% 
  left_join(select(courthouse_asset, bid, name, address, city, courthouse.lat, courthouse.long), by = c("city", "address")) %>% 
  left_join(select(distinct(courthouse_asset, city, .keep_all = TRUE), bid, name, address, city, courthouse.lat, courthouse.long), by = c("city")) %>%
  mutate(bid = ifelse(is.na(bid.x), bid.y, bid.x)) %>% 
  mutate(name = ifelse(is.na(name.x), name.y, name.x)) %>% 
  mutate(address = ifelse(is.na(address.x), address.y, address.x)) %>% 
  mutate(courthouse.lat = ifelse(is.na(courthouse.lat.x), courthouse.lat.y, courthouse.lat.x)) %>% 
  mutate(courthouse.long = ifelse(is.na(courthouse.long.x), courthouse.long.y, courthouse.long.x)) %>% 
  select(-bid.x, -bid.y, -name.x, -name.y, -address.x, -address.y,
         -courthouse.lat.x, -courthouse.lat.y, -courthouse.long.x, -courthouse.long.y)

# Overlay on TRESO zones to get the CDUID
treso_shp <- readOGR(dsn = "input/treso", layer = "TRESO_Zones_SocioData_Gatineau_LCC") 
treso_zone_system <- read_csv('input/treso/treso_zone_system.csv')
courthouse_hours_xy <- create_court_xy(courthouse_hours_wide_location)
courthouse_hours_overlay <- create_overlay(courthouse_hours_xy, treso_shp, type = "court")
courthouse_hours_overlay <- courthouse_hours_overlay %>% 
  left_join(treso_zone_system, by = c("treso.id.pos" = "treso_id")) %>% 
  left_join(courthouse_hours_wide_location, by = "bid")

#issue long form of court hour dataset for easy use
courthouse_hours_overlay_long <- courthouse_hours_overlay %>%
  gather(key = "year", value, `2014_civil`:`2018_total`) %>% 
  separate(year, c("year", "casetypes"), sep = 4) %>% 
  spread(key = casetypes, value) %>% 
  select(-"_number_of_courtrooms","_number_of_courtrooms" ) %>% 
  gather(key="casetypes", value, `_civil`:`_smac`) %>% 
  rename("number_of_courtrooms" = "_number_of_courtrooms", "total" = "_total") %>% 
  select(-"total", -"number_of_courtrooms", "total", "number_of_courtrooms") %>% 
  mutate(casetypes = substring(casetypes, 2))

# Save the wide court hour dataset
saveRDS(courthouse_hours_overlay_long, "cache/mag/courthouse_hours.rds")

rm(temp, courthouse_hours_wide_location, courthouse_hours_wide, courthouse_hours_xy)
```

```{r clean courthouse asssets}
# Relying on the assumption that satellite courthouses are 1 courtroom and satellite courthouses are within the same
# CD as the base courthouse, distribute the total courtrooms appropriately
courthouse_asset_xy <- create_court_xy(courthouse_asset)
courthouse_asset_overlay <- create_overlay(courthouse_asset_xy, treso_shp, type = "court") %>% 
  left_join(treso_zone_system, by = c("treso.id.pos" = "treso_id")) %>% 
  left_join(courthouse_asset, by = "bid") %>% 
  mutate(building.type = replace(building.type, 
                                 building.type %in% c("Office", "Court Support Office"), 
                                 "Base Court")) %>% 
  # There are a few satellite courts in Sudbury but base court is in Greater Sudbury, replace those manually
  mutate(cdname = replace(cdname, cdname == "Sudbury", "Greater Sudbury / Grand Sudbury")) %>% 
  mutate(cduid = replace(cduid, cduid == 3552, 3553)) %>%
  left_join(select(courthouse_hours_overlay, bid, `2018_number_of_courtrooms`), by = "bid") %>% 
  mutate(courtrooms = ifelse(building.type == "Satellite Court", courtrooms, `2018_number_of_courtrooms`)) %>% 
  select(-`2018_number_of_courtrooms`)

# Distribute the base courthouse's courtrooms to satellite courthouses
multiple_courthouse_asset_tag <- courthouse_asset_overlay %>% 
  filter(building.type == "Base Court") %>% 
  group_by(cdname) %>% 
  summarise(mutilple.basecourts.tag = ifelse(n() > 1, 1, 0))

courthouse_asset_overlay <- left_join(courthouse_asset_overlay, multiple_courthouse_asset_tag, by = "cdname")

multiple_basecourts_satellite_rooms <- filter(courthouse_asset_overlay, mutilple.basecourts.tag == 1) %>% 
  filter(building.type == "Satellite Court") %>% 
  group_by(cdname) %>% 
  summarise(total.satellite.rooms = sum(courtrooms))

multiple_basecourts <- filter(courthouse_asset_overlay, mutilple.basecourts.tag == 1) %>% 
  left_join(multiple_basecourts_satellite_rooms, by = "cdname") %>% 
  replace_na(list("total.satellite.rooms" = 0))

multiple_basecourts_satellite_room_share <- multiple_basecourts %>% 
  filter(building.type == "Base Court") %>% 
  group_by(cdname) %>% 
  mutate(total.base.courts = n()) %>% 
  ungroup() %>% 
  mutate(share.of.satellite = total.satellite.rooms / total.base.courts) %>% 
  arrange(cdname)

# Apply bucket rounding to chunks of data by TRESO POS
bucket_round_share <- by(multiple_basecourts_satellite_room_share$share.of.satellite, 
                         multiple_basecourts_satellite_room_share[c("cdname")], smart_round, simplify = FALSE)

# Convert the output of by() to a dataframe
temp <- sapply(bucket_round_share, I) %>% 
  data.table::melt() %>% 
  rename(share.of.satellite.rounded = value, cdname = L1) %>% 
  mutate(share.of.satellite.rounded = as.numeric(share.of.satellite.rounded)) %>% 
  arrange(cdname) %>% 
  select(-cdname) %>% 
  cbind(multiple_basecourts_satellite_room_share) %>% 
  mutate(courtrooms = ifelse(building.type == "Base Court", courtrooms - share.of.satellite.rounded, courtrooms))

# If there are negative courtooms in any base courts, manually shift them from another courthouse
print(paste0("There are ", nrow(filter(temp, courtrooms < 1)), " base court(s) with less than one courtroom"))
temp <- temp %>% 
  mutate(courtrooms = ifelse(name == "Stratford SCJ Courthouse", courtrooms + 1, courtrooms)) %>% 
  mutate(courtrooms = ifelse(name == "Stratford OCJ Courthouse", courtrooms - 1, courtrooms)) %>% 
  select(bid, courtrooms.reduced = courtrooms)
print(paste0("There are ", nrow(filter(temp, courtrooms.reduced < 1)), " base court(s) with less than one courtroom"))

multiple_basecourts <- left_join(multiple_basecourts, temp, by = "bid") %>% 
  mutate(courtrooms = ifelse(is.na(courtrooms.reduced), courtrooms, courtrooms.reduced)) %>% 
  select(-mutilple.basecourts.tag, -total.satellite.rooms, -courtrooms.reduced)
  
# Distribute satellite courthouses in CD with a single basecourt
single_basecourts_satellite_rooms <- filter(courthouse_asset_overlay, mutilple.basecourts.tag == 0) %>% 
  filter(building.type == "Satellite Court") %>% 
  group_by(cdname) %>% 
  summarise(total.satellite.rooms = sum(courtrooms))

single_basecourts <- filter(courthouse_asset_overlay, mutilple.basecourts.tag == 0) %>% 
  left_join(single_basecourts_satellite_rooms, by = "cdname") %>% 
  replace_na(list("total.satellite.rooms" = 0)) %>% 
  mutate(courtrooms = ifelse(building.type == "Base Court", courtrooms - total.satellite.rooms, courtrooms)) %>% 
  select(-mutilple.basecourts.tag, -total.satellite.rooms)

# If there are negative courtooms in any base courts, manually shift them from another courthouse
print(paste0("There are ", nrow(filter(single_basecourts, courtrooms < 1)), " base court(s) with less than one courtroom"))
  
courthouse_asset_distributed <- rbind(multiple_basecourts, single_basecourts)
```

```{r append caretypes serviced}
courthouse_service_caretypes <- readRDS("cache/mag/courthouse_hours.rds") %>% 
  filter(value != 0) %>% 
  group_by(bid) %>% 
  summarise(casetypes.serviced = paste(unique(casetypes), collapse = ","))

courthouse_asset_casetypes <- left_join(courthouse_asset_distributed, courthouse_service_caretypes, by = "bid") %>% 
  group_by(cduid) %>% 
  mutate(casetypes.serviced = ifelse(building.type == "Satellite Court",
                                     paste(unique(casetypes.serviced), collapse = ","),
                                     casetypes.serviced)) %>% 
  ungroup() %>%
  unnest(casetypes.serviced = strsplit(casetypes.serviced, ",")) %>% 
  filter(casetypes.serviced != "NA") %>% 
  distinct(bid, casetypes.serviced, .keep_all = TRUE) %>% 
  group_by_at(vars(-casetypes.serviced)) %>% 
  summarise(casetypes.serviced = paste(casetypes.serviced, collapse = ",")) %>% 
  ungroup()

saveRDS(courthouse_asset_casetypes, "cache/mag/courthouse_master.rds")
```





# Unused Code - Potential for Future Need
## EDU Unused Code
## Health Unused Code

```{r sql health code, include=FALSE, eval=FALSE}
healthRodbc <-odbcConnect("NourDSN")

#Bed Census Data
dailybedhistory <- sqlFetch(healthRodbc, "cap.MOH_DailyBedCensus_Historical")
dailybedcensus <- sqlFetch(healthRodbc, "cap.MOH_DailyBedCensus_Summary")
hospitaldischarges <- sqlFetch(healthRodbc, "cap.MOH_Discharges")

#HBAM Data
HBAMhistorical <- sqlFetch(healthRodbc, "cap.MOH_HBAM_HIST")
HBAMprojected <- sqlFetch(healthRodbc, "cap.MOH_HBAM_PROJECT")

#LHIN Data
populationLHIN <- sqlFetch(healthRodbc, "dbo.Population_LHIN")
healthbeddays <- sqlFetch(healthRodbc, "cap.MOH_Pat_Bed_Days")

#ALC Data
ALCage <- sqlFetch(healthRodbc, "cap.ALCAge")
ALCannualvolume <- sqlFetch(healthRodbc, "cap.ALCAnnualVolumeAndTotalDays")
ALCcases <- sqlFetch(healthRodbc, "cap.ALCCases")
ALCdesignations <- sqlFetch(healthRodbc, "cap.ALCDesignations")
ALCdischargedest <- sqlFetch(healthRodbc, "cap.ALCDischargeDestination")
ALCinpatientbedtype <- sqlFetch(healthRodbc, "cap.ALCInpatientBedType")
ALCmostappropriate <- read_csv('P:/Y362/2019/191-00826-00 MOI Capacity and Demand Model/3. Modelling/moi_cu_project/input/moh/ALC.MostAppropriateDischage from CCO_2019-06-28.csv')

#CIHI Data
CIHIhospitalbeds <- sqlFetch(healthRodbc, "cap.CIHI_Hospital_Beds")

#Health Asset Inventory
hospitallocations <- sqlFetch(healthRodbc, "dbo.MOH_Hospital_Locations")

#Lookup Tables
hospitalsitelookup <- sqlFetch(healthRodbc, "xRef.HC_HospitalSite_Lookup")
LHINlookup <- sqlFetch(healthRodbc, "xRef.HC_LHIN_Lookup")

#Sample Population Extraction by LHIN
healthPopulationLHIN %>%
  filter(LHIN=='South West') %>%
  arrange(Year, Gender, Age)

#List of Care-Types
caretypes <- healthHBAMprojected %>%
  distinct(Care_Type)


```

```{r health unused import code, include=FALSE, eval=FALSE}
#ALC Data
##Reference Files
ALCage <- read_csv('input/moh/cap.ALCAge.csv')
ALCcases <- read_csv('input/moh/cap.ALCCases.csv')
ALCdesignations <- read_csv('input/moh/cap.ALCDesignations.csv')
ALCdischargedest <- read_csv('input/moh/cap.ALCDischargeDestination.csv')
ALCinpatientbedtype <- read_csv('input/moh/cap.ALCInpatientBedType.csv')

#Hospital Discharge Data
hospitaldischarges <- read_csv('input/moh/cap.MOH_Discharges.csv')

#ALCmostappropriate
ALCmostappropriate <- read_csv('input/moh/ALCMostAppropriateDischage.csv')
```

```{r commented out code for testing, include=FALSE, eval=FALSE}
# TODO: Delete when code working
# a <- 3949
# hosploc <- hospitallocations %>%
#   filter(datasetID1.siteid == a | datasetID2.siteid == a | datasetID3.siteid == a | datasetID4.siteid == a | datasetID5.siteid == a | datasetID6.siteid == a)


## Hosp Site IDs that unmatched between projected HBAM and Hosp PAI (total from 2016-2026 = ~10.3m cases, averaging ~1m to ~900k cases p.a.) --> NO MORE MISSING DATA
# unmatched_hosp <- HBAMprojected %>% 
#   group_by(year, id, caretype, agegroup) %>% 
#   summarise(cases = sum(cases),
#             los = sum(lengthofstay)) %>% 
#   mutate(beddays = (cases*los)) %>% 
#   left_join(distinct(hospitallocations, id, caretype, pcode), by = c('id')) %>% 
#   filter(is.na(pcode))


#Test SiteID/Fac ID Linkages
#ALC_idlinkage <- left_join(hospitallocations, ALC_idcrosswalk, by = c('siteid', 'facilityid'), suffix = c('.moh', '.cco'))

#Identify Mismatched Site IDs
# ALC_mismatchedids <- ALC_idlinkage %>% 
#   filter(is.na(type))
# 
# ALC_mismatchedids %>% 
#   group_by(type) %>%
#   count()
# 
# ALC_idlinkage %>% 
#   count(type %in% lhin.moh)
# 
# #Filter out Mismatched IDs
# hospital_ALC_master <- ALC_idlinkage %>% 
#   filter(!is.na(type)) %>% 
#   group_by(siteid, facilityid, type, name.moh) %>% 
#   distinct()
```

```{r unused obsolete code, include=FALSE, eval=FALSE}
#hospital discharge data prep
hospitaldischargesprep <- hospitaldischarges %>%
  replace_na(list(Discharges = 0)) %>% 
  replace_na(list(Total_Days = 0)) %>% 
  mutate(ATSEPARATIONS = ifelse(ATSEPARATIONS == 'NULL', '0', ATSEPARATIONS),
         ATSEPARATIONS = as.integer(ATSEPARATIONS),
         TOTAL_DAYS1 = ifelse(TOTAL_DAYS1 == 'NULL', '0', TOTAL_DAYS1),
         TOTAL_DAYS1 = as.integer(TOTAL_DAYS1),
         ALC_DAYS = ifelse(ALC_DAYS == 'NULL', '0', ALC_DAYS),
         ALC_DAYS = as.integer(ALC_DAYS),
         agegroup = as.character(AGE_GROUP)) %>% 
  mutate(totaldays = TOTAL_DAYS1 + Total_Days,
         discharges = Discharges + ATSEPARATIONS) %>% 
  select(year = FY, 
         hospitalcorporation = HOSPITAL_CORPORATION,
         hospitalname = HOSPITAL_NAME, 
         facilityid = FACILITY_NO,
         siteid = SITE_ID,
         agegroup,
         bedtype = 'Bed Type',
         discharges,
         totaldays,
         ALCdays = ALC_DAYS) %>% 
  mutate(agegroup = substring(agegroup, 0, 1)) %>%
  mutate(agegroup = replace(agegroup, agegroup == 0, 1)) %>% 
  filter(agegroup != 7)

#ALCmostappropriate
ALCmostappropriateprep <- ALCmostappropriate %>% 
  separate(period, c("year", "month"), sep = "_") %>%
  select(year,
         month,
         siteid = sitenumber,
         casetype,
         bedtype = INPATIENTBEDTYPE,
         agegroup = Agerange,
         tag = TYPEFLAG,
         dd = DD,
         madd,
         freq = '_FREQ_',
         losmean = MEAN,
         losmedian = MEDIAN,
         los90thp = P90,
         totalALCdays = SUM) %>% 
  mutate(totalALCdays = as.numeric(totalALCdays),
         losmean = as.numeric(losmean),
         losmedian = as.numeric(losmedian),
         los90thp = as.numeric(los90thp)) %>% 
  filter(tag == 'MADD', 
         madd != 'ALL', #filter out sum values for DD
         agegroup != 9,
         casetype == 9,
         bedtype == 'AP') 

ALCmostappropriateprep %>% #Check number of months in Year entries (5 mo. in 2019)
  group_by(year) %>% 
  distinct(month) %>% 
  count()

ALCmostappropriateprep <- ALCmostappropriateprep %>% 
  group_by(year, siteid, agegroup, madd) %>%
  summarise(freq = sum(freq),
            totalALCdays = sum(totalALCdays))

#From daily bed census data cleaning section
#Operational Capacity by Hospital
hospitalopcap <- left_join(beddaysobserved, annualizationfactor, by = c('siteid', 'type', 'year')) %>% 
  mutate(atbeds = atbedsobs + atbedsaf,
         mhbeds = mhbedsobs + mhbedsaf,
         cccbeds = cccbedsobs + cccbedsaf,
         grbeds = grbedsobs + grbedsaf,
         srbeds = srbedsobs + srbedsaf,
         patientbeds = patientbedsobs + patientbedsaf,
         staffedbeds = staffedbedsobs + staffedbedsaf) %>% 
  select(siteid,
         type,
         year,
         atbeds,
         mhbeds,
         cccbeds,
         grbeds,
         srbeds,
         patientbeds,
         staffedbeds)

#From daily bed census data cleaning section
#Physcial Capacity
Hospitalphyscap <- dailybedcensusprepagg %>% 
  group_by(siteid, type, year) %>% 
  summarise(maxatbeds = max(atbeds, na.rm = TRUE)*365,
            maxmhbeds = max(cccbeds, na.rm= TRUE)*365,
            maxcccbeds = max(cccbeds, na.rm = TRUE)*365,
            maxgrbeds = max(grbeds, na.rm = TRUE)*365,
            maxsrbeds = max(srbeds, na.rm = TRUE)*365,
            maxpatientbeds = max(patientbeds, na.rm = TRUE)*365,
            maxstaffedbeds = max(staffedbeds, na.rm = TRUE)*365)
```


```{r obsolete}
  # - Aggregate HBAM caseload data to CSD level instead of hospital site ID level 
  # - Aggregate TRESO population data to CSD level
  
###CSD Caserate Calculations

HBAMhistorical_csd <- HBAMhistorical_master %>% 
  select(year,
         siteid,
         caretype,
         agegroup,
         cases,
         orig_csd) %>% 
  ungroup() %>% 
  group_by(year, orig_csd, caretype, agegroup) %>% 
  summarise(cases = sum(cases))

csd_pop <- treso_population_moh %>% 
  group_by(csduid, age_group) %>%
  summarise(population.2041 = sum(population.2041))

for (target in 2011:2031) {
  pop_var <- paste0('population.',target)
  temp_pop <- treso_population_moh %>%
    group_by(csduid, age_group) %>% 
    summarise(!!pop_var := sum(get(paste0('population.',target))))
  
  csd_pop <- left_join(csd_pop, temp_pop, by = c('csduid', 'age_group')) %>% 
    select(-population.2041, population.2041) # to move 2041 to the last column

}

rm(temp_pop)

#Convert TRESO-CSD Population data to long format
csd_pop_long <- gather(csd_pop, year, population, population.2011:population.2041, -age_group) %>% 
  separate(year, into = c('pop', 'year'), sep = "n.") %>% 
  mutate(year = as.numeric(year)) %>% 
  select(-pop)

#Join CSD and HBAM-CSD Origin Data and remove NA CSD values (outside of Ontario)
csd_caserates <- left_join(HBAMhistorical_csd, csd_pop_long, by = c('year', 'orig_csd' = 'csduid', 'agegroup' = 'age_group')) %>% 
  mutate(csd_caserate = cases/population) %>% 
  select(-cases, 
         -population) %>% 
  mutate(orig_cd = as.numeric(substring(orig_csd, 0,4)),
         csd_caserate = replace(csd_caserate, csd_caserate == Inf, 0)) #CSD populations w/ 0 (as summed TRESO zones w/ 0 population) result in Inf case-rates; replace with 0

# #FOR INFO - Deselect cases & population from csd_caserates code above for use
# #Calculte Mismatched CSDs
# mismatched_csd <- csd_caserates %>% 
#   filter(is.na(population)) %>% 
#   summarise(sum(cases)) #total of 57,951 mismatched cases from 89 CSDs

#Output for use in hospitals.rmd
saveRDS(csd_caserates, file = 'cache/moh/csd_caserates.rds')
```




```{r obsolete cont.}
  # - Convert HBAM data back to long format
  # - Calculate caserates per care-type disaggregated by age group
  # - Note: exclusion of CD's outside of Ontario (totalling ~40,000 cases of 8.2m, <0.5%)
  # - Note: HBAM age groups ped1:ped3 overlap within age group "1" but with unique case values. Therefore, replace function to include 'ped' age groups into ag1.
  #     - Population ped groups duplicate with population ag1, therefore, they are excluded from gather function (wide to long)


HBAMhistorical_cd <- HBAMhistorical_master %>% 
  mutate(orig_cd = substring(orig_csd, 0,4)) %>% 
  select(year, 
         siteid,
         caretype,
         agegroup,
         cases,
         orig_cd) %>% 
  group_by(year, orig_cd, caretype, agegroup) %>% 
  summarise(cases = sum(cases))

cd_pop_long <- csd_pop_long %>% 
  mutate(cd = substring(csduid, 0,4)) %>% 
  group_by(year, cd, age_group) %>% 
  summarise(population = sum(population))

cd_caserates <- left_join(HBAMhistorical_cd, cd_pop_long, by = c('year', 'orig_cd'= 'cd', 'agegroup'='age_group')) %>% 
  ungroup() %>% 
  mutate(cd_caserate = cases/population,
         orig_cd = as.numeric(orig_cd)) %>% 
  select(-cases,
         -population)

# #FOR INFO - TEST: To use, deselect cases & population from cd_caserates above
# mismatched_cd <- cd_caserates %>% 
#   filter(is.na(population)) %>% 
#   summarise(sum(cases))

saveRDS(cd_caserates, file = 'cache/moh/cd_caserates.rds')

```


```{r obsolete cont.2}
#Compile caserates into one df (CD and CSD)
caserates_comp <- full_join(csd_caserates, cd_caserates, by = c('year', 'agegroup', 'caretype', 'orig_cd')) %>% 
  select(year, caretype, agegroup,orig_csd, csd_caserate, orig_cd, cd_caserate)

saveRDS(caserates_comp, file = 'cache/moh/caserates_comp.rds')

####Plotting Caserates
ct <- 'AM'
csd_caserates_plot <- csd_caserates %>% 
  filter(caretype == ct,
         !csd_caserate == 'Inf') %>%
  group_by(year, agegroup, caretype) %>% 
  summarise(avg_cr = mean(csd_caserate)) %>% 
  ungroup()

ggplot(csd_caserates_plot, aes(x=year, y=avg_cr, color=as.factor(agegroup))) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)

```


```{r obsolete cont. 3}
  # - Calculate caserates by care types for provincial level disaggregated by age group

#Provincial Caserates
cases_total <- HBAMhistorical_csd_spread %>% 
  ungroup(csd) %>%
  summarise(cases_total = sum(cases_tot))

pop_total <- csd_pop %>%
  summarise(total_pop = sum(pop_tot))

provincial_caserate = cases_total/pop_total

#Provincial Caserate by CT
cases_ct <- HBAMhistorical_csd_spread %>% 
  ungroup(csd) %>% 
  group_by(caretype) %>% 
  summarise(cases_total = sum(cases_tot)) %>% 
  mutate(index_link = 1)

pop_total <- pop_total %>%
  mutate(index_link = 1) 
  
provincial_caserate_ct <- left_join(cases_ct, pop_total, by = 'index_link') %>% 
  mutate(caserate_ct = cases_total/total_pop) %>% 
  select(-index_link,
         caretype,
         caserate_ct)

#Provincial Caserate by Age Group
pop_agegroup <- csd_pop %>% 
  ungroup(csd) %>% 
  summarise(pop_tot = sum(pop_tot),
            pop_ag1 = sum(pop_ag1),
            pop_ag2 = sum(pop_ag2),
            pop_ag3 = sum(pop_ag3),
            pop_ag4 = sum(pop_ag4),
            pop_ag5 = sum(pop_ag5),
            pop_ag6 = sum(pop_ag6),
            pop_ped1 = sum(pop_ped1),
            pop_ped2 = sum(pop_ped2),
            pop_ped3 = sum(pop_ped3)) %>% 
  mutate(index_link = 1)

cases_agegoup <- HBAMhistorical_csd_spread %>% 
  ungroup(csd) %>%
  summarise(cases_tot = sum(cases_tot),
            cases_ag1 = sum(cases_ag1),
            cases_ag2 = sum(cases_ag2),
            cases_ag3 = sum(cases_ag3),
            cases_ag4 = sum(cases_ag4),
            cases_ag5 = sum(cases_ag5),
            cases_ag6 = sum(cases_ag6),
            cases_ped1 = sum(cases_ped1),
            cases_ped2 = sum(cases_ped2),
            cases_ped3 = sum(cases_ped3)) %>% 
  mutate(index_link = 1)
  
provincial_caserate_agegroup <- left_join(cases_agegoup, pop_agegroup, by = 'index_link') %>% 
  mutate(caserate_tot = cases_tot/pop_tot,
         caserate_ag1 = cases_ag1/pop_ag1,
         caserate_ag2 = cases_ag2/pop_ag2,
         caserate_ag3 = cases_ag3/pop_ag3,
         caserate_ag4 = cases_ag4/pop_ag4,
         caserate_ag5 = cases_ag5/pop_ag5,
         caserate_ag6 = cases_ag6/pop_ag6,
         caserate_ped1 = cases_ped1/pop_ped1,
         caserate_ped2 = cases_ped2/pop_ped2,
         caserate_ped3 = cases_ped3/pop_ped3) %>% 
  select(caserate_tot,
         caserate_ag1,
         caserate_ag2,
         caserate_ag3,
         caserate_ag4,
         caserate_ag5,
         caserate_ag6,
         caserate_ped1,
         caserate_ped2,
         caserate_ped3)

#Provincial Caserate by Caretype by Age Group
cases_ct_agegroup <- HBAMhistorical_csd_spread %>% 
  ungroup(csd) %>% 
  group_by(caretype) %>% 
    summarise(cases_tot = sum(cases_tot),
            cases_ag1 = sum(cases_ag1),
            cases_ag2 = sum(cases_ag2),
            cases_ag3 = sum(cases_ag3),
            cases_ag4 = sum(cases_ag4),
            cases_ag5 = sum(cases_ag5),
            cases_ag6 = sum(cases_ag6),
            cases_ped1 = sum(cases_ped1),
            cases_ped2 = sum(cases_ped2),
            cases_ped3 = sum(cases_ped3)) %>% 
  mutate(index_link = 1)

provincial_caserate_ct_agegroup <- left_join(cases_ct_agegroup, pop_agegroup, by = 'index_link') %>% 
  mutate(caserate_tot = cases_tot/pop_tot,
         caserate_ag1 = cases_ag1/pop_ag1,
         caserate_ag2 = cases_ag2/pop_ag2,
         caserate_ag3 = cases_ag3/pop_ag3,
         caserate_ag4 = cases_ag4/pop_ag4,
         caserate_ag5 = cases_ag5/pop_ag5,
         caserate_ag6 = cases_ag6/pop_ag6,
         caserate_ped1 = cases_ped1/pop_ped1,
         caserate_ped2 = cases_ped2/pop_ped2,
         caserate_ped3 = cases_ped3/pop_ped3) %>% 
  select(caretype,
         caserate_tot,
         caserate_ag1,
         caserate_ag2,
         caserate_ag3,
         caserate_ag4,
         caserate_ag5,
         caserate_ag6,
         caserate_ped1,
         caserate_ped2,
         caserate_ped3)


```


```{r obsolete cont. 4}

# <!-- ## ALC Data -->
# <!--   - Link Site IDs with missing Facility IDs (and vice-versa) for ALC data (both Annual Vol and MADD) -->
# <!--   - Given ALC data with multiple Site ID types (1-4-digit codes), each unique volume needs to be stripped out in order to get accurate totals -->
# <!--   - ALC Site number Counts: Total SiteID 647, ALC Total Counts 348, ALC Counts 4-digit IDs 201, Total Joined IDs 169       -->


#Isolate all 3-digit ALC-Site IDs (assuming single address/location)
three_digit_ALC <- ALCannualvolumeprep %>%
  filter(siteid < 999,
         siteid > 99) %>% 
  select (-casetype,
          -bedtype) 

unique_facilityids <- hospital_id_master %>% 
  mutate(pcode = as.character(pcode)) %>% 
  group_by(facilityid) %>%
  summarise(pcodecount = n_distinct(pcode)) %>%
  right_join(hospital_id_master, by=c('facilityid')) %>% 
  filter(pcodecount == 1) %>% 
  distinct()

site_id_count <- unique_facilityids %>% 
  group_by(facilityid) %>% 
  distinct(siteid) %>% 
  count()

facilityid_ALC <- left_join(unique_facilityids, three_digit_ALC, by = c('facilityid' = 'siteid')) %>% 
  filter(!is.na(pcode)) %>% 
  select(-pcodecount) %>% 
  # rename('facilityid' = 'siteid',
  #        'siteid' = 'siteid.y') %>%
  left_join(site_id_count, by=c('facilityid')) %>% 
  mutate(totalALCdays = (totalALCdays/n)) %>% 
  select(-n)

facilityid_ALC %>% filter(facilityid == 927, year ==1112) %>% summarise(n = sum(totalALCdays))

#Isolate all 4-digit ALC-Site IDs
four_digit_ALC <- ALCannualvolume %>% 
  filter(siteid > 999) %>% 
  select(-casetype,
          -bedtype)

siteid_ALC <-left_join(four_digit_ALC, hospital_id_master, by = c('siteid' = 'ALCsite_id')) %>% 
  filter(!is.na(pcode)) %>% 
  rename('ALCsite_id' = 'siteid',
         'siteid' = 'siteid.y')

ALCsite_id_count <- siteid_ALC %>% 
  group_by(ALCsite_id) %>% 
  summarise(duplicates = n_distinct(siteid))

siteid_ALC <- left_join(siteid_ALC, ALCsite_id_count, by = c('ALCsite_id')) %>%
  mutate(totalALCdays = (totalALCdays/duplicates)) %>% 
  select(-duplicates)

siteid_ALC %>%  filter(ALCsite_id == 4414, year == 1112) %>% summarise(sum(totalALCdays))

ALC_master <- rbind(siteid_ALC, facilityid_ALC)

#TEST
ALC_master %>% filter(ALCsite_id == 4142, year == 1112) %>% summarise(sum(totalALCdays))

```

```{r obsolete cont. 5}
ALCannualvolumeprep <- ALCannualvolume %>%
  select(year = Year,
         siteid = SiteNumber,
         casetype = CaseType,
         bedtype = InPatientBedType,
         agegroup = AgeGroup,
         dd = DischargeDestination,
         freq = Frequency,
         losmean = Mean,
         losmed = Median,
         los90thp = '90thP',
         totalALCdays = TotalALCDays) %>% 
  filter(casetype == 9, 
         agegroup != 9,
         agegroup != 7,
         bedtype == 'AP',
         dd != "ALL")
```


