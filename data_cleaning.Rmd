---
title: "MOI Data Clean-up"
Feb-Apr 2019
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(weights)
source("helpers.R")
```


# Import data
```{r import}
# TRESO data
hhld_df <- data.table::fread("input/households_2011.csv.gz")
pop_df <- data.table::fread("input/persons_2011.csv.gz")

# School Data
schoolCap <- read.csv("input/school_capacity.csv", stringsAsFactors = FALSE)
schoolForecast <- read.csv("input/school_forecast.csv", stringsAsFactors = FALSE)
SchoolAssets <- read.csv("input/school_assets.csv", stringsAsFactors = FALSE)
schoolAssetsPortables <- read.csv("input/school_assets_portables.csv", stringsAsFactors = FALSE)
studentPost <- read.csv('input/sch_enr_pcode.txt', sep = "|", stringsAsFactors = FALSE)

# postal code to lat/long conversion file
pccf <- read.csv('input/PCCF_ONT_2018.csv', stringsAsFactors = FALSE, fileEncoding = "UTF-8-BOM") 

# Office Data
#officeSpace <- sqlFetch(schoolRodbc, "cap.IOAnnualSpaceBaselineBuilding")
#officeSpace %>%
#  write.csv('P:/Y362/2019/191-00826-00 MOI Capacity and Demand Model/3. Modelling/OfficeSpaceData.csv', row.names = FALSE)

#officeSpaceAssets <- sqlFetch(schoolRodbc, "dbo.AssetInventoryIO")
#officeSpaceAssets %>%
#  write.csv('P:/Y362/2019/191-00826-00 MOI Capacity and Demand Model/3. Modelling/OfficeSpaceAssetData.csv', row.names = FALSE)

```

## TRESO Data cleaning 

- Combine the population, household information
- Summarize by TRESO zones

```{r treso data cleaning}
# Clean hhld_df
hhld_tb <- select(hhld_df, hhid, treso_zone, income) %>%
  as.tibble()

# Clean pop_df and join with hhld
socio_economic_tb <- select(pop_df, hhid, treso_zone, age, hdgree, nocs_11, work_status, school_status) %>%
  as.tibble() %>%
  left_join(hhld_tb, by = c("hhid" , "treso_zone")) %>%
  mutate(adult = ifelse(age >= 21, 1, 0)) %>%
  mutate(child = ifelse(age < 21, 1, 0))

hhld_structure <- socio_economic_tb %>%
  group_by(hhid) %>%
  summarise(
    hhld_adult = sum(adult),
    hhld_child = sum(child),
    treso_zone = unique(treso_zone)
  ) %>%
  mutate(n_zero_adult = ifelse(hhld_adult == 0, 1, 0)) %>%
  mutate(n_one_adult_zero_child = ifelse(hhld_adult == 1 & hhld_child == 0, 1, 0)) %>%
  mutate(n_one_adult_one_child = ifelse(hhld_adult == 1 & hhld_child == 1, 1, 0)) %>%
  mutate(n_one_adult_two_child = ifelse(hhld_adult == 1 & hhld_child == 2, 1, 0)) %>%
  mutate(n_one_adult_twoplus_child = ifelse(hhld_adult == 1 & hhld_child > 2, 1, 0)) %>%
  mutate(n_two_adult_zero_child = ifelse(hhld_adult == 2 & hhld_child == 0, 1, 0)) %>%
  mutate(n_two_adult_one_child = ifelse(hhld_adult == 2 & hhld_child == 1, 1, 0)) %>%
  mutate(n_two_adult_two_child = ifelse(hhld_adult == 2 & hhld_child == 2, 1, 0)) %>%
  mutate(n_two_adult_twoplus_child = ifelse(hhld_adult == 2 & hhld_child > 2, 1, 0)) %>%
  mutate(n_twoplus_adult_zero_child = ifelse(hhld_adult > 2 & hhld_child == 0, 1, 0)) %>%
  mutate(n_twoplus_adult_one_child = ifelse(hhld_adult > 2 & hhld_child == 1, 1, 0)) %>%
  mutate(n_twoplus_adult_two_child = ifelse(hhld_adult > 2 & hhld_child == 2, 1, 0)) %>%
  mutate(n_twoplus_adult_twoplus_child = ifelse(hhld_adult > 2 & hhld_child > 2, 1, 0)) %>%
  # Group into treso ID
  select(treso_zone, n_zero_adult:n_twoplus_adult_twoplus_child) %>%
  group_by(treso_zone) %>%
  summarise_all(
    funs(sum)
  )

# Summarize into TRESO Zones
treso_tb <- socio_economic_tb %>%
  group_by(treso_zone) %>%
  summarise(
    n_pop = n(),
    n_hhlds = length(unique(hhid)),
    n_ft = length(treso_zone[work_status == "full_time"]),
    n_pt = length(treso_zone[work_status == "part_time"]),
    n_unemp = length(treso_zone[work_status == "unemployed"]),
    n_sec_pop = length(treso_zone[age <= 18 & age >= 13]),
    n_ele_pop = length(treso_zone[age <= 12 & age >= 3]),
    n_pre_pop = length(treso_zone[age <= 2]),
    
    mean_income = mean(income, na.rm = TRUE),
    mean_age = mean(age, na.rm = TRUE),
    
    occu_management = length(treso_zone[nocs_11 == 1]),
    occu_business = length(treso_zone[nocs_11 == 2]),
    occu_science = length(treso_zone[nocs_11 == 3]),
    occu_health = length(treso_zone[nocs_11 == 4]),
    occu_public = length(treso_zone[nocs_11 == 5]),
    occu_recreation = length(treso_zone[nocs_11 == 6]),
    occu_sales = length(treso_zone[nocs_11 == 7]),
    occu_trades = length(treso_zone[nocs_11 == 8]),
    occu_production = length(treso_zone[nocs_11 == 9]),
    occu_manufacturing = length(treso_zone[nocs_11 == 10]),
    occu_notapplicable = length(treso_zone[nocs_11 == 99]),
    attend_school = length(treso_zone[school_status == 2]),
    deg_none = length(treso_zone[hdgree == 1]),
    deg_hs = length(treso_zone[hdgree == 2]),
    deg_trades = length(treso_zone[hdgree == 3]),
    deg_ra = length(treso_zone[hdgree == 4]),
    deg_col = length(treso_zone[hdgree == 5]),
    deg_uni = length(treso_zone[hdgree == 6]),
    deg_ugrad = length(treso_zone[hdgree == 7]),
    deg_grad = length(treso_zone[hdgree == 8]),
    deg_na = length(treso_zone[hdgree == 88 | hdgree == 99])
  ) %>%
  left_join(hhld_structure, by = "treso_zone") %>%
  saveRDS("output/treso_tb.rds")

# Clean global variables
rm(hhld_tb, socio_economic_tb, hhld_structure)
```


## Education Data cleaning
 
- clean the school forecast data.
- Then, clean school capacity and historical demand data
- Combine together 

- Clean the student postal code data

```{r education cleaning}
# The school capacity dataset contains the correct lat/long for schools
schoolCapSlim <- schoolCap %>%
  select(year = Sch_yr, 
         dsb.index = DSB_Index, 
         board.name = BoardName, 
         panel = Panel, 
         sfis = `SFIS_ID`,
         school.name = `FacilityName`, 
         ade = ADE,
         otg = OTG, 
         school.lat = `Latitude`, 
         school.long = `longitude`, 
         status = Status, 
         dataset.id = dataSetID) %>%
  mutate(utilization = ifelse(otg != 0, ade / otg, 0)) %>%
  filter(year == 2017, status == "Open", dataset.id == 2, !is.na(school.lat), !is.na(school.long)) %>%
  group_by(sfis) %>%
  summarise(
    year = first(year),
    dsb.index = first(dsb.index),
    board.name = first(board.name), 
    panel = first(panel), 
    school.name = first(school.name), 
    ade = mean(ade),
    otg = mean(otg), 
    utilization = mean(utilization),
    school.lat = first(school.lat), 
    school.long = first(school.long), 
    status = first(status), 
    dataset.id = first(dataset.id)
  )

saveRDS(schoolCapSlim, file = 'output/school_capacity_2017.rds')

# The school forecast dataset contains BSID which is needed to merge student postal code
# From inspection, there are same amount of school in each forecast year.
schoolForecastSlim <- schoolForecast %>%
  select(year = SCH_YR, 
         sfis = SFIS,
         bsid = BSID,
         dsb.index = DSBINDEX,
         school.name = School.Name, 
         ade.forecast = ADE,
         ade.sec.forecast = ADE_SEC,
         ade.elem.forecast = ADE_ELEM,
         ade.jksk.forecast = ADE_JKSK,
         ade.g1g3.forecast = ADE_G1G3, 
         ade.g4g8.forecast = ADE_G4G8) %>%
  filter(year == 2017, bsid != 0)

# Combine the School capacity data with the forecast data on SFIS

schoolSFIS <- left_join(schoolCapSlim, schoolForecastSlim, by = c('sfis')) %>%
  select(-school.name.y, -dsb.index.y) %>%
  rename(school.name = school.name.x, dsb.index = dsb.index.x) %>%
  arrange(sfis)

# Drop any school that does not have a corresponding forecast
unmatched_schools <- sum(is.na(schoolSFIS$bsid))                       
print(paste0('A total of ', unmatched_schools, ' schools are unmatched between capacity and forecast'))
schoolSFIS <- schoolSFIS %>%
  drop_na(bsid)

# The postal code and enrollment dataset is cleaned here
# We are looking at 2011 data
studentPostSlim <- studentPost %>%
  select(year = Sch_YR,
         bsid = BSID, 
         dsb.index = dsbindex,
         school.name = School.Name, 
         student.postal.code = Student.Postal.Code,
         enrolment = Enrolment) %>%
  filter(year == 2011) %>%
  filter(str_length(student.postal.code) == 6) %>%
  mutate(enrolment = as.integer(enrolment))

num_schools_from_student_post <- length(unique(studentPostSlim$bsid))
num_schools_from_school_sfis <- length(unique(schoolSFIS$bsid))
print(paste0('A total of ', num_schools_from_student_post, ' unique schools are contained in student postal code dataset'))
print(paste0('A total of ', num_schools_from_school_sfis, ' unique schools are contained in the school dataset'))

# Clean global variables
rm(num_schools_from_student_post, num_schools_from_school_sfis)
```


## Calculate School Catchment Areas

- First, join the school and student's together into one table based on `bsid`
- Then, join the postal code centroids with lat/long information to each student based on `postal.code`
- Filter the unmatched records from the table

- Calculate the straight line travel distance between student to school based on lat/long information and `haverFunction()`
- Validate the distances are reasonable for each school, establish a threshold to remove extremely long travel distances

- *TODO* Filter out Adult Con ED schools, check with name
- *TODO* High level finding of proportion of students going to nearest school by board, region. Summary of 2017 school utilization.
- *TODO* Utilization vs travel time

```{r, fig.width=20}
# Join postal code centroids to student's postal code data
pccfSlim <- pccf %>%
  filter(SLI == 1) %>%
  select(postal.code = PostalCode,
         lat = LAT,
         long = LONG,
         retirement.date = Ret_Date) %>%
  group_by(postal.code) %>%
  filter(retirement.date == max(retirement.date))

# Create a list of postal codes with SLI == 1 but different lat/long
pccfSlim[duplicated(pccfSlim$postal.code) | duplicated(pccfSlim$postal.code, fromLast = TRUE), ] %>%
  arrange(postal.code) %>%
  group_by(postal.code, lat, long, retirement.date) %>%
  summarise(n = n()) %>%
  filter(n == 1)

schoolCatchment <- schoolSFIS %>%
  select(sfis, bsid, school.name, school.lat, school.long, dsb.index, panel) %>%
  left_join(select(studentPostSlim, bsid, student.postal.code, enrolment), by = c('bsid' = 'bsid'))

unmatched_schools <- schoolCatchment %>%
  filter(is.na(enrolment)) %>%
  group_by(sfis) %>%
  summarise(school.name = first(school.name), unmatched.enrollment = n())
num_unmatched_schools <- length(unique(unmatched_schools$sfis))
print(paste0('There are ', num_unmatched_schools, ' unmatched schools'))

schoolCatchment <- schoolCatchment %>%
  drop_na(enrolment) %>%
  left_join(select(pccfSlim, student.lat = lat, student.long = long, postal.code), by = c('student.postal.code' = 'postal.code'))

temp_tb <- filter(schoolCatchment, is.na(student.lat))
num_unmatched_students <- length(unique(temp_tb$student.postal.code))
print(paste0('There are ', num_unmatched_students, ' unique postal codes that were not match between postal code and lat/long'))

schoolCatchment <- schoolCatchment %>%
  drop_na(student.lat, student.long)

# Calculate straight-line home-to-school distances
schoolCatchment <- schoolCatchment %>%
  mutate(dist = haverFunction(school.lat, school.long, student.lat, student.long))

# Plot boxplots of travel distances to find any huge outliers
temp_dist <- schoolCatchment %>%
  filter(panel == 'Secondary', dsb.index == 14)

ggplot(temp_dist, aes(x = school.name, y = dist)) +
  geom_boxplot(outlier.colour = 'red')

temp <- schoolCatchment %>%
  filter(panel == 'Secondary', dsb.index == 14)

summary(temp$dist)

# TODO: create a threshold for the outliers, maybe one for secondary one for elementary?

# Calculate the catchment distance by a specified quantile weighted with the enrolment of the school
percentileList <- c(0.9, 0.8, 0.7, 0.6, 0.5)
schoolCatchmentDistPercent <- schoolCatchment %>%
  group_by(sfis, school.name, school.lat, school.long) %>%
  # use a weighted quantile function to select the distance by enrolment
  summarise(
    panel = first(panel),
    list(
      enframe(
        wtd.quantile(dist, probs = percentileList, na.rm = FALSE, weight = enrolment)
        )
      )
    ) %>%
  unnest %>%
  ungroup() %>%
  rename(perc.value = name, perc.dist = value) %>%
  mutate(perc.value = as.numeric(sub("%", "", perc.value))/100)

schoolCatchmentDistPercent %>%
  group_by(perc.value, panel) %>%
  summarise(average.distance = mean(perc.dist)) %>%
  ggplot(aes(x = perc.value, y = average.distance, fill = panel)) +
  geom_bar(stat = 'identity', position = 'dodge') +
  labs(x = "Quantile", y = "Distance (KM)", title = "Average Catchment Distance of Schools") +
  theme_minimal()

# Select students within the catchment distance and export it
for (catchment_dist in percentileList){
  schoolCatchment %>%
    left_join(select(schoolCatchmentDistPercent, sfis, perc.dist, perc.value), by = c('sfis' = 'sfis')) %>%
    filter(perc.value == catchment_dist) %>%
    filter(dist <= perc.dist) %>%
    saveRDS(file = paste0('output/student_travel_', as.character(catchment_dist), '.rds'))
}

rm(schoolCatchment, schoolCatchmentDistPercent, percentileList, temp_tb)
```

### Quick Check of ADE vs Enrollment
```{r quick check, fig.height = 50, fig.width = 10}
# Check the enrollment total vs ADE numbers
temp1 <- schoolSFIS %>%
  select(bsid, school.name, ade, ade.forecast) %>%
  arrange(school.name)
  
temp2 <- studentPostSlim %>%
  group_by(bsid) %>%
  summarise(
    enrolment = sum(enrolment),
    school.name = first(school.name)
  ) %>%
  arrange(school.name)

temp <- left_join(temp1, temp2, by = "bsid") %>%
  drop_na(enrolment) %>%
  gather(key = 'key', value = 'value', ade, enrolment) %>%
  select(-school.name.y) %>%
  arrange(school.name.x) %>%
  mutate(facet_index = factor(row_number() %/% 100))

ggplot(data = temp, aes(fill = key, x = school.name.x, y = value)) +
  geom_bar(stat = "identity", position = 'dodge') +
  facet_wrap(~facet_index, ncol = 5, scales = 'free_x')
```


## Visualization of percentile travel distance

```{r}
student_travel <- readRDS(file = 'output/student_travel_0.6.rds') %>%
  as.tibble() %>%
  group_by(sfis) %>%
  summarise(distance = first(perc.dist),
            school.name = first(school.name),
            school.lat = first(school.lat),
            school.long = first(school.long))

ggplot(data = student_travel, aes(distance)) +
  geom_freqpoly(stat = "bin", binwidth = 5, size = 1)

```

## Clean and Simplify Portables Data
```{r}
#Select most recent Portable Data year for each school
#schoolPortableYears <- schoolAssetsPortables %>%
  #filter(DataSetID == 2, sch_yr = 2017) %>%
  #select(SFIS_ID, Sch_yr) %>%
  #group_by(SFIS_ID) %>%
  #summarise(Sch_yr_max = max(Sch_yr))

#Join most recent portable data to School Asset data, and sum total Ground Floor Area and Number of Portable Units by school
filtList <- c('cafe|child care|administration|other|commercial|general|best start|staff')

schoolAssetsPortablesSlim <- schoolAssetsPortables %>%
  filter(DataSetID == 2, Sch_yr == 2017) %>%
  #filter out non-classroom room types
  filter(!grepl(filtList, CurrentUse, ignore.case = TRUE)) %>%
  #inner_join(schoolPortableYears, by = c('SFIS_ID' = 'SFIS_ID', 'Sch_yr' = 'Sch_yr_max')) %>%
  select(Sch_yr, Dsb_index, SFIS_ID, FacilityName, GFA_m2, NumberOfUnits) %>%
  group_by(Sch_yr, Dsb_index, SFIS_ID, FacilityName) %>%
  summarise(sum(GFA_m2), sum(NumberOfUnits))

```

Join Portables Data to School Cap/ADE Data
```{r}
#BID is unique field in AssetInventoryEDU when using only DataSetID = 2 and BID is not null
schoolCapSlim %>%
  left_join(schoolAssetsPortablesSlim, by = c('SFIS_ID' = 'SFIS_ID')) %>%
  arrange(SFIS_ID)
  #write.csv(.,file = "P:/Y362/2019/191-00826-00 MOI Capacity and Demand Model/3. Modelling/schoolCapPortables.csv")
```

Plot School Data
```{r}
options(scipen=999) # turn off scientific notation like 1e+06
g <- ggplot(schoolCapSlim, aes(x=SFIS_ID, y=utilization)) +
  geom_bar(stat="identity") +
  ggtitle("School Utilization") + 
  theme_grey() +
  ylim(c(0, 10))
#max(SchoolCapSlim$utilization)))

g
```


```{r}
SchoolAssets %>%
  filter(DataSetId == 2)
  #filter(!is.na(BID)) %>%

#schoolAssetsLatLong %>%
  #select(`BUILDING ID`, X_COORD, Y_COORD) %>%
  #drop_na(`BUILDING ID`) %>%
  #mutate(X_COORD_round = round(X_COORD, 3), Y_COORD_round = round(Y_COORD, 3)) %>%
  #distinct(`BUILDING ID`, X_COORD_round, Y_COORD_round) %>%
  #Several BUILDING IDs are being repeated because coordinates are recorded differently for duplicate copies of the Building ID; this happens at all scales of precision; must choose acceptable level of precision and then choose mechanism for selecting "correct" lat/long
  #summarise(n())
schoolCap
```


*Push Health Data into SQL Server
```{r}
#Loading Health Bed Census Summary data into SQL Server
#healthBedsSummary <- read.csv('P:/Y362/2019/191-00826-00 MOI Capacity and Demand Model/3. Modelling/Received files/Data received 2019-03-01/MOH_DailyBedCensus_Summary.txt')
#sqlSave(healthRodbc,healthBedsSummary,"cap.MOH_DailyBedCensus_Summary",safer=FALSE, fast=TRUE)
```



*Import Health Data
```{r}
healthRodbc <-odbcConnect("SQLDNS")

healthDailyBedHistory <- sqlFetch(healthRodbc, "cap.MOH_DailyBedCensus_Historical")
healthDailyBedCensus <- sqlFetch(healthRodbc, "cap.MOH_DailyBedCensus_Summary")
healthDischarges <- sqlFetch(healthRodbc, "cap.MOH_Discharges")

healthHBAMhistorical <- sqlFetch(healthRodbc, "cap.MOH_HBAM_HIS")
healthHBAMprojected <- sqlFetch(healthRodbc, "cap.MOH_HBAM_Proj")

healthLHINfacilityList <- sqlFetch(healthRodbc, "cap.MOH_LHIN_Hosp_Fac_List")
healthHospitalLocations <- sqlFetch(healthRodbc, "dbo.MOH_Hospital_Locations")

healthPopulationLHIN <- sqlFetch(healthRodbc, "dbo.Population_LHIN")
healthBedDays <- sqlFetch(healthRodbc, "cap.MOH_Pat_Bed_Days")

healthWaitTime <- sqlFetch(healthRodbc, "cap.HospitalWaitTime")

#ALC Data
healthALCAge <- sqlFetch(healthRodbc, "cap.ALCAge")
healthALCAnnualVolume <- sqlFetch(healthRodbc, "cap.ALCAnnualVolumeAndTotalDays")
healthALCCases <- sqlFetch(healthRodbc, "cap.ALCCases")
healthALCDesignations <- sqlFetch(healthRodbc, "cap.ALCDesignations")
healthALCDischarge <- sqlFetch(healthRodbc, "cap.ALCDischargeDestination")
healthALCInpatientBedType <- sqlFetch(healthRodbc, "cap.ALCInpatientBedType")
healthALCMonthlyRatebySite <- sqlFetch(healthRodbc, "cap.ALCMonthlyRateByProvinceLHINFacilitySite")
healthALCMonthlyVolume <- sqlFetch(healthRodbc, "cap.ALCMonthlyVolumeAndTotalDays")

#CIHI Data
healthCIHIFacilityNameID <- sqlFetch(healthRodbc, "cap.CIHI_FacilityName_FacilityID")
healthCIHIFacilityNumberOld <- sqlFetch(healthRodbc, "cap.CIHI_FacilityNumber_OLD")
healthCIHIHospitalBeds <- sqlFetch(healthRodbc, "cap.CIHI_Hospital_Beds")
healthCIHIWaitTimesRegion <- sqlFetch(healthRodbc, "cap.CIHI_Wait Times by Region")
healthCIHIWaitTimesProvince <- sqlFetch(healthRodbc, "cap.CIHI_Wait_Time_Data_by_Province")

#Health Asset Inventory
healthInventoryMOHLTC <- sqlFetch(healthRodbc, "dbo.AssetInventoryMOHLTC")
healthInventoryMOHLTCfid <- sqlFetch(healthRodbc, "dbo.AssetInventoryMOHLTC_FID_Map")

#Lookup Tables
healthHospitalSiteLookup <- sqlFetch(healthRodbc, "xRef.HC_HospitalSite_Lookup")
healthLHINLookup <- sqlFetch(healthRodbc, "xRef.HC_LHIN_Lookup")

healthPopulationLHIN %>%
  filter(LHIN=='South West') %>%
  arrange(Year, Gender, Age)

healthHBAMprojected %>%
  distinct(Care_Type)

```

*Import MAG Data
```{r}

```




