---
title: "MOI Data Clean-up"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(weights)
source("helpers.R")
```


# Import data
```{r import, include=FALSE}
# TRESO data
hhld_df <- data.table::fread("input/households_2011.csv.gz")
pop_df <- data.table::fread("input/persons_2011.csv.gz")

# School Data
schoolCap <- read.csv("input/school_capacity.csv", stringsAsFactors = FALSE)
schoolForecast <- read.csv("input/school_forecast.csv", stringsAsFactors = FALSE)
schoolAssets <- read.csv("input/school_assets.csv", stringsAsFactors = FALSE)
schoolAssetsPortables <- read.csv("input/school_assets_portables.csv", stringsAsFactors = FALSE)
studentPost <- read.csv('input/sch_enr_pcode.txt', sep = "|", stringsAsFactors = FALSE)
eqao <- read.csv('input/eqao_2017_2018.csv', stringsAsFactors = FALSE, fileEncoding = "UTF-8-BOM")

# Postal code to lat/long conversion file
pccf <- read.csv('input/PCCF_ONT_2018.csv', stringsAsFactors = FALSE, fileEncoding = "UTF-8-BOM") 
```

# TRESO Data cleaning 

- Combine the population, household information
- Summarize by TRESO zones

```{r treso data cleaning, echo=FALSE}
# Clean hhld_df
hhld_tb <- select(hhld_df, hhid, treso_zone, income) %>%
  as_tibble()

# Clean pop_df and join with hhld
socio_economic_tb <- select(pop_df, hhid, treso_zone, age, hdgree, nocs_11, work_status, school_status) %>%
  as_tibble() %>%
  left_join(hhld_tb, by = c("hhid" , "treso_zone")) %>%
  mutate(adult = ifelse(age >= 21, 1, 0)) %>%
  mutate(child = ifelse(age < 21, 1, 0))

hhld_structure <- socio_economic_tb %>%
  group_by(hhid) %>%
  summarise(
    hhld_adult = sum(adult),
    hhld_child = sum(child),
    treso_zone = unique(treso_zone)
  ) %>%
  mutate(n_zero_adult = ifelse(hhld_adult == 0, 1, 0)) %>%
  mutate(n_one_adult_zero_child = ifelse(hhld_adult == 1 & hhld_child == 0, 1, 0)) %>%
  mutate(n_one_adult_one_child = ifelse(hhld_adult == 1 & hhld_child == 1, 1, 0)) %>%
  mutate(n_one_adult_two_child = ifelse(hhld_adult == 1 & hhld_child == 2, 1, 0)) %>%
  mutate(n_one_adult_twoplus_child = ifelse(hhld_adult == 1 & hhld_child > 2, 1, 0)) %>%
  mutate(n_two_adult_zero_child = ifelse(hhld_adult == 2 & hhld_child == 0, 1, 0)) %>%
  mutate(n_two_adult_one_child = ifelse(hhld_adult == 2 & hhld_child == 1, 1, 0)) %>%
  mutate(n_two_adult_two_child = ifelse(hhld_adult == 2 & hhld_child == 2, 1, 0)) %>%
  mutate(n_two_adult_twoplus_child = ifelse(hhld_adult == 2 & hhld_child > 2, 1, 0)) %>%
  mutate(n_twoplus_adult_zero_child = ifelse(hhld_adult > 2 & hhld_child == 0, 1, 0)) %>%
  mutate(n_twoplus_adult_one_child = ifelse(hhld_adult > 2 & hhld_child == 1, 1, 0)) %>%
  mutate(n_twoplus_adult_two_child = ifelse(hhld_adult > 2 & hhld_child == 2, 1, 0)) %>%
  mutate(n_twoplus_adult_twoplus_child = ifelse(hhld_adult > 2 & hhld_child > 2, 1, 0)) %>%
  # Group into treso ID
  select(treso_zone, n_zero_adult:n_twoplus_adult_twoplus_child) %>%
  group_by(treso_zone) %>%
  summarise_all(
    funs(sum)
  )

# Summarize into TRESO Zones
treso_tb <- socio_economic_tb %>%
  group_by(treso_zone) %>%
  summarise(
    n_pop = n(),
    n_hhlds = length(unique(hhid)),
    n_ft = length(treso_zone[work_status == "full_time"]),
    n_pt = length(treso_zone[work_status == "part_time"]),
    n_unemp = length(treso_zone[work_status == "unemployed"]),
    n_sec_pop = length(treso_zone[age <= 18 & age >= 13]),
    n_ele_pop = length(treso_zone[age <= 12 & age >= 3]),
    n_pre_pop = length(treso_zone[age <= 2]),
    
    mean_income = mean(income, na.rm = TRUE),
    mean_age = mean(age, na.rm = TRUE),
    
    occu_management = length(treso_zone[nocs_11 == 1]),
    occu_business = length(treso_zone[nocs_11 == 2]),
    occu_science = length(treso_zone[nocs_11 == 3]),
    occu_health = length(treso_zone[nocs_11 == 4]),
    occu_public = length(treso_zone[nocs_11 == 5]),
    occu_recreation = length(treso_zone[nocs_11 == 6]),
    occu_sales = length(treso_zone[nocs_11 == 7]),
    occu_trades = length(treso_zone[nocs_11 == 8]),
    occu_production = length(treso_zone[nocs_11 == 9]),
    occu_manufacturing = length(treso_zone[nocs_11 == 10]),
    occu_notapplicable = length(treso_zone[nocs_11 == 99]),
    attend_school = length(treso_zone[school_status == 2]),
    deg_none = length(treso_zone[hdgree == 1]),
    deg_hs = length(treso_zone[hdgree == 2]),
    deg_trades = length(treso_zone[hdgree == 3]),
    deg_ra = length(treso_zone[hdgree == 4]),
    deg_col = length(treso_zone[hdgree == 5]),
    deg_uni = length(treso_zone[hdgree == 6]),
    deg_ugrad = length(treso_zone[hdgree == 7]),
    deg_grad = length(treso_zone[hdgree == 8]),
    deg_na = length(treso_zone[hdgree == 88 | hdgree == 99])
  ) %>%
  left_join(hhld_structure, by = "treso_zone") %>%
  saveRDS("cache/treso_tb.rds")

# Clean global variables
rm(hhld_tb, socio_economic_tb, hhld_structure)
```


# Education Data cleaning
 
- clean the school forecast data.
- Then, clean school capacity and historical demand data
- Combine together 
- Clean the student postal code data

```{r education data cleaning, echo=FALSE}
# The school capacity dataset contains the correct lat/long for schools
schoolCapSlim <- schoolCap %>%
  select(year = Sch_yr, 
         dsb.index = DSB_Index, 
         board.name = BoardName, 
         panel = Panel, 
         sfis = `SFIS_ID`,
         school.name = `FacilityName`, 
         ade = ADE,
         otg = OTG, 
         school.lat = `Latitude`, 
         school.long = `longitude`, 
         status = Status, 
         dataset.id = dataSetID) %>%
  mutate(utilization = ifelse(otg != 0, ade / otg, 0)) %>%
  filter(year == 2017, status == "Open", dataset.id == 2, !is.na(school.lat), !is.na(school.long)) %>%
  # Remove schools with capacity of 0
  filter(otg != 0, ade != 0) %>%
  # Remove schools with ADE that is less than 50
  filter(ade >= 50)

# The school forecast dataset contains BSID which is needed to merge student postal code
# From inspection, there are same amount of school in each forecast year.
schoolForecastSlim <- schoolForecast %>%
  select(year = SCH_YR, 
         sfis = SFIS,
         bsid = BSID,
         dsb.index = DSBINDEX,
         school.name = School.Name, 
         ade.forecast = ADE,
         ade.sec.forecast = ADE_SEC,
         ade.elem.forecast = ADE_ELEM,
         ade.jksk.forecast = ADE_JKSK,
         ade.g1g3.forecast = ADE_G1G3, 
         ade.g4g8.forecast = ADE_G4G8) %>%
  filter(year == 2017, bsid != 0)

# Combine the School capacity data with the forecast data on SFIS
schoolSFIS <- left_join(schoolCapSlim, schoolForecastSlim, by = c('sfis')) %>%
  select(-school.name.y, -dsb.index.y) %>%
  rename(school.name = school.name.x, dsb.index = dsb.index.x) %>%
  arrange(sfis)

# Drop any school that does not have a corresponding forecast
unmatched_schools <- sum(is.na(schoolSFIS$bsid))                       
print(paste0('A total of ', unmatched_schools, ' schools are unmatched between capacity and forecast'))
schoolSFIS <- schoolSFIS %>%
  drop_na(bsid)

# The postal code and enrollment dataset is cleaned here
# We are looking at 2017 student data at this time.
studentPostSlim <- studentPost %>%
  select(year = Sch_YR,
         bsid = BSID, 
         dsb.index = dsbindex,
         school.name = School.Name, 
         student.postal.code = Student.Postal.Code,
         enrolment = Enrolment) %>%
  filter(year == 2017) %>%
  filter(str_length(student.postal.code) == 6) %>%
  mutate(enrolment = as.integer(enrolment))

num_schools_from_student_post <- length(unique(studentPostSlim$bsid))
num_schools_from_school_sfis <- length(unique(schoolSFIS$bsid))
print(paste0('A total of ', num_schools_from_student_post, ' unique schools are contained in student postal code dataset'))
print(paste0('A total of ', num_schools_from_school_sfis, ' unique schools are contained in the school dataset'))

# Clean global variables
rm(num_schools_from_student_post, num_schools_from_school_sfis)
```

## Calculate School Catchment Lengths

- First, join the school and student's together into one table based on `bsid`
- Then, join the postal code centroids with lat/long information to each student based on `postal.code`
- Filter the unmatched records from the table
- Find any schools with a ratio of ADE to enrolment below 0.8 and above 1.0 between the school and student data, remove these outliers
- Calculate the straight line travel distance between student to school based on lat/long information and `haverFunction()`

```{r join edu data, echo=FALSE}
# Join postal code centroids to student's postal code data
pccfSlim <- pccf %>%
  filter(SLI == 1) %>%
  select(postal.code = PostalCode,
         lat = LAT,
         long = LONG,
         retirement.date = Ret_Date) %>%
  group_by(postal.code) %>%
  filter(retirement.date == max(retirement.date))

# Create a list of postal codes with SLI == 1 but different lat/long
pccfSlim[duplicated(pccfSlim$postal.code) | duplicated(pccfSlim$postal.code, fromLast = TRUE), ] %>%
  arrange(postal.code) %>%
  group_by(postal.code, lat, long, retirement.date) %>%
  summarise(n = n()) %>%
  filter(n == 1)

# Combine school, student and postal data together
schoolCatchment <- schoolSFIS %>%
  select(sfis, bsid, school.name, school.lat, school.long, dsb.index, panel, ade) %>%
  left_join(select(studentPostSlim, bsid, student.postal.code, enrolment), by = c('bsid' = 'bsid'))

unmatched_schools <- schoolCatchment %>%
  filter(is.na(enrolment)) %>%
  group_by(sfis) %>%
  summarise(school.name = first(school.name), unmatched.enrollment = n())

unmatched_school_pct <- round(length(unique(unmatched_schools$sfis)) / length(unique(schoolSFIS$sfis)) * 100, 2)
print(paste0(unmatched_school_pct, '% of shcools are unmatched, and ', sum(unmatched_schools$unmatched.enrollment),
             ' students are unmatched after combining with student postal code'))

schoolCatchment <- schoolCatchment %>%
  drop_na(enrolment) %>%
  left_join(select(pccfSlim, student.lat = lat, student.long = long, postal.code), by = c('student.postal.code' = 'postal.code'))

unmatched_students <- round((length(unique(filter(schoolCatchment, is.na(student.lat))$student.postal.code)) / 
                             length(unique(filter(schoolCatchment, !is.na(student.lat))$student.postal.code))) * 100, 2)
print(paste0(unmatched_students, '% of students did not have a match between postal code and lat/long'))

schoolCatchment <- schoolCatchment %>%
  drop_na(student.lat, student.long)

# Check very low or very high Enrolment/ADE ratios and remove these
temp1 <- schoolSFIS %>%
  select(bsid, school.name, ade)
  
temp2 <- studentPostSlim %>%
  group_by(bsid) %>%
  summarise(
    enrolment = sum(enrolment)
  )

temp_tb <- left_join(temp1, temp2, by = 'bsid') %>%
  mutate(ratio = ade / enrolment) %>%
  arrange(ratio) %>%
  filter(ratio <= 0.8 | ratio >= 1.02)

num_outlier_matched <- round(length(temp_tb$bsid) / length(schoolSFIS$bsid) * 100, 2)
print(paste0(num_outlier_matched, '% of all schools is flagged due to a large mismatch between ADE and enrolment'))

schoolCatchment <- anti_join(schoolCatchment, temp_tb, by = 'bsid')

# Calculate straight-line home-to-school distances
schoolCatchment <- schoolCatchment %>%
  mutate(dist = haverFunction(school.lat, school.long, student.lat, student.long))
```

## Remove outlier students

The data provided contains students travelling extremely far distances. This can be a source of error when calculating
the catchment areas for schools. For each school, the students outside of the whiskers of a typical boxplot are removed. 

- The end of whiskers is defined as [Q_1 - 1.5*IQR, Q_3 + 1.5IQR], and IQR is the difference between Q_3 and Q_1. 

```{r distance threshold filtering, fig.width=15}

schoolCatchmentThreshold <- schoolCatchment %>%
  uncount(enrolment) %>%
  group_by(school.name, school.lat, school.long) %>%
  summarise(
    lower_adj = boxplot.stats(dist)$stats[1],
    upper_adj = boxplot.stats(dist)$stats[5]
  )

schoolCatchment <- left_join(schoolCatchment, schoolCatchmentThreshold, by = c('school.name', 'school.lat', 'school.long')) %>%
  mutate(keep = as.factor(ifelse(dist <= upper_adj & dist >= lower_adj, 1, 0)))

# Plot stacked barplots of students within vs outside of threshold
schoolCatchment %>%
  uncount(enrolment) %>%
  ggplot(aes(x = panel, fill = keep)) +
  geom_bar() +
  facet_wrap(vars(dsb.index), scales = 'free_y')  +
  theme_minimal() + 
  labs(x = '', y = 'Enrolment', title = 'Threshold Analysis by DSB') +
  scale_fill_discrete(name = '', labels = c('Dropped', 'Kept')) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

num_outlier_students <- sum(filter(schoolCatchment, keep == '0')$enrolment)
num_within_students <- sum(filter(schoolCatchment, keep == '1')$enrolment)
print(paste0('Dropped ', num_outlier_students, ' students because they fall outside of acceptable threshold range.'))
print(paste0('Kept ', num_within_students, ' students because they fall inside of acceptable threshold range.'))

schoolCatchment <- schoolCatchment %>%
  filter(keep == '1')

# schoolCatchment %>%
#   filter(panel == 'Secondary', dsb.index == 14) %>%
#   uncount(enrolment) %>%
#   ggplot(aes(x = school.name, y = dist)) +
#   geom_boxplot(outlier.color = 'red')

```

``` {r students within catchment, echo=FALSE}
# Calculate the catchment distance by a specified quantile weighted with the enrolment of the school
percentileList <- c(0.9, 0.8, 0.7, 0.6, 0.5)
schoolCatchmentDistPercent <- schoolCatchment %>%
  group_by(sfis, school.name, school.lat, school.long) %>%
  # use a weighted quantile function to select the distance by enrolment
  summarise(
    panel = first(panel),
    list(
      enframe(
        wtd.quantile(dist, probs = percentileList, na.rm = FALSE, weight = enrolment)
        )
      )
    ) %>%
  unnest %>%
  ungroup() %>%
  rename(perc.value = name, perc.dist = value) %>%
  mutate(perc.value = as.numeric(sub("%", "", perc.value))/100)

schoolCatchmentDistPercent %>%
  group_by(perc.value, panel) %>%
  summarise(average.distance = mean(perc.dist)) %>%
  ggplot(aes(x = perc.value, y = average.distance, fill = panel)) +
  geom_bar(stat = 'identity', position = 'dodge') +
  labs(x = "Quantile", y = "Distance (KM)", title = "Average Catchment Distance of Schools") +
  theme_minimal()

# Select students within the catchment distance and export it
for (catchment_dist in percentileList){
  schoolCatchment %>%
    left_join(select(schoolCatchmentDistPercent, sfis, perc.dist, perc.value), by = c('sfis' = 'sfis')) %>%
    filter(perc.value == catchment_dist) %>%
    filter(dist <= perc.dist) %>%
    saveRDS(file = paste0('cache/student_travel_', as.character(catchment_dist), '.rds'))
}

rm(schoolCatchment, schoolCatchmentDistPercent, schoolCatchmentThreshold, percentileList, temp_tb)
```

### Quick Check of ADE vs Enrollment

```{r quick check, fig.height = 50, fig.width = 10}
# Check the enrollment total vs ADE numbers
temp1 <- schoolSFIS %>%
  select(bsid, school.name, ade, ade.forecast) %>%
  arrange(school.name)
  
temp2 <- studentPostSlim %>%
  group_by(bsid) %>%
  summarise(
    enrolment = sum(enrolment),
    school.name = first(school.name)
  ) %>%
  arrange(school.name)

temp <- left_join(temp1, temp2, by = "bsid") %>%
  drop_na(enrolment) %>%
  gather(key = 'key', value = 'value', ade, enrolment) %>%
  select(-school.name.y) %>%
  arrange(school.name.x) %>%
  mutate(facet_index = factor(row_number() %/% 100))

ggplot(data = temp, aes(fill = key, x = school.name.x, y = value)) +
  geom_bar(stat = "identity", position = 'dodge') +
  facet_wrap(~facet_index, ncol = 5, scales = 'free_x') +
  labs(x = '')

rm(temp1, temp2, temp)
```


### Visualization of percentile travel distance

```{r visualize travel distance}
student_travel <- readRDS(file = 'cache/student_travel_0.9.rds') %>%
  as_tibble() %>%
  group_by(sfis, school.name, school.lat, school.long) %>%
  summarise(distance = first(perc.dist))

ggplot(data = student_travel, aes(distance)) +
  geom_freqpoly(stat = "bin", binwidth = 5, size = 1) +
  labs(x = "Distance (KM)", y = "Count", title = "") +
  theme_minimal()

```

## Clean and Simplify Portables Data

- Assume that portable units are rounded at 0.75. So a protable with 1.8 units is rounded 2 units and a portable with
1.7 units is rounded to 1 unit
- Assume that 23 elementary or 21 secondary students per unit of portable
- Update the utilization of each school after adding in the portables

```{r clean portables, echo=FALSE}
# Sum total ground floor area and number of portable units by school
filterList <- c('cafe|child care|administration|other|commercial|general|best start|staff')

ELE_STUDENTS_UNIT_CLASS = 23
SEC_STUDENTS_UNIT_CLASS = 21
PORTABLE_UNIT_SIZE = 75

schoolAssetsPortablesSlim <- schoolAssetsPortables %>%
  select(sfis = SFIS_ID, year = Sch_yr, dsb.index = Dsb_index, facility.name = FacilityName, dataset.id = DataSetID,
         current.use = CurrentUse, area.m2 = GFA_m2, num.units = NumberOfUnits) %>%
  filter(dataset.id == 2, year == 2017, area.m2 > 0) %>%
  select(-dataset.id) %>%
  filter(!grepl(filterList, current.use, ignore.case = TRUE)) %>%
  group_by(year, dsb.index, sfis, facility.name) %>%
  summarise(
    area.m2 = sum(area.m2),
    num.units = sum(num.units)
  ) %>%
  ungroup() %>%
  mutate(num.units.calculated = round(area.m2 / PORTABLE_UNIT_SIZE, 0))

# schoolSFIS <- readRDS('output/school_sfis_2017.rds') %>%
#   select(-area.m2, -num.units.calculated)

# Join Portables Data to School Data and recalculate utilization based on the size of portable
schoolSFIS <- left_join(schoolSFIS, select(schoolAssetsPortablesSlim, sfis, area.m2, num.units.calculated), by = 'sfis') %>%
  replace_na(list(area.m2 = 0, num.units.calculated = 0)) %>%
  mutate(capacity.portable = ifelse(panel == 'Elementary', num.units.calculated * ELE_STUDENTS_UNIT_CLASS, 
                                    num.units.calculated * SEC_STUDENTS_UNIT_CLASS)) %>%
  mutate(capacity.total = otg + capacity.portable) %>%
  mutate(utilization.total = ade / capacity.total)

# Utilization above 1 at this point could be erroneous data
# TODO check with Alec regarding this.
print(paste0('There are ', length(filter(schoolSFIS, utilization.total > 1)$sfis), ' schools with utilization greater than 1.2.'))

saveRDS(schoolSFIS, file = 'cache/school_sfis_2017.rds')
```

```{r clean school assets, echo=FALSE}
# TODO ask Alec what is this info used for.
schoolAssetsSlim <- schoolAssets %>%
  filter(DataSetId == 2, Status == 'Open', Panel == 'School') %>%
  select(bid = BID, lat = Latitude, long = Longitude, ade = ADE,
         asset.name = AssetName) %>%
  drop_na(bid, lat, long, ade)
```

## Clean EQAO Data

- Remove not reported (N/R) and no data (N/D)
- Remove suppressed (SP)
- Keep only public and catholic school types
- Calculate mean and standard deviations for reading, writing, and mathematics across the same board/panel

```{r eqao, eval=FALSE}
eqaoSlim <- eqao %>%
  select(School.Number, School.Name, School.Type, School.Level, School.Language, Enrolment, Latitude, Longitude,
         Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Reading:Change.in.Grade.10.OSSLT.Literacy.Achievement.Over.Three.Years) %>%
  mutate_at(vars(matches("Percentage|Change")), list(~gsub(" *%", "", .))) %>%
  # Remove N/R (not-reported) and N/D (no-data)
  mutate_at(vars(matches("Percentage|Change")), list(~gsub("[A-z]\\/[A-z]", NA, .))) %>%
  # Remove SP (suppressed)
  mutate_at(vars(matches("Percentage|Change")), list(~gsub("[A-z][A-z]", NA, .))) %>%
  mutate_at(vars(matches("Percentage|Change")), list(~as.numeric(.))) %>%
  # Keep only "public" and "catholic"
  filter(School.Type %in% c("Public", "Catholic"))

eqao_distribution <- eqaoSlim %>%
  select_at(vars("School.Type", "School.Language", "School.Level", matches("Achieving.the.Provincial"))) %>%
  group_by(School.Type, School.Language, School.Level) %>%
  summarise_all(list(mean = mean, std = sd), na.rm = TRUE)

eqao_standardized <- left_join(eqaoSlim, eqao_distribution, by = c("School.Type", "School.Language", "School.Level")) %>%
  mutate(Grade.3.Reading.Standardized = (Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Reading - 
                                         Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Reading_mean) /
                                         Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Reading_std) %>%
  mutate(Grade.3.Writing.Standardized = (Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Writing - 
                                         Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Writing_mean) /
                                         Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Writing_std) %>%
  mutate(Grade.3.Mathematics.Standardized = (Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Mathematics - 
                                         Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Mathematics_mean) /
                                         Percentage.of.Grade.3.Students.Achieving.the.Provincial.Standard.in.Mathematics_std) %>%
  mutate(Grade.6.Reading.Standardized = (Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Reading - 
                                         Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Reading_mean) /
                                         Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Reading_std) %>%
  mutate(Grade.6.Writing.Standardized = (Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Writing - 
                                         Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Writing_mean) /
                                         Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Writing_std) %>%
  mutate(Grade.6.Mathematics.Standardized = (Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Mathematics - 
                                         Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Mathematics_mean) /
                                         Percentage.of.Grade.6.Students.Achieving.the.Provincial.Standard.in.Mathematics_std) %>%
  mutate(Grade.9.Academic.Mathematics.Standardized = (Percentage.of.Grade.9.Students.Achieving.the.Provincial.Standard.in.Academic.Mathematics - 
                                         Percentage.of.Grade.9.Students.Achieving.the.Provincial.Standard.in.Academic.Mathematics_mean) /
                                         Percentage.of.Grade.9.Students.Achieving.the.Provincial.Standard.in.Academic.Mathematics_std) %>%
  mutate(Grade.9.Applied.Mathematics.Standardized = (Percentage.of.Grade.9.Students.Achieving.the.Provincial.Standard.in.Applied.Mathematics - 
                                         Percentage.of.Grade.9.Students.Achieving.the.Provincial.Standard.in.Applied.Mathematics_mean) /
                                         Percentage.of.Grade.9.Students.Achieving.the.Provincial.Standard.in.Applied.Mathematics_std) %>%
  select_at(vars(School.Name, School.Number, School.Type, School.Language, School.Level, matches("Standardized"))) %>%
  mutate(eqao = select(., Grade.3.Reading.Standardized, Grade.3.Writing.Standardized, Grade.3.Mathematics.Standardized,
                           Grade.6.Reading.Standardized, Grade.6.Writing.Standardized, Grade.6.Mathematics.Standardized,
                           Grade.9.Academic.Mathematics.Standardized, Grade.9.Applied.Mathematics.Standardized) %>% rowSums(na.rm = TRUE)) %>%
  select(School.Name, School.Number, School.Type, School.Language, School.Level, eqao)

saveRDS(eqao_standardized, file = 'cache/eqao_standardized_2017.rds')

```

